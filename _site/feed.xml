<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="ko"><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://shjeong92.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://shjeong92.github.io/" rel="alternate" type="text/html" hreflang="ko" /><updated>2021-06-06T22:34:26+09:00</updated><id>https://shjeong92.github.io/feed.xml</id><title type="html">Hyuk’s devlog</title><subtitle>Your Site Description
</subtitle><author><name>Sanghyuk Jeong</name><email>shjeong920522@gmail.com</email></author><entry><title type="html">[ #9 ] 클러스터 백업 &amp;amp; 복구</title><link href="https://shjeong92.github.io/2021/06/04/Learning-Kubernetes-09.html" rel="alternate" type="text/html" title="[ #9 ] 클러스터 백업 &amp;amp; 복구" /><published>2021-06-04T00:00:00+09:00</published><updated>2021-06-04T00:00:00+09:00</updated><id>https://shjeong92.github.io/2021/06/04/Learning-Kubernetes-09</id><content type="html" xml:base="https://shjeong92.github.io/2021/06/04/Learning-Kubernetes-09.html">&lt;p&gt;이번 포스트에서는 ETCD database를 이용한 클러스터 백업 및 복구 방법에 대해서 다뤄보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;etcd란&quot;&gt;etcd란&lt;/h2&gt;

&lt;p&gt;etcd는 모든 클러스터 데이터에 대한 Kubernetes의 백업 저장소로 사용되는 일관되고 가용성이 높은 키 값 저장소입니다&lt;/p&gt;

&lt;p&gt;그리고 ETCD는 각 마스터노드에 존재하고, key=value의 데이터는 마스터 노드의 /var/lib/etcd 에 저장됩니다.&lt;/p&gt;

&lt;p&gt;ETCD는 built in 스냅샷 solution을 가지고 있는데요 이를통해 현재 실행중인 모든 리소스의 정보를 백업하고, 복구할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;step1---etcd가-설치되어-있지-않을경우-설치합니다&quot;&gt;STEP1 - etcd가 설치되어 있지 않을경우 설치합니다.&lt;/h3&gt;

&lt;p&gt;제 쿠버네티 클러스터는 1 개의 마스터노드, 3개의 워커노드로 구성되어 있습니다. googld cloud compute engine 인스턴스를 사용하여 구성하였으며 모든 노드는 Ubuntu 18.04.5 LTS 버전입니다.&lt;/p&gt;

&lt;p&gt;아래 커맨드를 이용해 etcd-client를 설치해줍니다&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt update

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;etcd-client
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step2---복구시킬-환경-구성&quot;&gt;STEP2 - 복구시킬 환경 구성&lt;/h3&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#depl.yaml&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;apps/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Deployment&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp-deployment&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;front-end&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp-pod&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;front-end&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-container&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx:1.19&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;replicas&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;selector&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;matchLabels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;front-end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;간단한 yaml파일을 통해 3개의 nginx 파드를 배포합니다&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl apply &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; depl.yml 
deployment.apps/myapp-deployment created
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그리고 현재 어떤 리소스들이 돌아가고있는지 확인해주고 이 상황의 스냅샷을 생성할겁니다&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kubectl get all
NAME                                    READY   STATUS    RESTARTS   AGE
pod/myapp-deployment-7f6679cc7d-5qwxx   1/1     Running   0          32s
pod/myapp-deployment-7f6679cc7d-855lp   1/1     Running   0          32s
pod/myapp-deployment-7f6679cc7d-bxxjx   1/1     Running   0          32s

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    &amp;lt;none&amp;gt;        443/TCP   8d

NAME                               READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/myapp-deployment   3/3     3            3           32s

NAME                                          DESIRED   CURRENT   READY   AGE
replicaset.apps/myapp-deployment-7f6679cc7d   3         3         3       32s
shjeong920522@master:~/Pod$ 

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;스냅샷-생성하기&quot;&gt;스냅샷 생성하기&lt;/h2&gt;

&lt;p&gt;etcdctl의 스냅샷을 생성하기위해선 아래와같은 옵션이 필요합니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;etcdctl &lt;span class=&quot;nt&quot;&gt;--cacert&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;옵션값 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--cert&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;옵션값 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;옵션값 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
snapshot save 백업경로 및 파일이름
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;그렇다면 이 옵션값은 어디서 확인가능할까요?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ps명령어 와 grep을 를 활용하면 된답니다&lt;/p&gt;

&lt;p&gt;아래 명령어를 사용하여 다 찾아서 값을 가져와도되지만&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ps &lt;span class=&quot;nt&quot;&gt;-ef&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;grep &lt;/span&gt;etcd
root      2863  2764  1 05:36 ?        00:00:23 etcd &lt;span class=&quot;nt&quot;&gt;--advertise-client-urls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;https://10.178.0.2:2379 &lt;span class=&quot;nt&quot;&gt;--cert-file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/kubernetes/pki/etcd/server.crt &lt;span class=&quot;nt&quot;&gt;--client-cert-auth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--data-dir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/var/lib/etcd &lt;span class=&quot;nt&quot;&gt;--initial-advertise-peer-urls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;https://10.178.0.2:2380 &lt;span class=&quot;nt&quot;&gt;--initial-cluster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;master&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;https://10.178.0.2:2380 &lt;span class=&quot;nt&quot;&gt;--key-file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/kubernetes/pki/etcd/server.key &lt;span class=&quot;nt&quot;&gt;--listen-client-urls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;https://127.0.0.1:2379,https://10.178.0.2:2379 &lt;span class=&quot;nt&quot;&gt;--listen-metrics-urls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;http://127.0.0.1:2381 &lt;span class=&quot;nt&quot;&gt;--listen-peer-urls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;https://10.178.0.2:2380 &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;master &lt;span class=&quot;nt&quot;&gt;--peer-cert-file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/kubernetes/pki/etcd/peer.crt &lt;span class=&quot;nt&quot;&gt;--peer-client-cert-auth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--peer-key-file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/kubernetes/pki/etcd/peer.key &lt;span class=&quot;nt&quot;&gt;--peer-trusted-ca-file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/kubernetes/pki/etcd/ca.crt &lt;span class=&quot;nt&quot;&gt;--snapshot-count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;10000 &lt;span class=&quot;nt&quot;&gt;--trusted-ca-file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/kubernetes/pki/etcd/ca.crt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;표에 들어간 커맨드로 원하는 부분을 강조시켜 찾는방법을 추천드립니다. 눈알굴려서 찾는것보다 훨씬 빠르더라구요&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;center&gt;etcdctl 명령 옵션&lt;/center&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;center&gt;etcd &lt;br /&gt;프로세스 실행옵션&lt;/center&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;center&gt;값&lt;/center&gt;&lt;/th&gt;
      &lt;th&gt;&lt;center&gt;커맨드로 빨리찾기&lt;/center&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--cacert&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--trusted-ca-file&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;/etc/kubernetes/pki/etcd/ca.crt&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ps -ef | grep etcd | grep trusted&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--cert&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--cert-file&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;/etc/kubernetes/pki/etcd/server.crt&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ps -ef | grep etcd | grep &quot;\--cert&quot;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--key&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--key-file&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;/etc/kubernetes/pki/etcd/server.key&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ps -ef | grep etcd | grep &quot;\--key&quot;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;그리고 값 부분은 항상 같은것이 아닐 수도 있기에 커맨드로 직접 확인하셔야 합니다.&lt;/p&gt;

&lt;p&gt;자 이제 스냅샷을 생성하기위하여 우선 루트계정으로 전환해줍니다&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아래와 같이 환경변수를 등록해줍니다
ETCDCTL_API 3버전을 사용하기 위함입니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root# &lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ETCDCTL_API&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root# etcdctl &lt;span class=&quot;nt&quot;&gt;--cacert&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/kubernetes/pki/etcd/ca.crt &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--cert&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/kubernetes/pki/etcd/server.crt &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/kubernetes/pki/etcd/server.key &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; snapshot save /opt/backup
Snapshot saved at /opt/backup
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;스냅샷을 생성하였으니 아까 배포하였던 deployment 를 delete하고 etcdctl 복구를하여
정말 동작하던 deployment를 다시 배포해주는지 확인해봅시다&lt;/p&gt;

&lt;p&gt;우선 루트계정에서 로그아웃 해주시구요&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root# &lt;span class=&quot;nb&quot;&gt;exit
logout&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;deployment를 삭제시켜줍니다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl delete &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; depl.yml 
deployment.apps &lt;span class=&quot;s2&quot;&gt;&quot;myapp-deployment&quot;&lt;/span&gt; deleted
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;복구하기로 넘어갑니다.&lt;/p&gt;

&lt;h2 id=&quot;스냅샷으로-복구하기&quot;&gt;스냅샷으로 복구하기&lt;/h2&gt;

&lt;p&gt;복구할때는 스냅샷을 만들때 넣었던 옵션에서 네가지의 옵션이 더 추가됩니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;center&gt;etcdctl 명령 옵션&lt;/center&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;center&gt;etcd &lt;br /&gt;프로세스 실행옵션&lt;/center&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;&lt;center&gt;값&lt;/center&gt;&lt;/th&gt;
      &lt;th&gt;&lt;center&gt;커맨드로 빨리찾기&lt;/center&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--cacert&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--trusted-ca-file&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;/etc/kubernetes/pki/etcd/ca.crt&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ps -ef | grep etcd | grep trusted&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--cert&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--cert-file&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;/etc/kubernetes/pki/etcd/server.crt&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ps -ef | grep etcd | grep &quot;\--cert&quot;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--key&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--key-file&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;/etc/kubernetes/pki/etcd/server.key&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ps -ef | grep etcd | grep &quot;\--key&quot;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--initial-advertise-peer-urls&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--initial-advertise-peer-urls&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;https://10.178.0.2:2380&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ps -ef | grep etcd | grep initial&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--initial-cluster=master&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--initial-cluster=master&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;https://10.178.0.2:2380&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ps -ef | grep etcd | grep initial&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--data-dir&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--data-dir&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;/var/lib/etcd_backup&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ps -ef | grep etcd | grep &quot;\--data-dir&quot; &lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--name&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;--name&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;master(마스터노드이름)&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ps -ef | grep etcd | grep &quot;\--name&quot;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;자 여기까지가 restore 할때 필요한 모든 옵션입니다.&lt;/p&gt;

&lt;p&gt;이제 아까 찍어놨던 스냅샷으로 복구되는지 확인해봅시다.&lt;/p&gt;

&lt;p&gt;우선 루트 계정으로 전환하구요&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;restore 명령어를 입력해주고 로그아웃해줍니다&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root# etcdctl &lt;span class=&quot;nt&quot;&gt;--cacert&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/kubernetes/pki/etcd/ca.crt &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--cert&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/kubernetes/pki/etcd/server.crt &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/kubernetes/pki/etcd/server.key &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--initial-advertise-peer-urls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;https://10.178.0.2:2380 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--initial-cluster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;master&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;https://10.178.0.2:2380 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--data-dir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/var/lib/etcd_backup &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;master &lt;span class=&quot;se&quot;&gt;\ &lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; snapshot restore /opt/backup

root# &lt;span class=&quot;nb&quot;&gt;exit
logout&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;/opt/backup 에 생성해뒀던 스냅샷을이용해서 /var/lib 위치에 etcd_backup 파일을 생성합니다
staticpod에서 실행되는 etcd가 이를 바라보도록 해줘야하겠지요&lt;/p&gt;

&lt;p&gt;staticpod의 위치인 /etc/kubernetes/manifest로 이동후 etcd.yaml을 수정해야합니다&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /etc/kubernetes/manifest

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;vim etcd.yaml

~~~yaml
&lt;span class=&quot;c&quot;&gt;#etcd.yaml&lt;/span&gt;
...중략

volumes:
- hostPath:
    path: /etc/kubernetes/pki/etcd
    &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;: DirectoryOrCreate
  name: etcd-certs
- hostPath:
    path: /var/lib/etcd_backup     &amp;lt;&lt;span class=&quot;nt&quot;&gt;-----------&lt;/span&gt;  backup한 스냅샷을 바라보게 수정해줍니다
    &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;: DirectoryOrCreate
  name: etcd-data

...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;변경사항을 저장해주면 새로 로드될때까지 시간이 조금걸립니다&lt;/p&gt;

&lt;p&gt;잠시후 정말 실행 중이던 deployment가 실행중인지 확인해봅시다&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get deploy
NAME               READY   UP-TO-DATE   AVAILABLE   AGE
myapp-deployment   3/3     3            3           20s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;짜잔~ 잘 복구된것을 확인할 수 있었습니다&lt;/p&gt;</content><author><name>Sanghyuk Jeong</name><email>shjeong920522@gmail.com</email></author><category term="Kubernetes" /><category term="maintenance" /><category term="static" /><category term="pod" /><category term="strategy" /><category term="쿠버네티스" /><category term="update" /><summary type="html">이번 포스트에서는 ETCD database를 이용한 클러스터 백업 및 복구 방법에 대해서 다뤄보겠습니다. etcd란 etcd는 모든 클러스터 데이터에 대한 Kubernetes의 백업 저장소로 사용되는 일관되고 가용성이 높은 키 값 저장소입니다 그리고 ETCD는 각 마스터노드에 존재하고, key=value의 데이터는 마스터 노드의 /var/lib/etcd 에 저장됩니다. ETCD는 built in 스냅샷 solution을 가지고 있는데요 이를통해 현재 실행중인 모든 리소스의 정보를 백업하고, 복구할 수 있습니다. STEP1 - etcd가 설치되어 있지 않을경우 설치합니다. 제 쿠버네티 클러스터는 1 개의 마스터노드, 3개의 워커노드로 구성되어 있습니다. googld cloud compute engine 인스턴스를 사용하여 구성하였으며 모든 노드는 Ubuntu 18.04.5 LTS 버전입니다. 아래 커맨드를 이용해 etcd-client를 설치해줍니다 $ sudo apt update $ sudo apt install etcd-client STEP2 - 복구시킬 환경 구성 #depl.yaml apiVersion: apps/v1 kind: Deployment metadata: name: myapp-deployment labels: app: myapp type: front-end spec: template: metadata: name: myapp-pod labels: app: myapp type: front-end spec: containers: - name: nginx-container image: nginx:1.19 replicas: 3 selector: matchLabels: type: front-end 간단한 yaml파일을 통해 3개의 nginx 파드를 배포합니다 $ kubectl apply -f depl.yml deployment.apps/myapp-deployment created 그리고 현재 어떤 리소스들이 돌아가고있는지 확인해주고 이 상황의 스냅샷을 생성할겁니다 $ kubectl get all NAME READY STATUS RESTARTS AGE pod/myapp-deployment-7f6679cc7d-5qwxx 1/1 Running 0 32s pod/myapp-deployment-7f6679cc7d-855lp 1/1 Running 0 32s pod/myapp-deployment-7f6679cc7d-bxxjx 1/1 Running 0 32s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.96.0.1 &amp;lt;none&amp;gt; 443/TCP 8d NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/myapp-deployment 3/3 3 3 32s NAME DESIRED CURRENT READY AGE replicaset.apps/myapp-deployment-7f6679cc7d 3 3 3 32s shjeong920522@master:~/Pod$ 스냅샷 생성하기 etcdctl의 스냅샷을 생성하기위해선 아래와같은 옵션이 필요합니다. etcdctl --cacert=옵션값 \ --cert=옵션값 \ --key=옵션값 \ snapshot save 백업경로 및 파일이름 그렇다면 이 옵션값은 어디서 확인가능할까요? ps명령어 와 grep을 를 활용하면 된답니다 아래 명령어를 사용하여 다 찾아서 값을 가져와도되지만 $ ps -ef | grep etcd root 2863 2764 1 05:36 ? 00:00:23 etcd --advertise-client-urls=https://10.178.0.2:2379 --cert-file=/etc/kubernetes/pki/etcd/server.crt --client-cert-auth=true --data-dir=/var/lib/etcd --initial-advertise-peer-urls=https://10.178.0.2:2380 --initial-cluster=master=https://10.178.0.2:2380 --key-file=/etc/kubernetes/pki/etcd/server.key --listen-client-urls=https://127.0.0.1:2379,https://10.178.0.2:2379 --listen-metrics-urls=http://127.0.0.1:2381 --listen-peer-urls=https://10.178.0.2:2380 --name=master --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt --peer-client-cert-auth=true --peer-key-file=/etc/kubernetes/pki/etcd/peer.key --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt --snapshot-count=10000 --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt 표에 들어간 커맨드로 원하는 부분을 강조시켜 찾는방법을 추천드립니다. 눈알굴려서 찾는것보다 훨씬 빠르더라구요 etcdctl 명령 옵션 etcd 프로세스 실행옵션 값 커맨드로 빨리찾기 --cacert --trusted-ca-file /etc/kubernetes/pki/etcd/ca.crt ps -ef | grep etcd | grep trusted --cert --cert-file /etc/kubernetes/pki/etcd/server.crt ps -ef | grep etcd | grep &quot;\--cert&quot; --key --key-file /etc/kubernetes/pki/etcd/server.key ps -ef | grep etcd | grep &quot;\--key&quot; 그리고 값 부분은 항상 같은것이 아닐 수도 있기에 커맨드로 직접 확인하셔야 합니다. 자 이제 스냅샷을 생성하기위하여 우선 루트계정으로 전환해줍니다 $ sudo -i 아래와 같이 환경변수를 등록해줍니다 ETCDCTL_API 3버전을 사용하기 위함입니다. root# export ETCDCTL_API=3 root# etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt \ &amp;gt; --cert=/etc/kubernetes/pki/etcd/server.crt \ &amp;gt; --key=/etc/kubernetes/pki/etcd/server.key \ &amp;gt; snapshot save /opt/backup Snapshot saved at /opt/backup 스냅샷을 생성하였으니 아까 배포하였던 deployment 를 delete하고 etcdctl 복구를하여 정말 동작하던 deployment를 다시 배포해주는지 확인해봅시다 우선 루트계정에서 로그아웃 해주시구요 root# exit logout deployment를 삭제시켜줍니다. $ kubectl delete -f depl.yml deployment.apps &quot;myapp-deployment&quot; deleted 복구하기로 넘어갑니다. 스냅샷으로 복구하기 복구할때는 스냅샷을 만들때 넣었던 옵션에서 네가지의 옵션이 더 추가됩니다. etcdctl 명령 옵션 etcd 프로세스 실행옵션 값 커맨드로 빨리찾기 --cacert --trusted-ca-file /etc/kubernetes/pki/etcd/ca.crt ps -ef | grep etcd | grep trusted --cert --cert-file /etc/kubernetes/pki/etcd/server.crt ps -ef | grep etcd | grep &quot;\--cert&quot; --key --key-file /etc/kubernetes/pki/etcd/server.key ps -ef | grep etcd | grep &quot;\--key&quot; --initial-advertise-peer-urls --initial-advertise-peer-urls https://10.178.0.2:2380 ps -ef | grep etcd | grep initial --initial-cluster=master --initial-cluster=master https://10.178.0.2:2380 ps -ef | grep etcd | grep initial --data-dir --data-dir /var/lib/etcd_backup ps -ef | grep etcd | grep &quot;\--data-dir&quot; --name --name master(마스터노드이름) ps -ef | grep etcd | grep &quot;\--name&quot; 자 여기까지가 restore 할때 필요한 모든 옵션입니다. 이제 아까 찍어놨던 스냅샷으로 복구되는지 확인해봅시다. 우선 루트 계정으로 전환하구요 $ sudo -i restore 명령어를 입력해주고 로그아웃해줍니다 root# etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt \ &amp;gt; --cert=/etc/kubernetes/pki/etcd/server.crt \ &amp;gt; --key=/etc/kubernetes/pki/etcd/server.key \ &amp;gt; --initial-advertise-peer-urls=https://10.178.0.2:2380 \ &amp;gt; --initial-cluster=master=https://10.178.0.2:2380 \ &amp;gt; --data-dir=/var/lib/etcd_backup \ &amp;gt; --name=master \ &amp;gt; snapshot restore /opt/backup root# exit logout /opt/backup 에 생성해뒀던 스냅샷을이용해서 /var/lib 위치에 etcd_backup 파일을 생성합니다 staticpod에서 실행되는 etcd가 이를 바라보도록 해줘야하겠지요 staticpod의 위치인 /etc/kubernetes/manifest로 이동후 etcd.yaml을 수정해야합니다 $ cd /etc/kubernetes/manifest $ sudo vim etcd.yaml ~~~yaml #etcd.yaml ...중략 volumes: - hostPath: path: /etc/kubernetes/pki/etcd type: DirectoryOrCreate name: etcd-certs - hostPath: path: /var/lib/etcd_backup &amp;lt;----------- backup한 스냅샷을 바라보게 수정해줍니다 type: DirectoryOrCreate name: etcd-data ... 변경사항을 저장해주면 새로 로드될때까지 시간이 조금걸립니다 잠시후 정말 실행 중이던 deployment가 실행중인지 확인해봅시다 $ kubectl get deploy NAME READY UP-TO-DATE AVAILABLE AGE myapp-deployment 3/3 3 3 20s 짜잔~ 잘 복구된것을 확인할 수 있었습니다</summary></entry><entry><title type="html">[ #8 ] 클러스터 유지보수</title><link href="https://shjeong92.github.io/2021/06/03/Learning-Kubernetes-08.html" rel="alternate" type="text/html" title="[ #8 ] 클러스터 유지보수" /><published>2021-06-03T00:00:00+09:00</published><updated>2021-06-03T00:00:00+09:00</updated><id>https://shjeong92.github.io/2021/06/03/Learning-Kubernetes-08</id><content type="html" xml:base="https://shjeong92.github.io/2021/06/03/Learning-Kubernetes-08.html">&lt;p&gt;오늘은 클러스터의 유지보수에 관련한 포스트를 써볼까 합니다.&lt;/p&gt;

&lt;p&gt;쿠버네티스를 이용하여 서비스를 구축하고나서 언젠가는 시스템을 업데이트 시켜야할 일이 생길 것이며, 오류로 인하여 노드가 먹통이 되는일도 생길 것입니다.&lt;/p&gt;

&lt;p&gt;그렇다면 노드의 작동을 중지시키면, 또는 오류로 중지된다면 어떻게 될까요?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;master node의 kube-contoller-manager에는 pod-eviction-timeout이 존재합니다&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;컨디션&quot;&gt;컨디션&lt;/h2&gt;

&lt;p&gt;각 노드에는 아래와 같이 여러가지 condition이 존재합니다&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;노드 컨디션&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;설명&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;Ready&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;노드가 상태 양호하며 파드를 수용할 준비가 되어 있는 경우 True, 노드의 상태가 불량하여 파드를 수용하지 못할 경우 False, 그리고 노드 컨트롤러가 마지막 node-monitor-grace-period (기본값 40 기간 동안 노드로부터 응답을 받지 못한 경우) Unknown&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;DiskPressure&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;디스크 사이즈 상에 압박이 있는 경우, 즉 디스크 용량이 넉넉치 않은 경우 True, 반대의 경우 False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;MemoryPressure&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;노드 메모리 상에 압박이 있는 경우, 즉 노드 메모리가 넉넉치 않은 경우 True, 반대의 경우 False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;PIDPressure&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;프로세스 상에 압박이 있는 경우, 즉 노드 상에 많은 프로세스들이 존재하는 경우 True, 반대의 경우 False&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;NetworkUnavailable&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;노드에 대해 네트워크가 올바르게 구성되지 않은 경우 True, 반대의 경우 False&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;또한 노드 lifecycle controller는 컨디션을 아래와 같은 &lt;strong&gt;&lt;em&gt;built-in taint&lt;/em&gt;&lt;/strong&gt;를 자동으로 생성합니다.&lt;/p&gt;

&lt;h3 id=&quot;built-in-taints&quot;&gt;built-in taints&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;node.kubernetes.io/not-ready: 노드가 준비되지 않음. 이는 NodeCondition Ready 가 “False”로 됨에 해당.&lt;/li&gt;
  &lt;li&gt;node.kubernetes.io/unreachable: 노드가 노드 컨트롤러에서 도달할 수 없음. 이는  NodeCondition Ready 가 “Unknown”로 됨에 해당.&lt;/li&gt;
  &lt;li&gt;node.kubernetes.io/memory-pressure: 노드에 메모리 할당 압박이 있음.&lt;/li&gt;
  &lt;li&gt;node.kubernetes.io/disk-pressure: 노드에 디스크 할당 압박이 있음.&lt;/li&gt;
  &lt;li&gt;node.kubernetes.io/pid-pressure: 노드에 PID 할당 압박이 있음.&lt;/li&gt;
  &lt;li&gt;node.kubernetes.io/network-unavailable: 노드의 네트워크를 사용할 수 없음.&lt;/li&gt;
  &lt;li&gt;node.kubernetes.io/unschedulable: 노드를 스케줄할 수 없음.&lt;/li&gt;
  &lt;li&gt;node.cloudprovider.kubernetes.io/uninitialized: “외부” 클라우드 공급자로 kubelet을 시작하면, 이 테인트가 노드에서 사용 불가능으로 표시되도록 설정됨.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그 중에서도 &lt;code&gt;ready&lt;/code&gt; 컨디션은 좀 특별한데요. 
ready 컨디션의 상태가 pod-eviction-timeout (kube-controller-manager에 전달된 인수) 보다 더 길게 Unknown 또는 False로 유지되는 경우, 노드 상에 모든 파드는 노드 컨트롤러에 의해 삭제되도록 스케줄 됩니다.&lt;/p&gt;

&lt;p&gt;클라우드-컨트롤러-관리자의 컨트롤러가 이 노드를 초기화하면, kubelet이 이 테인트를 제거합니다 즉 다시 pod가 배정될 수 있는 상태가 되는것이죠. 기본 축출 타임아웃 기간은 기본 5분으로 설정되어 있습니다. 만약 노드가 다운되었다가 5분안에 복구가 되었다면 노드 내의 pod들은 그대로 존재하지만, 설정된 타임아웃 시간을 초과한다면 그안의 파드들은 모두 중단 되는것입니다.&lt;/p&gt;

&lt;p&gt;만약 수정하고 싶다면 마스터 노드의 kube-system 네임스페이스에 있는 kube-controller-manager-master을 edit해주면됩니다.&lt;/p&gt;

&lt;p&gt;그런데 말이죠 이 pod는 static pod입니다. 
&lt;a href=&quot;https://shjeong92.github.io/2021/05/31/Learning-Kubernetes-06.html&quot;&gt;6번째 포스트&lt;/a&gt;에서 설명 했었는데 static pod 를 수정하려면 
static pod을 생성한 yaml파일 자체를 수정한다고 했었죠?&lt;/p&gt;

&lt;p&gt;static pod의 위치를 찾는것 부터 복습해봅시다&lt;/p&gt;

&lt;p&gt;우선 config.yaml파일의 위치를 찾아줍니다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ps &lt;span class=&quot;nt&quot;&gt;-ef&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;grep &lt;/span&gt;kubelet | &lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\-&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;-config&quot;&lt;/span&gt;

root     10476     1  3 May28 ?        05:09:26 /usr/bin/kubelet &lt;span class=&quot;nt&quot;&gt;--bootstrap-kubeconfig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/kubernetes/bootstrap-kubelet.conf &lt;span class=&quot;nt&quot;&gt;--kubeconfig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/kubernetes/kubelet.conf &lt;span class=&quot;nt&quot;&gt;--config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/var/lib/kubelet/config.yaml &lt;span class=&quot;nt&quot;&gt;--network-plugin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;cni &lt;span class=&quot;nt&quot;&gt;--pod-infra-container-image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;k8s.gcr.io/pause:3.4.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;config.yaml파일 내에서 staticpath를 찾아냅시다&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo grep&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; static /var/lib/kubelet/config.yaml
staticPodPath: /etc/kubernetes/manifests
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;staticPodPath로 이동후 뭐가있나 확인해봅니다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /etc/kubernetes/manifests

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;ls
&lt;/span&gt;etcd.yaml  kube-apiserver.yaml  kube-controller-manager.yaml  kube-scheduler.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;자 이제 이 yaml파일을 수정하면 됩니다.
저는 이 기본 5분인 eviction-timeout을 60초로 바꾸어 보겠습니다.&lt;/p&gt;

&lt;p&gt;command에 &lt;code&gt;--pod-eviction-timeout=60s&lt;/code&gt; 옵션을 추가해 줌으로써 말이죠.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Pod&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;annotations&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;kubernetes.io/config.hash&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;47cace34a635d6f3e305eee20e0e7b30&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;kubernetes.io/config.mirror&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;47cace34a635d6f3e305eee20e0e7b30&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;kubernetes.io/config.seen&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2021-05-28T03:40:42.961803243Z&quot;&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;kubernetes.io/config.source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;file&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;creationTimestamp&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2021-05-28T03:40:55Z&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;component&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kube-controller-manager&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;tier&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;control-plane&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kube-controller-manager-master&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kube-system&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;ownerReferences&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;controller&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Node&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;master&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;uid&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;69f4d243-9420-45a9-928e-672a1d3b977a&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;resourceVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;478&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;uid&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;4cfad35d-8664-42cf-9ed9-5fd5b4d771a4&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kube-controller-manager&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--allocate-node-cidrs=true&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--pod-eviction-timeout=60s&lt;/span&gt;      &lt;span class=&quot;c1&quot;&gt;#&amp;lt;----------- 해당라인을 추가하면 이제 5분이아닌 60초로 변경됩니다.&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--authentication-kubeconfig=/etc/kubernetes/controller-manager.conf&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--authorization-kubeconfig=/etc/kubernetes/controller-manager.conf&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--bind-address=127.0.0.1&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--client-ca-file=/etc/kubernetes/pki/ca.crt&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--cluster-cidr=10.244.0.0/16&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--cluster-name=kubernetes&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--cluster-signing-key-file=/etc/kubernetes/pki/ca.key&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--controllers=*,bootstrapsigner,tokencleaner&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--kubeconfig=/etc/kubernetes/controller-manager.conf&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--leader-elect=true&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--port=0&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--root-ca-file=/etc/kubernetes/pki/ca.crt&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--service-account-private-key-file=/etc/kubernetes/pki/sa.key&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--service-cluster-ip-range=10.96.0.0/12&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;--use-service-account-credentials=true&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;k8s.gcr.io/kube-controller-manager:v1.21.1&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;...중략&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;저장해주면 멈췄다가&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kube-controller-manager-master    0/1     Running   0          3s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;옵션을 적용시켜 pod시 재시동됩니다~&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kube-controller-manager-master    1/1     Running   0          3s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;eviction-timeout의-존재이유&quot;&gt;eviction timeout의 존재이유?&lt;/h2&gt;
&lt;p&gt;위에서 eviction timeout의 값을 바꾸는 실습을 해보았는데요 이 timeout은 무엇과 연관이 있는지 두가지 케이스를 통해서 알아보겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;case1: node가 먹통이 되었다가 설정해놓은 eviction-timeout보다 짦은시간안에 복구된경우&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;노드내에 있던 pod들이 kubectl에 의해 다시 해당노드에서 재시작됩니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;case2: node가 먹통이 된후 eviction-timeout을 초과한경우&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;해당 노드에있는 pod들을 모두 축출한 후에 노드가 재시동됩니다.&lt;/li&gt;
      &lt;li&gt;해당 노드에있던 pod이 replicaset을 통해 생성되었다면 다시 다른노드에 잘 생성이 되겠지만, 일반 pod이라면 다시 살아나지 못할겁니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;노드관련-명령어&quot;&gt;노드관련 명령어&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code&gt; kubectl drain node &lt;/code&gt;
    &lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl drain node
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;해당 노드에있는 pod들을 종료시키고, 다른노드에 재시작시킵니다 (graceful node shutdown) 또한 해당 노드를 unschedulable하게 만든다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;kubernetes의 버전 또는 리눅스 커널등의 업그레이드할 때 사용할 수 있겠습니다(kubeadm, kubelet, kubectl, …)&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code&gt; kubectl cordon node &lt;/code&gt;
    &lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl cordon node
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;ul&gt;
      &lt;li&gt;해당 노드를 unschedulable하게 만듭니다&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;실행 중인 Pod를 축출하지는 않습니다&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code&gt; kubectl uncordon node &lt;/code&gt;
    &lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl uncordon node
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;ul&gt;
      &lt;li&gt;해당 노드를 schedulable하게 만든다&lt;/li&gt;
      &lt;li&gt;업그레이드를 마친 노드를 스케쥴러블하게 만듭니다 (taint를 제거)&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;drain명령에 의해서 집나간 pod들이 다시 집을 찾아오진 않습니다.&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;쿠버네티스-버전-및-버전차이-지원&quot;&gt;쿠버네티스 버전 및 버전차이 지원&lt;/h2&gt;

&lt;h3 id=&quot;버전&quot;&gt;버전&lt;/h3&gt;
&lt;p&gt;쿠버네티스 버전은 x.y.z로 표현되는데, 여기서 x는 메이저 버전, y는 마이너 버전, z는 시맨틱 버전 용어에 따른 패치 버전입니다.
kubernetes에는 여러가지 컴포넌트가 있습니다.
각각의 버전은 전부 동일해야할까요? 아닙니다.&lt;/p&gt;

&lt;p&gt;kube-apiserver의 버전이 주축이되고, 나머지 컴포넌트는 각각 다르게 한 두단계 버전이 낮거나 같아도 상관이 없습니다. 특별하게 &lt;strong&gt;kubectl&lt;/strong&gt;의 경우는 kube-apiserver의 버전보다 한단계 높은경우도 지원이 됩니다.&lt;/p&gt;

&lt;p&gt;더 자세한 내용은 &lt;a href=&quot;https://kubernetes.io/ko/docs/setup/release/version-skew-policy/&quot;&gt;공식문서&lt;/a&gt;에서 확인가능 합니다&lt;/p&gt;

&lt;h2 id=&quot;클러스터-업그레이드&quot;&gt;클러스터 업그레이드&lt;/h2&gt;

&lt;p&gt;kubernets는 latest버전부터 두단계 낮은버전까지 서비스를 지원하는데요, 만약에 현재 1.19버전을 사용하고 있는데 1.22버전이 출시 된다면 업그레이드를 해야겠죠.&lt;/p&gt;

&lt;p&gt;그렇다면 1.19버전에서 한번에 1.22번으로 업그레이드 시키면될까요? 추천되는 방법에 의하면
한단계 한단계씩 차례차례로 업그레이드 해야된다고 합니다.&lt;/p&gt;

&lt;h3 id=&quot;업그레이드-방법&quot;&gt;업그레이드 방법&lt;/h3&gt;

&lt;p&gt;쿠버네티스 환경을 어떻게 구성하였는가에 따라 업그레이드 방법이 다양합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;구글의 GKE, AWS의 EKS등의 kubernete를 지원하는 cloud의 경우&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;간단한 클릭 몇번으로 업그레이드 가능&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The hard way로 설치한경우&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;한땀한땀 설치한 것처럼 업그레이드 또한 한땀한땀 해야합니다&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;저는 &lt;strong&gt;kubeadm&lt;/strong&gt;을 이용하여 kubernetes환경을 구축하였고, &lt;strong&gt;kubeadm&lt;/strong&gt;을 통한 업그레이드 방법에 대해 자세히 설명해 보겠습니다.&lt;/p&gt;

&lt;p&gt;저의 쿠버네티스 환경은 한개의 master노드, 3개의 worker노드로 구성되어있습니다. 1.20버전을 이용하고 있는데 1.21버전으로 업그레이드 해보겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;step1---마스터-노드에-kubeadm-업그레이드-시키기&quot;&gt;STEP1 - 마스터 노드에 kubeadm 업그레이드 시키기.&lt;/h3&gt;

&lt;p&gt;마스터 노드에 접속합니다&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ssh gcloud
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;ssh config&lt;/strong&gt;에 설정을 해놨기에 이렇게 간단하게 접속가능합니다. &lt;strong&gt;ssh config 설정방법&lt;/strong&gt;이 궁금하시면 &lt;a href=&quot;https://shjeong92.github.io/2021/06/01/Handling-ssh-config.html&quot;&gt;여기&lt;/a&gt;로 이동하세요.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그리고  kubernetes환경을 구축할때 hold시켜놨었던 kubeadm을 unhold시켜주고, apt-get 색인 업데이트후, kubeadm을 업데이트 한다음 다시 kubeadm을 hold시켜 줄겁니다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 1.21.x-00에서 x를 최신 패치 버전으로 바꿉니다&lt;/span&gt;
apt-mark unhold kubeadm &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
apt-get update &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;kubeadm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1.21.x-00 &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
apt-mark hold kubeadm

&lt;span class=&quot;c&quot;&gt;#버전 확인해주기&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubeadm version
kubeadm version: &amp;amp;version.Info&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;Major:&lt;span class=&quot;s2&quot;&gt;&quot;1&quot;&lt;/span&gt;, Minor:&lt;span class=&quot;s2&quot;&gt;&quot;21&quot;&lt;/span&gt;, GitVersion:&lt;span class=&quot;s2&quot;&gt;&quot;v1.21.1&quot;&lt;/span&gt;, GitCommit:&lt;span class=&quot;s2&quot;&gt;&quot;5e58841cce77d4bc13713ad2b91fa0d961e69192&quot;&lt;/span&gt;, GitTreeState:&lt;span class=&quot;s2&quot;&gt;&quot;clean&quot;&lt;/span&gt;, BuildDate:&lt;span class=&quot;s2&quot;&gt;&quot;2021-05-12T14:17:27Z&quot;&lt;/span&gt;, GoVersion:&lt;span class=&quot;s2&quot;&gt;&quot;go1.16.4&quot;&lt;/span&gt;, Compiler:&lt;span class=&quot;s2&quot;&gt;&quot;gc&quot;&lt;/span&gt;, Platform:&lt;span class=&quot;s2&quot;&gt;&quot;linux/amd64&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;apt-mark unhold&lt;/strong&gt;와 &lt;strong&gt;apt-mark hold&lt;/strong&gt; 해주는 이유는 kubeadm을 업그레이드하면 설치시 kubelet과 같은 다른 구성 요소가 기본적으로 최신 버전 으로 자동으로 업그레이드되기 때문입니다. (kubernetes는 여러버전을 한꺼번에 업그레이드 권장하지 않기때문입니다!) 이를 해결하기 위해 보류를 사용하여 패키지를 보류 된 것으로 표시하여 패키지가 자동으로 설치, 업그레이드 또는 제거되지 않도록합니다.&lt;/p&gt;

&lt;h3 id=&quot;step2---업그레이드-정보-확인하기&quot;&gt;STEP2 - 업그레이드 정보 확인하기&lt;/h3&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubeadm upgrade plan

...

COMPONENT            CURRENT AVAILABLE

API Server           v1.20.0 v1.21.1

Controller Manager   v1.20.0 v1.21.1

Scheduler            v1.20.0 v1.21.1

Kube Proxy           v1.20.0 v1.21.1

...

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step3---업그레이드-적용시키기&quot;&gt;STEP3 - 업그레이드 적용시키기&lt;/h3&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubeadm upgrade plan apply v1.21.1
&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;조금 오래걸릴 수도 있습니다&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

아래와같이뜨면 성공
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;upgrade/successful] SUCCESS! Your cluster was upgraded to &lt;span class=&quot;s2&quot;&gt;&quot;v1.21.1&quot;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; Enjoy!

&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets &lt;span class=&quot;k&quot;&gt;if &lt;/span&gt;you haven&lt;span class=&quot;s1&quot;&gt;&apos;t already done so.
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step4---node-drain후-kubelet-kubectl-업데이트후-재시작하기&quot;&gt;STEP4 - node drain후 kubelet, kubectl 업데이트후 재시작하기&lt;/h3&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#노드 드레인하기(모든 pod 종료후 다른노드에 새로 실행하기 및 해당노드 unschedulable하게 만듬)&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl drain &amp;lt;node-to-drain&amp;gt; &lt;span class=&quot;nt&quot;&gt;--ignore-daemonsets&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;apt-mark unhold kubelet kubectl &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;apt-get update &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;kubelet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1.21.1-00 &lt;span class=&quot;nv&quot;&gt;kubectl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1.21.1-00 &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;apt-mark hold kubelet kubectl

&lt;span class=&quot;c&quot;&gt;#설정 수정사항 재로딩&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl daemon-reload
&lt;span class=&quot;c&quot;&gt;#kubelet 재시작&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl restart kubelet

&lt;span class=&quot;c&quot;&gt;#업데이트가 끝났으므로 다시 schedulable하게 만들어주기&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl uncordon &amp;lt;node-to-uncordon&amp;gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;여기까지가 마스터노드의 업그레이드 방법이었습니다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h1 id=&quot;rocket-여기서부터는-워커노드들을-업그레이드-합니다&quot;&gt;:rocket: 여기서부터는 워커노드들을 업그레이드 합니다.&lt;/h1&gt;

&lt;h3 id=&quot;step5---워커-노드에-kubeadm-설치하기&quot;&gt;STEP5 - 워커 노드에 kubeadm 설치하기&lt;/h3&gt;

&lt;p&gt;우선 3개의 워커노드중 하나인 worker-1에 접속합니다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh worker-1 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;그 다음, 마스터노드에 설치했던과 같은방법으로 kubeadm를 설치합니다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;apt-mark unhold kubeadm &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;apt-get update &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;kubeadm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1.21.x-00 &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;apt-mark hold kubeadm
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아까 마스터노드에서 아래의 커맨드를 이용해 upgrade가능 버전을 확인하고 v1.21.1로 apply했었습니다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubeadm upgrade plan
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubeadm upgrade apply v1.21.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;하지만 워커노드에서는 아래의 커맨드를 이용하여 클러스터에서 kubeadm ClusterConfiguration 을 가져오며,
이 노드의 kubelet 구성을 업그레이드 합니다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubeadm upgrade node
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그리고 마스터 노드로 이동하여 업그레이드 할 워커노드를 드레인 해줍니다. (마스터 노드에서 워커노드로 접속했었기에 접속 종료하면 마스터노드로 이동합니다.)&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;exit
logout
&lt;/span&gt;Connection to 10.128.0.5 closed.

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl drain worker-1 &lt;span class=&quot;nt&quot;&gt;--ignore-daemonsets&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step6---워커노드의-kubelet-및-kubectl-업그레이드&quot;&gt;STEP6 - 워커노드의 kubelet 및 kubectl 업그레이드&lt;/h3&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 다시 워커노드로 접속하기&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ssh worker-1
 

&lt;span class=&quot;c&quot;&gt;# kubectl 과 kubelet 업데이트하기&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;apt-mark unhold kubectl kubelet &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;apt-get update &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;kubectl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1.21.1-00 &lt;span class=&quot;nv&quot;&gt;kubelet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1.21.1-00 &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;apt-mark hold kubectl kubelet
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step7---kubelet-다시-시작하기&quot;&gt;STEP7 - kubelet 다시 시작하기&lt;/h3&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl daemon-reload
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl restart kubelet
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step8---cordon-해재하기&quot;&gt;STEP8 - cordon 해재하기&lt;/h3&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#마스터노드로 이동하기&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;exit&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl uncordon worker-1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step9---반복하기&quot;&gt;STEP9 - 반복하기&lt;/h3&gt;

&lt;p&gt;업그레이드 할 워커노드에
STEP5 ~ STEP8을 똑같이 진행해줍니다&lt;/p&gt;

&lt;p&gt;마지막으로 업데이트가 잘 되었는지 확인해줍니다&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get nodes
NAME         STATUS   ROLES                  AGE    VERSION
master       Ready    control-plane,master   6d8h   v1.21.1
worker-1     Ready    &amp;lt;none&amp;gt;                 6d8h   v1.21.1
worker-2     Ready    &amp;lt;none&amp;gt;                 6d8h   v1.21.1
worker-3     Ready    &amp;lt;none&amp;gt;                 6d8h   v1.21.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;버전이 v1.21.1로 잘 업그레이드 된것을 확인할 수 있습니다.&lt;/p&gt;</content><author><name>Sanghyuk Jeong</name><email>shjeong920522@gmail.com</email></author><category term="Kubernetes" /><category term="maintenance" /><category term="static" /><category term="pod" /><category term="strategy" /><category term="쿠버네티스" /><category term="update" /><summary type="html">오늘은 클러스터의 유지보수에 관련한 포스트를 써볼까 합니다. 쿠버네티스를 이용하여 서비스를 구축하고나서 언젠가는 시스템을 업데이트 시켜야할 일이 생길 것이며, 오류로 인하여 노드가 먹통이 되는일도 생길 것입니다. 그렇다면 노드의 작동을 중지시키면, 또는 오류로 중지된다면 어떻게 될까요? master node의 kube-contoller-manager에는 pod-eviction-timeout이 존재합니다 컨디션 각 노드에는 아래와 같이 여러가지 condition이 존재합니다 노드 컨디션 설명 Ready 노드가 상태 양호하며 파드를 수용할 준비가 되어 있는 경우 True, 노드의 상태가 불량하여 파드를 수용하지 못할 경우 False, 그리고 노드 컨트롤러가 마지막 node-monitor-grace-period (기본값 40 기간 동안 노드로부터 응답을 받지 못한 경우) Unknown DiskPressure 디스크 사이즈 상에 압박이 있는 경우, 즉 디스크 용량이 넉넉치 않은 경우 True, 반대의 경우 False MemoryPressure 노드 메모리 상에 압박이 있는 경우, 즉 노드 메모리가 넉넉치 않은 경우 True, 반대의 경우 False PIDPressure 프로세스 상에 압박이 있는 경우, 즉 노드 상에 많은 프로세스들이 존재하는 경우 True, 반대의 경우 False NetworkUnavailable 노드에 대해 네트워크가 올바르게 구성되지 않은 경우 True, 반대의 경우 False 또한 노드 lifecycle controller는 컨디션을 아래와 같은 built-in taint를 자동으로 생성합니다. built-in taints node.kubernetes.io/not-ready: 노드가 준비되지 않음. 이는 NodeCondition Ready 가 “False”로 됨에 해당. node.kubernetes.io/unreachable: 노드가 노드 컨트롤러에서 도달할 수 없음. 이는 NodeCondition Ready 가 “Unknown”로 됨에 해당. node.kubernetes.io/memory-pressure: 노드에 메모리 할당 압박이 있음. node.kubernetes.io/disk-pressure: 노드에 디스크 할당 압박이 있음. node.kubernetes.io/pid-pressure: 노드에 PID 할당 압박이 있음. node.kubernetes.io/network-unavailable: 노드의 네트워크를 사용할 수 없음. node.kubernetes.io/unschedulable: 노드를 스케줄할 수 없음. node.cloudprovider.kubernetes.io/uninitialized: “외부” 클라우드 공급자로 kubelet을 시작하면, 이 테인트가 노드에서 사용 불가능으로 표시되도록 설정됨. 그 중에서도 ready 컨디션은 좀 특별한데요. ready 컨디션의 상태가 pod-eviction-timeout (kube-controller-manager에 전달된 인수) 보다 더 길게 Unknown 또는 False로 유지되는 경우, 노드 상에 모든 파드는 노드 컨트롤러에 의해 삭제되도록 스케줄 됩니다. 클라우드-컨트롤러-관리자의 컨트롤러가 이 노드를 초기화하면, kubelet이 이 테인트를 제거합니다 즉 다시 pod가 배정될 수 있는 상태가 되는것이죠. 기본 축출 타임아웃 기간은 기본 5분으로 설정되어 있습니다. 만약 노드가 다운되었다가 5분안에 복구가 되었다면 노드 내의 pod들은 그대로 존재하지만, 설정된 타임아웃 시간을 초과한다면 그안의 파드들은 모두 중단 되는것입니다. 만약 수정하고 싶다면 마스터 노드의 kube-system 네임스페이스에 있는 kube-controller-manager-master을 edit해주면됩니다. 그런데 말이죠 이 pod는 static pod입니다. 6번째 포스트에서 설명 했었는데 static pod 를 수정하려면 static pod을 생성한 yaml파일 자체를 수정한다고 했었죠? static pod의 위치를 찾는것 부터 복습해봅시다 우선 config.yaml파일의 위치를 찾아줍니다. $ ps -ef | grep kubelet | grep &quot;\--config&quot; root 10476 1 3 May28 ? 05:09:26 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --network-plugin=cni --pod-infra-container-image=k8s.gcr.io/pause:3.4.1 config.yaml파일 내에서 staticpath를 찾아냅시다 $ sudo grep -i static /var/lib/kubelet/config.yaml staticPodPath: /etc/kubernetes/manifests staticPodPath로 이동후 뭐가있나 확인해봅니다. $ cd /etc/kubernetes/manifests $ ls etcd.yaml kube-apiserver.yaml kube-controller-manager.yaml kube-scheduler.yaml 자 이제 이 yaml파일을 수정하면 됩니다. 저는 이 기본 5분인 eviction-timeout을 60초로 바꾸어 보겠습니다. command에 --pod-eviction-timeout=60s 옵션을 추가해 줌으로써 말이죠. apiVersion: v1 kind: Pod metadata: annotations: kubernetes.io/config.hash: 47cace34a635d6f3e305eee20e0e7b30 kubernetes.io/config.mirror: 47cace34a635d6f3e305eee20e0e7b30 kubernetes.io/config.seen: &quot;2021-05-28T03:40:42.961803243Z&quot; kubernetes.io/config.source: file creationTimestamp: &quot;2021-05-28T03:40:55Z&quot; labels: component: kube-controller-manager tier: control-plane name: kube-controller-manager-master namespace: kube-system ownerReferences: - apiVersion: v1 controller: true kind: Node name: master uid: 69f4d243-9420-45a9-928e-672a1d3b977a resourceVersion: &quot;478&quot; uid: 4cfad35d-8664-42cf-9ed9-5fd5b4d771a4 spec: containers: - command: - kube-controller-manager - --allocate-node-cidrs=true - --pod-eviction-timeout=60s #&amp;lt;----------- 해당라인을 추가하면 이제 5분이아닌 60초로 변경됩니다. - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf - --bind-address=127.0.0.1 - --client-ca-file=/etc/kubernetes/pki/ca.crt - --cluster-cidr=10.244.0.0/16 - --cluster-name=kubernetes - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key - --controllers=*,bootstrapsigner,tokencleaner - --kubeconfig=/etc/kubernetes/controller-manager.conf - --leader-elect=true - --port=0 - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt - --root-ca-file=/etc/kubernetes/pki/ca.crt - --service-account-private-key-file=/etc/kubernetes/pki/sa.key - --service-cluster-ip-range=10.96.0.0/12 - --use-service-account-credentials=true image: k8s.gcr.io/kube-controller-manager:v1.21.1 ...중략 저장해주면 멈췄다가 kube-controller-manager-master 0/1 Running 0 3s 옵션을 적용시켜 pod시 재시동됩니다~ kube-controller-manager-master 1/1 Running 0 3s eviction timeout의 존재이유? 위에서 eviction timeout의 값을 바꾸는 실습을 해보았는데요 이 timeout은 무엇과 연관이 있는지 두가지 케이스를 통해서 알아보겠습니다. case1: node가 먹통이 되었다가 설정해놓은 eviction-timeout보다 짦은시간안에 복구된경우 노드내에 있던 pod들이 kubectl에 의해 다시 해당노드에서 재시작됩니다. case2: node가 먹통이 된후 eviction-timeout을 초과한경우 해당 노드에있는 pod들을 모두 축출한 후에 노드가 재시동됩니다. 해당 노드에있던 pod이 replicaset을 통해 생성되었다면 다시 다른노드에 잘 생성이 되겠지만, 일반 pod이라면 다시 살아나지 못할겁니다. 노드관련 명령어 kubectl drain node $ kubectl drain node 해당 노드에있는 pod들을 종료시키고, 다른노드에 재시작시킵니다 (graceful node shutdown) 또한 해당 노드를 unschedulable하게 만든다. kubernetes의 버전 또는 리눅스 커널등의 업그레이드할 때 사용할 수 있겠습니다(kubeadm, kubelet, kubectl, …) kubectl cordon node $ kubectl cordon node 해당 노드를 unschedulable하게 만듭니다 실행 중인 Pod를 축출하지는 않습니다 kubectl uncordon node $ kubectl uncordon node 해당 노드를 schedulable하게 만든다 업그레이드를 마친 노드를 스케쥴러블하게 만듭니다 (taint를 제거) drain명령에 의해서 집나간 pod들이 다시 집을 찾아오진 않습니다. 쿠버네티스 버전 및 버전차이 지원 버전 쿠버네티스 버전은 x.y.z로 표현되는데, 여기서 x는 메이저 버전, y는 마이너 버전, z는 시맨틱 버전 용어에 따른 패치 버전입니다. kubernetes에는 여러가지 컴포넌트가 있습니다. 각각의 버전은 전부 동일해야할까요? 아닙니다. kube-apiserver의 버전이 주축이되고, 나머지 컴포넌트는 각각 다르게 한 두단계 버전이 낮거나 같아도 상관이 없습니다. 특별하게 kubectl의 경우는 kube-apiserver의 버전보다 한단계 높은경우도 지원이 됩니다. 더 자세한 내용은 공식문서에서 확인가능 합니다 클러스터 업그레이드 kubernets는 latest버전부터 두단계 낮은버전까지 서비스를 지원하는데요, 만약에 현재 1.19버전을 사용하고 있는데 1.22버전이 출시 된다면 업그레이드를 해야겠죠. 그렇다면 1.19버전에서 한번에 1.22번으로 업그레이드 시키면될까요? 추천되는 방법에 의하면 한단계 한단계씩 차례차례로 업그레이드 해야된다고 합니다. 업그레이드 방법 쿠버네티스 환경을 어떻게 구성하였는가에 따라 업그레이드 방법이 다양합니다. 구글의 GKE, AWS의 EKS등의 kubernete를 지원하는 cloud의 경우 간단한 클릭 몇번으로 업그레이드 가능 The hard way로 설치한경우 한땀한땀 설치한 것처럼 업그레이드 또한 한땀한땀 해야합니다 저는 kubeadm을 이용하여 kubernetes환경을 구축하였고, kubeadm을 통한 업그레이드 방법에 대해 자세히 설명해 보겠습니다. 저의 쿠버네티스 환경은 한개의 master노드, 3개의 worker노드로 구성되어있습니다. 1.20버전을 이용하고 있는데 1.21버전으로 업그레이드 해보겠습니다. STEP1 - 마스터 노드에 kubeadm 업그레이드 시키기. 마스터 노드에 접속합니다 $ ssh gcloud ssh config에 설정을 해놨기에 이렇게 간단하게 접속가능합니다. ssh config 설정방법이 궁금하시면 여기로 이동하세요. 그리고 kubernetes환경을 구축할때 hold시켜놨었던 kubeadm을 unhold시켜주고, apt-get 색인 업데이트후, kubeadm을 업데이트 한다음 다시 kubeadm을 hold시켜 줄겁니다. # 1.21.x-00에서 x를 최신 패치 버전으로 바꿉니다 apt-mark unhold kubeadm &amp;amp;&amp;amp; \ apt-get update &amp;amp;&amp;amp; apt-get install -y kubeadm=1.21.x-00 &amp;amp;&amp;amp; \ apt-mark hold kubeadm #버전 확인해주기 $ kubeadm version kubeadm version: &amp;amp;version.Info{Major:&quot;1&quot;, Minor:&quot;21&quot;, GitVersion:&quot;v1.21.1&quot;, GitCommit:&quot;5e58841cce77d4bc13713ad2b91fa0d961e69192&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2021-05-12T14:17:27Z&quot;, GoVersion:&quot;go1.16.4&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;} apt-mark unhold와 apt-mark hold 해주는 이유는 kubeadm을 업그레이드하면 설치시 kubelet과 같은 다른 구성 요소가 기본적으로 최신 버전 으로 자동으로 업그레이드되기 때문입니다. (kubernetes는 여러버전을 한꺼번에 업그레이드 권장하지 않기때문입니다!) 이를 해결하기 위해 보류를 사용하여 패키지를 보류 된 것으로 표시하여 패키지가 자동으로 설치, 업그레이드 또는 제거되지 않도록합니다. STEP2 - 업그레이드 정보 확인하기 $ kubeadm upgrade plan ... COMPONENT CURRENT AVAILABLE API Server v1.20.0 v1.21.1 Controller Manager v1.20.0 v1.21.1 Scheduler v1.20.0 v1.21.1 Kube Proxy v1.20.0 v1.21.1 ... STEP3 - 업그레이드 적용시키기 $ kubeadm upgrade plan apply v1.21.1 (조금 오래걸릴 수도 있습니다) 아래와같이뜨면 성공 [upgrade/successful] SUCCESS! Your cluster was upgraded to &quot;v1.21.1&quot;. Enjoy! [upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven&apos;t already done so. STEP4 - node drain후 kubelet, kubectl 업데이트후 재시작하기 #노드 드레인하기(모든 pod 종료후 다른노드에 새로 실행하기 및 해당노드 unschedulable하게 만듬) $ kubectl drain &amp;lt;node-to-drain&amp;gt; --ignore-daemonsets $ apt-mark unhold kubelet kubectl &amp;amp;&amp;amp; \ $ apt-get update &amp;amp;&amp;amp; apt-get install -y kubelet=1.21.1-00 kubectl=1.21.1-00 &amp;amp;&amp;amp; \ $ apt-mark hold kubelet kubectl #설정 수정사항 재로딩 $ sudo systemctl daemon-reload #kubelet 재시작 $ sudo systemctl restart kubelet #업데이트가 끝났으므로 다시 schedulable하게 만들어주기 $ kubectl uncordon &amp;lt;node-to-uncordon&amp;gt; 여기까지가 마스터노드의 업그레이드 방법이었습니다. :rocket: 여기서부터는 워커노드들을 업그레이드 합니다. STEP5 - 워커 노드에 kubeadm 설치하기 우선 3개의 워커노드중 하나인 worker-1에 접속합니다. ssh worker-1 그 다음, 마스터노드에 설치했던과 같은방법으로 kubeadm를 설치합니다. $ apt-mark unhold kubeadm &amp;amp;&amp;amp; \ $ apt-get update &amp;amp;&amp;amp; apt-get install -y kubeadm=1.21.x-00 &amp;amp;&amp;amp; \ $ apt-mark hold kubeadm 아까 마스터노드에서 아래의 커맨드를 이용해 upgrade가능 버전을 확인하고 v1.21.1로 apply했었습니다. $ kubeadm upgrade plan $ kubeadm upgrade apply v1.21.1 하지만 워커노드에서는 아래의 커맨드를 이용하여 클러스터에서 kubeadm ClusterConfiguration 을 가져오며, 이 노드의 kubelet 구성을 업그레이드 합니다. $ kubeadm upgrade node 그리고 마스터 노드로 이동하여 업그레이드 할 워커노드를 드레인 해줍니다. (마스터 노드에서 워커노드로 접속했었기에 접속 종료하면 마스터노드로 이동합니다.) $ exit logout Connection to 10.128.0.5 closed. $ kubectl drain worker-1 --ignore-daemonsets STEP6 - 워커노드의 kubelet 및 kubectl 업그레이드 # 다시 워커노드로 접속하기 $ ssh worker-1 # kubectl 과 kubelet 업데이트하기 $ apt-mark unhold kubectl kubelet &amp;amp;&amp;amp; \ $ apt-get update &amp;amp;&amp;amp; apt-get install -y kubectl=1.21.1-00 kubelet=1.21.1-00 &amp;amp;&amp;amp; \ $ apt-mark hold kubectl kubelet STEP7 - kubelet 다시 시작하기 $ sudo systemctl daemon-reload $ sudo systemctl restart kubelet STEP8 - cordon 해재하기 #마스터노드로 이동하기 $ exit $ kubectl uncordon worker-1 STEP9 - 반복하기 업그레이드 할 워커노드에 STEP5 ~ STEP8을 똑같이 진행해줍니다 마지막으로 업데이트가 잘 되었는지 확인해줍니다 $ kubectl get nodes NAME STATUS ROLES AGE VERSION master Ready control-plane,master 6d8h v1.21.1 worker-1 Ready &amp;lt;none&amp;gt; 6d8h v1.21.1 worker-2 Ready &amp;lt;none&amp;gt; 6d8h v1.21.1 worker-3 Ready &amp;lt;none&amp;gt; 6d8h v1.21.1 버전이 v1.21.1로 잘 업그레이드 된것을 확인할 수 있습니다.</summary></entry><entry><title type="html">[ #7 ] 배포 전략</title><link href="https://shjeong92.github.io/2021/06/02/Learning-Kubernetes-07.html" rel="alternate" type="text/html" title="[ #7 ] 배포 전략" /><published>2021-06-02T00:00:00+09:00</published><updated>2021-06-02T00:00:00+09:00</updated><id>https://shjeong92.github.io/2021/06/02/Learning-Kubernetes-07</id><content type="html" xml:base="https://shjeong92.github.io/2021/06/02/Learning-Kubernetes-07.html">&lt;p&gt;쿠버네티스에는아래 그림과 같이 두가지 배포방법이 있습니다&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/75003424/120428975-9582c300-c3af-11eb-95cf-ba8825576440.png&quot; alt=&quot;deplstrategy&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;recreate&quot;&gt;Recreate&lt;/h2&gt;
&lt;p&gt;Recreate 방식은 이전버전 A를 종료시킨후 신규버전 B를 롤아웃 시키는 방식입니다.&lt;/p&gt;

&lt;h3 id=&quot;pros&quot;&gt;pros&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;가장 쉬운 배포방법&lt;/li&gt;
  &lt;li&gt;클라우드 리소스 비요이 적음&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;cons&quot;&gt;cons&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;A가 중지되고 B가 배포되기전까지 서비스가 중단되어 사용자에게 악영향을 줌&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rolling-update&quot;&gt;Rolling Update&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;기존서버를 순차적으로 중지시키며 순차적으로 업그레이드 시키는 방식으로, kubernetes에서 spec.strategy.type을 지정하지 않으면 기본적으로 RollingUpdate를 사용합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;처음 쿠버네티스에 입문하였을때 replicaset과, deployment의 차이점은 yaml파일로만 놓고 봤을때는 다른점이 kind 부분 말고는 없었습니다. 똑같이 파드를 적정갯수 만큼 생성해주고, crash되면 다시 복구시켜주는 점에서는 말이죠.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;오늘은 배포방식에 대해 공부하면서 왜 deployment를 사용하여 pod을 배포하는가에 대한 궁금증을 풀 수 있었습니다.&lt;/p&gt;

&lt;p&gt;Deployment를 사용하여 pod을 배포 하게되면 롤아웃을 생성합니다. 그리고 이 롤아웃은 새로운 배포 버전(revision)을 생성합니다. 이말이 잘 이해가 안 되실수도 있는데&lt;/p&gt;

&lt;p&gt;자세한 설명은 실습을 진행하면서 하도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;아래와같이 deployment definition을 작성한 yaml파일이 있습니다.&lt;/p&gt;
&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#depl.yaml&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;apps/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Deployment&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp-deployment&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;front-end&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp-pod&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;front-end&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-container&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;replicas&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;selector&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;matchLabels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;front-end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아래의 명령어를 사용하여 deployment를 생성하게되면&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl apply &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; depl.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;myapp-deployment라는 이름을가진 deployment와, myapp-deployment-hash값 을 가진 replicaset, 그리고 deployment를 통해 생성된 replicaset에 의해 생성된 pod을 확인할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl get all
NAME                                    READY   STATUS    RESTARTS   AGE
pod/myapp-deployment-7df67f74c5-4nkmq   1/1     Running   0          5m27s
pod/myapp-deployment-7df67f74c5-bnl9r   1/1     Running   0          5m27s
pod/myapp-deployment-7df67f74c5-jsd9p   1/1     Running   0          5m27s

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;S&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;   AGE
service/kubernetes   ClusterIP   10.96.0.1    &amp;lt;none&amp;gt;        443/TCP   5d2h

NAME                               READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/myapp-deployment   3/3     3            3           5m27s

NAME                                          DESIRED   CURRENT   READY   AGE
replicaset.apps/myapp-deployment-7df67f74c5   3         3         3       5m27s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아직까지는 별 차이가 없지요, deployment가 생겼다는것 외에는 말입니다.&lt;/p&gt;

&lt;p&gt;하지만 사실은 이외에도 &lt;code&gt;revision&lt;/code&gt;이라는 것을 생성합니다.&lt;/p&gt;

&lt;p&gt;이는 해당 deployment를 업데이트 할때마다 생기고, 이전 &lt;code&gt;revision&lt;/code&gt;의 정보도 가집니다. 또한, 새로운 버전의 &lt;code&gt;replicaset&lt;/code&gt;을 생성하고, 이전버전의 &lt;code&gt;replicaset&lt;/code&gt;의 정보를 남겨놓습니다.&lt;/p&gt;

&lt;p&gt;만약에 업데이트후에 문제가 생겼을시에 롤백을 가능케 하기 위해서 입니다. 그리고 이러한점이 &lt;strong&gt;deployment&lt;/strong&gt;를 사용해서 pod을 배포했을때랑 &lt;strong&gt;replicaset&lt;/strong&gt;을 사용했을때의 가장 큰 차이점이 아닐까 싶습니다.&lt;/p&gt;

&lt;h2 id=&quot;rollout-상태확인&quot;&gt;Rollout 상태확인&lt;/h2&gt;

&lt;p&gt;deployment를 사용하여 pod을 배포하게되면 rollout을 생성한다고 했었는데 
추가로 사용할 수 있는 커맨드도 생깁니다. &lt;code&gt;rollout&lt;/code&gt; 이라는 커맨드인데요.&lt;/p&gt;

&lt;p&gt;rollout 커맨드를 통하여 deployment의 revision및 history를 확인할 수 있습니다&lt;/p&gt;

&lt;p&gt;&lt;code&gt; kubectl rollout status deployment &lt;/code&gt; 커맨드를 사용하여 다음과 같이 롤아웃 생성의 상태를 확인할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl rollout status deployment/myapp-deployment
Waiting &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;deployment &lt;span class=&quot;s2&quot;&gt;&quot;myapp-deployment&quot;&lt;/span&gt; rollout to finish: 0 of 3 updated replicas are available...
Waiting &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;deployment &lt;span class=&quot;s2&quot;&gt;&quot;myapp-deployment&quot;&lt;/span&gt; rollout to finish: 1 of 3 updated replicas are available...
Waiting &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;deployment &lt;span class=&quot;s2&quot;&gt;&quot;myapp-deployment&quot;&lt;/span&gt; rollout to finish: 2 of 3 updated replicas are available...
deployment &lt;span class=&quot;s2&quot;&gt;&quot;myapp-deployment&quot;&lt;/span&gt; successfully rolled out
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;rollout-history-확인&quot;&gt;Rollout history 확인&lt;/h2&gt;

&lt;p&gt;또한 &lt;code&gt; kubectl rollout history deployment &lt;/code&gt; 커맨드를 사용하면 아래와 같이 리비전 정보를 확인할 수 있는데요&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl rollout &lt;span class=&quot;nb&quot;&gt;history &lt;/span&gt;deploy/myapp-deployment
deployment.apps/myapp-deployment 
REVISION  CHANGE-CAUSE
1         &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;하나의 revision 밖에 보이지않습니다. 그 이유는 depl.yaml을 이용하여 처음으로 배포한 버전이기 때문입니다.&lt;/p&gt;

&lt;h2 id=&quot;rollout-update&quot;&gt;Rollout update&lt;/h2&gt;
&lt;p&gt;해당 deployment를 업데이트하면 어떤일이 생기는지 보도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;우선 yaml파일을 수정해줍니다&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#depl.yaml&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;apps/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Deployment&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp-deployment&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;front-end&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp-pod&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;front-end&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-container&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx:1.20-alpine       &amp;lt;----- 바뀐부분&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;replicas&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;selector&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;matchLabels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;front-end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;이미지를 바꿀때에는 간단하게 set image를 통해서도 가능하지만 개인적으로 변경상황을 이력으로 남기는게 좋다고 생각하여 해당 방법을 사용합니다.&lt;/p&gt;

&lt;p&gt;변경사항을 적용시켜줍니다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl apply &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; depl.yaml
deployment.apps/myapp-deployment configured
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그다음 replicaset과 revision을 확인해봅시다&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get rs
NAME                          DESIRED   CURRENT   READY   AGE
myapp-deployment-79896f8f68   3         3         3       5m14s
myapp-deployment-7df67f74c5   0         0         0       5m42s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;replicaset이 하나더 생겼으며,&lt;/p&gt;

&lt;p&gt;revision도 하나더 생긴것을 확인할 수 있습니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kubectl rollout history deploy myapp-deployment
deployment.apps/myapp-deployment 
REVISION  CHANGE-CAUSE
2         &amp;lt;none&amp;gt;
1         &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;하지만 change-cause가 None 으로 되있으면 무엇이 바뀌었는지 알 수 가없는데, 아래 커맨드를 이용하면 따로 설정이 가능합니다.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl annotate deployment.v1.apps/[deployment name] kubernetes.io/change-cause=&quot;reason of update&quot;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;해당커맨드를 사용하여 주석을 달고 다시 확인해봅시다&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl annotate deployment.v1.apps/myapp-deployment kubernetes.io/change-cause&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;image updated to 1.20&quot;&lt;/span&gt;
deployment.apps/myapp-deployment annotated


&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl rollout &lt;span class=&quot;nb&quot;&gt;history &lt;/span&gt;deployment myapp-deployment
deployment.apps/myapp-deployment 
REVISION  CHANGE-CAUSE
1         &amp;lt;none&amp;gt;
2         image updated to 1.20
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;주석이 잘 달린것을 확인할 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;rollback&quot;&gt;Rollback&lt;/h2&gt;
&lt;p&gt;만약에 새로운 버전으로 업데이트를 했는데 문제가 생겼을때 이전 버전 으로 돌아갈 수 있는 기능입니다.&lt;/p&gt;

&lt;p&gt;&lt;code&gt; kubeclt rollout undo deployment &lt;/code&gt;커맨드를 사용하여 롤백 시킬 수 있습니다.&lt;/p&gt;

&lt;p&gt;직접 실습해봅시다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl rollout undo deployment myapp-deployment
deployment.apps/myapp-deployment rolled back
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;성공적으로 롤백 되었다고 뜹니다.&lt;/p&gt;

&lt;p&gt;우선 image가 다시 원래대로 돌아왔는지 확인해봅니다&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl describe deployment myapp-deployment
Name:                   myapp-deployment
Namespace:              default
CreationTimestamp:      Wed, 02 Jun 2021 07:05:06 +0000
Labels:                 &lt;span class=&quot;nv&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;myapp
                        &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;front-end
Annotations:            deployment.kubernetes.io/revision: 3
                        kubernetes.io/change-cause: 
Selector:               &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;front-end
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  &lt;span class=&quot;nv&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;myapp
           &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;front-end
  Containers:
   nginx-container:
    Image:        nginx          &amp;lt;&lt;span class=&quot;nt&quot;&gt;-------&lt;/span&gt; 1.20 에서 다시 원래대로 돌아온것을 확인할 수 있습니다.
    Port:         &amp;lt;none&amp;gt;
    Host Port:    &amp;lt;none&amp;gt;
    Environment:  &amp;lt;none&amp;gt;
    Mounts:       &amp;lt;none&amp;gt;
  Volumes:        &amp;lt;none&amp;gt;
Conditions:
  Type           Status  Reason
  &lt;span class=&quot;nt&quot;&gt;----&lt;/span&gt;           &lt;span class=&quot;nt&quot;&gt;------&lt;/span&gt;  &lt;span class=&quot;nt&quot;&gt;------&lt;/span&gt;
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  &amp;lt;none&amp;gt;
NewReplicaSet:   myapp-deployment-7df67f74c5 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;3/3 replicas created&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Events:
  Type    Reason             Age                  From                   Message
  &lt;span class=&quot;nt&quot;&gt;----&lt;/span&gt;    &lt;span class=&quot;nt&quot;&gt;------&lt;/span&gt;             &lt;span class=&quot;nt&quot;&gt;----&lt;/span&gt;                 &lt;span class=&quot;nt&quot;&gt;----&lt;/span&gt;                   &lt;span class=&quot;nt&quot;&gt;-------&lt;/span&gt;
  Normal  ScalingReplicaSet  23m                  deployment-controller  Scaled up replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-79896f8f68 to 1
  Normal  ScalingReplicaSet  23m                  deployment-controller  Scaled down replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-7df67f74c5 to 2
  Normal  ScalingReplicaSet  23m                  deployment-controller  Scaled up replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-79896f8f68 to 2
  Normal  ScalingReplicaSet  23m                  deployment-controller  Scaled down replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-7df67f74c5 to 1
  Normal  ScalingReplicaSet  23m                  deployment-controller  Scaled up replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-79896f8f68 to 3
  Normal  ScalingReplicaSet  23m                  deployment-controller  Scaled down replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-7df67f74c5 to 0
  Normal  ScalingReplicaSet  4m28s                deployment-controller  Scaled up replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-7df67f74c5 to 1
  Normal  ScalingReplicaSet  4m24s                deployment-controller  Scaled down replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-79896f8f68 to 2
  Normal  ScalingReplicaSet  4m24s                deployment-controller  Scaled up replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-7df67f74c5 to 2
  Normal  ScalingReplicaSet  4m20s &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x2 over 24m&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;  deployment-controller  Scaled up replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-7df67f74c5 to 3
  Normal  ScalingReplicaSet  4m20s                deployment-controller  Scaled down replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-79896f8f68 to 1
  Normal  ScalingReplicaSet  4m16s                deployment-controller  Scaled down replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-79896f8f68 to 0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그럼 replicaset과 revision은 어떨까요?&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#이미지 1.20으로 업데이트후 replicaset 상태&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get rs
NAME                          DESIRED   CURRENT   READY   AGE
myapp-deployment-79896f8f68   3         3         3       5m14s
myapp-deployment-7df67f74c5   0         0         0       5m42s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#롤백후 replicaset상태&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get rs
NAME                          DESIRED   CURRENT   READY   AGE
myapp-deployment-79896f8f68   0         0         0       25m
myapp-deployment-7df67f74c5   3         3         3       26m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;revision&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl rollout &lt;span class=&quot;nb&quot;&gt;history &lt;/span&gt;deployment myapp-deployment
deployment.apps/myapp-deployment 
REVISION  CHANGE-CAUSE
2         image updated to 1.20
3         &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;replicaset은 이전 버전의 replicaset으로 바뀐것을 확인할 수가 있는데 revision은 1로돌아가는것이아닌 1이 증가한 것을 확인할 수 있습니다.
여기서 궁금한점이 생겼습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;undo를 여러번하면 어떻게될까요?&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl rollout &lt;span class=&quot;nb&quot;&gt;history &lt;/span&gt;deployment myapp-deployment
deployment.apps/myapp-deployment 
REVISION  CHANGE-CAUSE
3         &amp;lt;none&amp;gt;
4         image updated to 1.20
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;결과&quot;&gt;결과&lt;/h3&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl describe deployment myapp-deployment
Name:                   myapp-deployment
Namespace:              default
CreationTimestamp:      Wed, 02 Jun 2021 07:05:06 +0000
Labels:                 &lt;span class=&quot;nv&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;myapp
                        &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;front-end
Annotations:            deployment.kubernetes.io/revision: 4
                        kubernetes.io/change-cause: image updated to 1.20
Selector:               &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;front-end
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  &lt;span class=&quot;nv&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;myapp
           &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;front-end
  Containers:
   nginx-container:
    Image:        nginx:1.20
    Port:         &amp;lt;none&amp;gt;
    Host Port:    &amp;lt;none&amp;gt;
    Environment:  &amp;lt;none&amp;gt;
    Mounts:       &amp;lt;none&amp;gt;
  Volumes:        &amp;lt;none&amp;gt;
Conditions:
  Type           Status  Reason
  &lt;span class=&quot;nt&quot;&gt;----&lt;/span&gt;           &lt;span class=&quot;nt&quot;&gt;------&lt;/span&gt;  &lt;span class=&quot;nt&quot;&gt;------&lt;/span&gt;
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  &amp;lt;none&amp;gt;
NewReplicaSet:   myapp-deployment-79896f8f68 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;3/3 replicas created&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
Events:
  Type    Reason             Age                  From                   Message
  &lt;span class=&quot;nt&quot;&gt;----&lt;/span&gt;    &lt;span class=&quot;nt&quot;&gt;------&lt;/span&gt;             &lt;span class=&quot;nt&quot;&gt;----&lt;/span&gt;                 &lt;span class=&quot;nt&quot;&gt;----&lt;/span&gt;                   &lt;span class=&quot;nt&quot;&gt;-------&lt;/span&gt;
  Normal  ScalingReplicaSet  14m                  deployment-controller  Scaled up replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-7df67f74c5 to 1
  Normal  ScalingReplicaSet  14m                  deployment-controller  Scaled down replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-79896f8f68 to 2
  Normal  ScalingReplicaSet  14m                  deployment-controller  Scaled up replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-7df67f74c5 to 2
  Normal  ScalingReplicaSet  14m &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x2 over 33m&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;    deployment-controller  Scaled up replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-7df67f74c5 to 3
  Normal  ScalingReplicaSet  14m                  deployment-controller  Scaled down replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-79896f8f68 to 1
  Normal  ScalingReplicaSet  13m                  deployment-controller  Scaled down replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-79896f8f68 to 0
  Normal  ScalingReplicaSet  2m13s &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x2 over 33m&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;  deployment-controller  Scaled up replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-79896f8f68 to 1
  Normal  ScalingReplicaSet  2m9s &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x2 over 33m&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;   deployment-controller  Scaled down replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-7df67f74c5 to 2
  Normal  ScalingReplicaSet  2m9s &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x2 over 33m&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;   deployment-controller  Scaled up replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-79896f8f68 to 2
  Normal  ScalingReplicaSet  2m5s &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x2 over 33m&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;   deployment-controller  Scaled down replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-7df67f74c5 to 1
  Normal  ScalingReplicaSet  2m5s &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x2 over 33m&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;   deployment-controller  Scaled up replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-79896f8f68 to 3
  Normal  ScalingReplicaSet  2m1s &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;x2 over 33m&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;   deployment-controller  Scaled down replica &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;myapp-deployment-7df67f74c5 to 0

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;undo 를 여러번하니 nginx &amp;lt;-&amp;gt; nginx:1.20 왔다 갔다 하는 모습을 보여줍니다.&lt;/p&gt;

&lt;h2 id=&quot;rocket-history&quot;&gt;:rocket: history&lt;/h2&gt;
&lt;p&gt;history를 보아도 두줄의 결과만 보여주기도했고, 정말 바로 이전단계까지만 이동할 수 있는건지도 궁금했습니다.&lt;/p&gt;

&lt;p&gt;궁금한건 못참기에 바로 kubernetes.io를 찾다보니 원하는 revision으로 가려면 &lt;strong&gt;–to-revision=[resion-number]&lt;/strong&gt; 를 입력해야되는것을 알 수 있었습니다.&lt;/p&gt;

&lt;p&gt;deployment 의 spec 밑에 revisionHistoryLimit: 10 으로 설정되어 있는것도 확인했으며 이 또한 수정할 수 있었군요 ㅎㅎ&lt;/p&gt;

&lt;p&gt;바로 이전 단계만 이동 가능하다고 포스트 올렸다가 호다닥 수정하네요&lt;/p&gt;

&lt;p&gt;그나저나 history에는 왜 사람 햇갈리게 두줄만을 보여줬던 걸까요?&lt;/p&gt;

&lt;p&gt;kubernetes는 상당히 &lt;strong&gt;똑똑했기&lt;/strong&gt; 때문입니다.&lt;/p&gt;

&lt;p&gt;이미 기억하고있는 replicaset랑 다름이 없기에 새로운 replicaset을 생성하지 않는것이었습니다.&lt;/p&gt;

&lt;p&gt;history에 없는 다른 버전의 nginx의 이미지로 바꾸어주니 replicaset과 history 각각 하나씩 더 생기는것을 확인할 수 있었습니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get rs
NAME                          DESIRED   CURRENT   READY   AGE
myapp-deployment-54d59f8648   3         3         3       17m
myapp-deployment-79896f8f68   0         0         0       117m
myapp-deployment-7df67f74c5   0         0         0       118m

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl rollout &lt;span class=&quot;nb&quot;&gt;history &lt;/span&gt;deploy myapp-deployment
deployment.apps/myapp-deployment 
REVISION  CHANGE-CAUSE
3         image updated to 1.20
4         &amp;lt;none&amp;gt;
5         &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Sanghyuk Jeong</name><email>shjeong920522@gmail.com</email></author><category term="Docker" /><category term="Kubernetes" /><category term="Replicasets" /><category term="Deployment" /><category term="static" /><category term="pod" /><category term="strategy" /><category term="쿠버네티스" /><category term="rolling" /><category term="update" /><summary type="html">쿠버네티스에는아래 그림과 같이 두가지 배포방법이 있습니다 Recreate Recreate 방식은 이전버전 A를 종료시킨후 신규버전 B를 롤아웃 시키는 방식입니다. pros 가장 쉬운 배포방법 클라우드 리소스 비요이 적음 cons A가 중지되고 B가 배포되기전까지 서비스가 중단되어 사용자에게 악영향을 줌 Rolling Update 기존서버를 순차적으로 중지시키며 순차적으로 업그레이드 시키는 방식으로, kubernetes에서 spec.strategy.type을 지정하지 않으면 기본적으로 RollingUpdate를 사용합니다. 처음 쿠버네티스에 입문하였을때 replicaset과, deployment의 차이점은 yaml파일로만 놓고 봤을때는 다른점이 kind 부분 말고는 없었습니다. 똑같이 파드를 적정갯수 만큼 생성해주고, crash되면 다시 복구시켜주는 점에서는 말이죠. 오늘은 배포방식에 대해 공부하면서 왜 deployment를 사용하여 pod을 배포하는가에 대한 궁금증을 풀 수 있었습니다. Deployment를 사용하여 pod을 배포 하게되면 롤아웃을 생성합니다. 그리고 이 롤아웃은 새로운 배포 버전(revision)을 생성합니다. 이말이 잘 이해가 안 되실수도 있는데 자세한 설명은 실습을 진행하면서 하도록 하겠습니다. 아래와같이 deployment definition을 작성한 yaml파일이 있습니다. #depl.yaml apiVersion: apps/v1 kind: Deployment metadata: name: myapp-deployment labels: app: myapp type: front-end spec: template: metadata: name: myapp-pod labels: app: myapp type: front-end spec: containers: - name: nginx-container image: nginx replicas: 3 selector: matchLabels: type: front-end 아래의 명령어를 사용하여 deployment를 생성하게되면 kubectl apply -f depl.yaml myapp-deployment라는 이름을가진 deployment와, myapp-deployment-hash값 을 가진 replicaset, 그리고 deployment를 통해 생성된 replicaset에 의해 생성된 pod을 확인할 수 있습니다. kubectl get all NAME READY STATUS RESTARTS AGE pod/myapp-deployment-7df67f74c5-4nkmq 1/1 Running 0 5m27s pod/myapp-deployment-7df67f74c5-bnl9r 1/1 Running 0 5m27s pod/myapp-deployment-7df67f74c5-jsd9p 1/1 Running 0 5m27s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.96.0.1 &amp;lt;none&amp;gt; 443/TCP 5d2h NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/myapp-deployment 3/3 3 3 5m27s NAME DESIRED CURRENT READY AGE replicaset.apps/myapp-deployment-7df67f74c5 3 3 3 5m27s 아직까지는 별 차이가 없지요, deployment가 생겼다는것 외에는 말입니다. 하지만 사실은 이외에도 revision이라는 것을 생성합니다. 이는 해당 deployment를 업데이트 할때마다 생기고, 이전 revision의 정보도 가집니다. 또한, 새로운 버전의 replicaset을 생성하고, 이전버전의 replicaset의 정보를 남겨놓습니다. 만약에 업데이트후에 문제가 생겼을시에 롤백을 가능케 하기 위해서 입니다. 그리고 이러한점이 deployment를 사용해서 pod을 배포했을때랑 replicaset을 사용했을때의 가장 큰 차이점이 아닐까 싶습니다. Rollout 상태확인 deployment를 사용하여 pod을 배포하게되면 rollout을 생성한다고 했었는데 추가로 사용할 수 있는 커맨드도 생깁니다. rollout 이라는 커맨드인데요. rollout 커맨드를 통하여 deployment의 revision및 history를 확인할 수 있습니다 kubectl rollout status deployment 커맨드를 사용하여 다음과 같이 롤아웃 생성의 상태를 확인할 수 있습니다. $ kubectl rollout status deployment/myapp-deployment Waiting for deployment &quot;myapp-deployment&quot; rollout to finish: 0 of 3 updated replicas are available... Waiting for deployment &quot;myapp-deployment&quot; rollout to finish: 1 of 3 updated replicas are available... Waiting for deployment &quot;myapp-deployment&quot; rollout to finish: 2 of 3 updated replicas are available... deployment &quot;myapp-deployment&quot; successfully rolled out Rollout history 확인 또한 kubectl rollout history deployment 커맨드를 사용하면 아래와 같이 리비전 정보를 확인할 수 있는데요 $ kubectl rollout history deploy/myapp-deployment deployment.apps/myapp-deployment REVISION CHANGE-CAUSE 1 &amp;lt;none&amp;gt; 하나의 revision 밖에 보이지않습니다. 그 이유는 depl.yaml을 이용하여 처음으로 배포한 버전이기 때문입니다. Rollout update 해당 deployment를 업데이트하면 어떤일이 생기는지 보도록 하겠습니다. 우선 yaml파일을 수정해줍니다 #depl.yaml apiVersion: apps/v1 kind: Deployment metadata: name: myapp-deployment labels: app: myapp type: front-end spec: template: metadata: name: myapp-pod labels: app: myapp type: front-end spec: containers: - name: nginx-container image: nginx:1.20-alpine &amp;lt;----- 바뀐부분 replicas: 3 selector: matchLabels: type: front-end 이미지를 바꿀때에는 간단하게 set image를 통해서도 가능하지만 개인적으로 변경상황을 이력으로 남기는게 좋다고 생각하여 해당 방법을 사용합니다. 변경사항을 적용시켜줍니다. $ kubectl apply -f depl.yaml deployment.apps/myapp-deployment configured 그다음 replicaset과 revision을 확인해봅시다 $ kubectl get rs NAME DESIRED CURRENT READY AGE myapp-deployment-79896f8f68 3 3 3 5m14s myapp-deployment-7df67f74c5 0 0 0 5m42s replicaset이 하나더 생겼으며, revision도 하나더 생긴것을 확인할 수 있습니다. $ kubectl rollout history deploy myapp-deployment deployment.apps/myapp-deployment REVISION CHANGE-CAUSE 2 &amp;lt;none&amp;gt; 1 &amp;lt;none&amp;gt; 하지만 change-cause가 None 으로 되있으면 무엇이 바뀌었는지 알 수 가없는데, 아래 커맨드를 이용하면 따로 설정이 가능합니다. kubectl annotate deployment.v1.apps/[deployment name] kubernetes.io/change-cause=&quot;reason of update&quot; 해당커맨드를 사용하여 주석을 달고 다시 확인해봅시다 $ kubectl annotate deployment.v1.apps/myapp-deployment kubernetes.io/change-cause=&quot;image updated to 1.20&quot; deployment.apps/myapp-deployment annotated $ kubectl rollout history deployment myapp-deployment deployment.apps/myapp-deployment REVISION CHANGE-CAUSE 1 &amp;lt;none&amp;gt; 2 image updated to 1.20 주석이 잘 달린것을 확인할 수 있습니다. Rollback 만약에 새로운 버전으로 업데이트를 했는데 문제가 생겼을때 이전 버전 으로 돌아갈 수 있는 기능입니다. kubeclt rollout undo deployment 커맨드를 사용하여 롤백 시킬 수 있습니다. 직접 실습해봅시다. $ kubectl rollout undo deployment myapp-deployment deployment.apps/myapp-deployment rolled back 성공적으로 롤백 되었다고 뜹니다. 우선 image가 다시 원래대로 돌아왔는지 확인해봅니다 $ kubectl describe deployment myapp-deployment Name: myapp-deployment Namespace: default CreationTimestamp: Wed, 02 Jun 2021 07:05:06 +0000 Labels: app=myapp type=front-end Annotations: deployment.kubernetes.io/revision: 3 kubernetes.io/change-cause: Selector: type=front-end Replicas: 3 desired | 3 updated | 3 total | 3 available | 0 unavailable StrategyType: RollingUpdate MinReadySeconds: 0 RollingUpdateStrategy: 25% max unavailable, 25% max surge Pod Template: Labels: app=myapp type=front-end Containers: nginx-container: Image: nginx &amp;lt;------- 1.20 에서 다시 원래대로 돌아온것을 확인할 수 있습니다. Port: &amp;lt;none&amp;gt; Host Port: &amp;lt;none&amp;gt; Environment: &amp;lt;none&amp;gt; Mounts: &amp;lt;none&amp;gt; Volumes: &amp;lt;none&amp;gt; Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailable OldReplicaSets: &amp;lt;none&amp;gt; NewReplicaSet: myapp-deployment-7df67f74c5 (3/3 replicas created) Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 23m deployment-controller Scaled up replica set myapp-deployment-79896f8f68 to 1 Normal ScalingReplicaSet 23m deployment-controller Scaled down replica set myapp-deployment-7df67f74c5 to 2 Normal ScalingReplicaSet 23m deployment-controller Scaled up replica set myapp-deployment-79896f8f68 to 2 Normal ScalingReplicaSet 23m deployment-controller Scaled down replica set myapp-deployment-7df67f74c5 to 1 Normal ScalingReplicaSet 23m deployment-controller Scaled up replica set myapp-deployment-79896f8f68 to 3 Normal ScalingReplicaSet 23m deployment-controller Scaled down replica set myapp-deployment-7df67f74c5 to 0 Normal ScalingReplicaSet 4m28s deployment-controller Scaled up replica set myapp-deployment-7df67f74c5 to 1 Normal ScalingReplicaSet 4m24s deployment-controller Scaled down replica set myapp-deployment-79896f8f68 to 2 Normal ScalingReplicaSet 4m24s deployment-controller Scaled up replica set myapp-deployment-7df67f74c5 to 2 Normal ScalingReplicaSet 4m20s (x2 over 24m) deployment-controller Scaled up replica set myapp-deployment-7df67f74c5 to 3 Normal ScalingReplicaSet 4m20s deployment-controller Scaled down replica set myapp-deployment-79896f8f68 to 1 Normal ScalingReplicaSet 4m16s deployment-controller Scaled down replica set myapp-deployment-79896f8f68 to 0 그럼 replicaset과 revision은 어떨까요? #이미지 1.20으로 업데이트후 replicaset 상태 $ kubectl get rs NAME DESIRED CURRENT READY AGE myapp-deployment-79896f8f68 3 3 3 5m14s myapp-deployment-7df67f74c5 0 0 0 5m42s #롤백후 replicaset상태 $ kubectl get rs NAME DESIRED CURRENT READY AGE myapp-deployment-79896f8f68 0 0 0 25m myapp-deployment-7df67f74c5 3 3 3 26m revision $ kubectl rollout history deployment myapp-deployment deployment.apps/myapp-deployment REVISION CHANGE-CAUSE 2 image updated to 1.20 3 &amp;lt;none&amp;gt; replicaset은 이전 버전의 replicaset으로 바뀐것을 확인할 수가 있는데 revision은 1로돌아가는것이아닌 1이 증가한 것을 확인할 수 있습니다. 여기서 궁금한점이 생겼습니다. undo를 여러번하면 어떻게될까요? $ kubectl rollout history deployment myapp-deployment deployment.apps/myapp-deployment REVISION CHANGE-CAUSE 3 &amp;lt;none&amp;gt; 4 image updated to 1.20 결과 $ kubectl describe deployment myapp-deployment Name: myapp-deployment Namespace: default CreationTimestamp: Wed, 02 Jun 2021 07:05:06 +0000 Labels: app=myapp type=front-end Annotations: deployment.kubernetes.io/revision: 4 kubernetes.io/change-cause: image updated to 1.20 Selector: type=front-end Replicas: 3 desired | 3 updated | 3 total | 3 available | 0 unavailable StrategyType: RollingUpdate MinReadySeconds: 0 RollingUpdateStrategy: 25% max unavailable, 25% max surge Pod Template: Labels: app=myapp type=front-end Containers: nginx-container: Image: nginx:1.20 Port: &amp;lt;none&amp;gt; Host Port: &amp;lt;none&amp;gt; Environment: &amp;lt;none&amp;gt; Mounts: &amp;lt;none&amp;gt; Volumes: &amp;lt;none&amp;gt; Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailable OldReplicaSets: &amp;lt;none&amp;gt; NewReplicaSet: myapp-deployment-79896f8f68 (3/3 replicas created) Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 14m deployment-controller Scaled up replica set myapp-deployment-7df67f74c5 to 1 Normal ScalingReplicaSet 14m deployment-controller Scaled down replica set myapp-deployment-79896f8f68 to 2 Normal ScalingReplicaSet 14m deployment-controller Scaled up replica set myapp-deployment-7df67f74c5 to 2 Normal ScalingReplicaSet 14m (x2 over 33m) deployment-controller Scaled up replica set myapp-deployment-7df67f74c5 to 3 Normal ScalingReplicaSet 14m deployment-controller Scaled down replica set myapp-deployment-79896f8f68 to 1 Normal ScalingReplicaSet 13m deployment-controller Scaled down replica set myapp-deployment-79896f8f68 to 0 Normal ScalingReplicaSet 2m13s (x2 over 33m) deployment-controller Scaled up replica set myapp-deployment-79896f8f68 to 1 Normal ScalingReplicaSet 2m9s (x2 over 33m) deployment-controller Scaled down replica set myapp-deployment-7df67f74c5 to 2 Normal ScalingReplicaSet 2m9s (x2 over 33m) deployment-controller Scaled up replica set myapp-deployment-79896f8f68 to 2 Normal ScalingReplicaSet 2m5s (x2 over 33m) deployment-controller Scaled down replica set myapp-deployment-7df67f74c5 to 1 Normal ScalingReplicaSet 2m5s (x2 over 33m) deployment-controller Scaled up replica set myapp-deployment-79896f8f68 to 3 Normal ScalingReplicaSet 2m1s (x2 over 33m) deployment-controller Scaled down replica set myapp-deployment-7df67f74c5 to 0 undo 를 여러번하니 nginx &amp;lt;-&amp;gt; nginx:1.20 왔다 갔다 하는 모습을 보여줍니다. :rocket: history history를 보아도 두줄의 결과만 보여주기도했고, 정말 바로 이전단계까지만 이동할 수 있는건지도 궁금했습니다. 궁금한건 못참기에 바로 kubernetes.io를 찾다보니 원하는 revision으로 가려면 –to-revision=[resion-number] 를 입력해야되는것을 알 수 있었습니다. deployment 의 spec 밑에 revisionHistoryLimit: 10 으로 설정되어 있는것도 확인했으며 이 또한 수정할 수 있었군요 ㅎㅎ 바로 이전 단계만 이동 가능하다고 포스트 올렸다가 호다닥 수정하네요 그나저나 history에는 왜 사람 햇갈리게 두줄만을 보여줬던 걸까요? kubernetes는 상당히 똑똑했기 때문입니다. 이미 기억하고있는 replicaset랑 다름이 없기에 새로운 replicaset을 생성하지 않는것이었습니다. history에 없는 다른 버전의 nginx의 이미지로 바꾸어주니 replicaset과 history 각각 하나씩 더 생기는것을 확인할 수 있었습니다. $ kubectl get rs NAME DESIRED CURRENT READY AGE myapp-deployment-54d59f8648 3 3 3 17m myapp-deployment-79896f8f68 0 0 0 117m myapp-deployment-7df67f74c5 0 0 0 118m $ kubectl rollout history deploy myapp-deployment deployment.apps/myapp-deployment REVISION CHANGE-CAUSE 3 image updated to 1.20 4 &amp;lt;none&amp;gt; 5 &amp;lt;none&amp;gt;</summary></entry><entry><title type="html">ssh config 설정으로 간편하게 ssh접속하기</title><link href="https://shjeong92.github.io/2021/06/01/Handling-ssh-config.html" rel="alternate" type="text/html" title="ssh config 설정으로 간편하게 ssh접속하기" /><published>2021-06-01T00:00:00+09:00</published><updated>2021-06-01T00:00:00+09:00</updated><id>https://shjeong92.github.io/2021/06/01/Handling-ssh-config</id><content type="html" xml:base="https://shjeong92.github.io/2021/06/01/Handling-ssh-config.html">&lt;p&gt;최근 몇일간 kubernetes를 공부하면서 구글 클라우드에 ssh접속을 하는일이 잦았는데요, 접속 할 때마다 구글 클라우드에 접속해서 인스턴스의 외부 IP를 확인 하여야하고 긴 ssh 접속문을 쓰는게 귀찮았는데 알고보니 이를 간편하게 해주는 설정이 있더군요.&lt;/p&gt;

&lt;p&gt;이 글에선 맥에서 GCP에 접속하기 위한 &lt;code&gt;RSA key pair&lt;/code&gt;를 생성하는 부분부터 &lt;code&gt;ssh config&lt;/code&gt; 설정하는법을 다루겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;key-pair-생성하기&quot;&gt;key pair 생성하기&lt;/h2&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#-t 암호화타입 -f key pair 저장할 위치 -C 주석(보통 사용자 로그인ID를 적음)
$ssh-keygen -t rsa -f ~/.ssh/&amp;lt;KEY_FILE_NAME&amp;gt; -C &quot;account@gmail.com&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위와같이 입력하면 RSA key pair가 생성됩니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh-keygen &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; rsa &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; ~/.ssh/test &lt;span class=&quot;nt&quot;&gt;-C&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;test@gmail.com&quot;&lt;/span&gt;
Generating public/private rsa key pair.
Enter passphrase &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;empty &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;no passphrase&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: 
Enter same passphrase again: 
Your identification has been saved &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; /Users/sanghyukjeong/.ssh/test.
Your public key has been saved &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; /Users/sanghyukjeong/.ssh/test.pub.
The key fingerprint is:
SHA256:6TjvkM1IFHeI5ywCVgt8DFJpqiK+K4SZO4eTuBcEHkQ &lt;span class=&quot;nb&quot;&gt;test&lt;/span&gt;@gmail.com
The key&lt;span class=&quot;s1&quot;&gt;&apos;s randomart image is:
+---[RSA 3072]----+
|+E+=. .....      |
|.o*.o..oo.       |
|.=.o. .+         |
|... ... o.       |
|o+   ...S        |
|B..  . B         |
|*+ .  * +        |
|O.o    +         |
|oOo    .o        |
+----[SHA256]-----+
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이후 cat명령어로 rsa 공개키를 확인할 수 있는데
구글 클라우드 인스턴스에 이 키를 등록하기위해 복사 해놓습니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; ~/.ssh/test.pub
ssh-rsa AAAB3NzaC1yc2EAAAADAQABAAABgQDIlHiLTIM6oCQtjILfmIaTZv6j37J0kZNNjIgK0dFOxSYnMgXirh8gbRqFQY7kMWXZwAo82akxyTAP65GcjsqR+L1RarkKlYA7/lj7rvAf2VMJXy0X6yCbGo3yHcPGEoWLlsOgeYZDAk3Wld/hGdBWKXX4404iUQygjWbIircQ6BNZBb14nbhJK+pLWXMB7TmaRvtDsumBAko0shkA5g6y1oNGdpGBsUTQHk+rqQhqZElP9hgXp71qGhTO0V11kH41n0beReBoi9YngrpJtu6b4h1Ttm4N7CpCU5rUW38i5s71aInLuPolCDXlA8b6qVtBqg6dQ6/IgNQgQFRpwIkcf4v0EHKygcdm+QM25x3VAx1XC51gqHxhdU71/24EiUw0EW3cIvER6150aZF3PiAe5odstk9vx4L/1Vtu1GySQ2Qz8LcK1J3lawh3i8yaobVPUOIOxGDhme+tRMuyy16PhumtxSI5SeSwoIhYEIZtHKHFHKztNGV6m5aNSLZwzbk&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;test&lt;/span&gt;@gmail.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;key-등록하기&quot;&gt;key 등록하기&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/75003424/120263396-9136a700-c2d6-11eb-8c97-65769591c66c.png&quot; alt=&quot;gcp&quot; /&gt;&lt;/p&gt;

&lt;p&gt;compute엔진 -&amp;gt; 메타데이터 -&amp;gt; SSH 키로 이동후에&lt;/p&gt;

&lt;p&gt;항목추가를 클릭하여 공개키를 추가합니다.&lt;/p&gt;

&lt;p&gt;키등록이 끝났으니 ssh 접속을 해봅시다&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ssh &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; ~/.ssh/test yourID@your.gcloudExternal.ip

Welcome to Ubuntu 18.04.5 LTS &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;GNU/Linux 5.4.0-1043-gcp x86_64&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Documentation:  https://help.ubuntu.com
 &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Management:     https://landscape.canonical.com
 &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Support:        https://ubuntu.com/advantage

  System information as of Tue Jun  1 03:44:22 UTC 2021

  System load:  0.27               Users logged &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt;:        0
  Usage of /:   14.2% of 28.90GB   IP address &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;ens4:    10.178.0.2
  Memory usage: 44%                IP address &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;docker0: 172.17.0.1
  Swap usage:   0%                 IP address &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;cni0:    10.244.0.1
  Processes:    143

 &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Super-optimized &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;small spaces - &lt;span class=&quot;nb&quot;&gt;read &lt;/span&gt;how we shrank the memory
   footprint of MicroK8s to make it the smallest full K8s around.

   https://ubuntu.com/blog/microk8s-memory-optimisation
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;잘 접속 되는것을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;그러나 접속할때마다 저 커맨드를 다 입력하는것은 참 귀찮은일입니다. ip정도는 한번보면 외우시는분이 아니라면요 ㅎㅎ&lt;/p&gt;

&lt;p&gt;이제 ssh config파일 설정에대해 알아봅시다&lt;/p&gt;

&lt;h2 id=&quot;ssh-config-설정하여-ssh-접속-간편하게-하기&quot;&gt;ssh config 설정하여 ssh 접속 간편하게 하기&lt;/h2&gt;

&lt;p&gt;Linux/Unix서버 접속 계정들을 여러 가지 관리하는 경우, 별도로 메모나 파일에 접속 계정 / 비밀번호 등을 관리하거나 alias에 접속 명령어를 설정하는 번거로움이 있습니다.&lt;/p&gt;

&lt;p&gt;하지만 .ssh 경로 밑 config 파일에 계정 정보들을 저장하여 관리하면 정말 편리하게 접속들을 관리할 수 있습니다.&lt;/p&gt;

&lt;p&gt;우선 사용자 홈 디렉토리에서 .ssh 폴더로 접근합니다. .ssh 폴더는 ssh 접속을 한 번이라도 했다면, rsa 파일이나 known_hosts 등이 생성되기 때문에 자동으로 생성되는 디렉토리입니다.&lt;/p&gt;

&lt;p&gt;홈디렉토리에 있는 .ssh폴더에 들어가서 config 파일을 생성해줍니다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; ~/.ssh

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;vim config
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Host gcloud
        HostName 10.178.0.3
        User shjeong920522
        IdentityFile: ~/.ssh/test
        Port 22
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Host: 접속할 정보의 이름입니다.&lt;/li&gt;
  &lt;li&gt;HostName: 접속할 서버의 외부 IP 주소를 입력하세요&lt;/li&gt;
  &lt;li&gt;User: 접속할 서버의 user 정보입니다.&lt;/li&gt;
  &lt;li&gt;IdentityFile: 인증 키파일이 필요한 경우, 키파일 경로를 설정합니다. 이전 단계에 rsa 키페어 만든거 기억나시죠?&lt;/li&gt;
  &lt;li&gt;Port: ssh 접속 포트입니다. 생략 가능하며, 생략할 경우에 디폴트로 22번 포트로 실생됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;모든 설정이 끝났으니 google cloud에 접속해보겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# config 에서 Host에 등록한 접속할 정보만 적어주면 접속이되는 마법....&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ssh gcloud
Welcome to Ubuntu 18.04.5 LTS &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;GNU/Linux 5.4.0-1043-gcp x86_64&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Documentation:  https://help.ubuntu.com
 &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Management:     https://landscape.canonical.com
 &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Support:        https://ubuntu.com/advantage

  System information as of Tue Jun  1 04:05:52 UTC 2021

  System load:  0.65               Users logged &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt;:        0
  Usage of /:   14.2% of 28.90GB   IP address &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;ens4:    12.178.0.2
  Memory usage: 44%                IP address &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;docker0: 172.17.0.1
  Swap usage:   0%                 IP address &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;cni0:    12.244.0.1
  Processes:    144

 &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Super-optimized &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;small spaces - &lt;span class=&quot;nb&quot;&gt;read &lt;/span&gt;how we shrank the memory
   footprint of MicroK8s to make it the smallest full K8s around.

   https://ubuntu.com/blog/microk8s-memory-optimisation

11 updates can be applied immediately.
To see these additional updates run: apt list &lt;span class=&quot;nt&quot;&gt;--upgradable&lt;/span&gt;

New release &lt;span class=&quot;s1&quot;&gt;&apos;20.04.2 LTS&apos;&lt;/span&gt; available.
Run &lt;span class=&quot;s1&quot;&gt;&apos;do-release-upgrade&apos;&lt;/span&gt; to upgrade to it.


Last login: Tue Jun  1 03:44:23 2021 from 122.32.103.55
shjeong920522@master:~&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이렇게 한번 설정해 놓으면 외부 ip포트 확인하러 gcloud 콘솔에 접속하지 않아도되고, 정말 간편하게 ssh 접속을 할 수 있습니다.&lt;/p&gt;</content><author><name>Sanghyuk Jeong</name><email>shjeong920522@gmail.com</email></author><category term="gcloud" /><category term="ssh" /><category term="key-gen" /><category term="rsa" /><category term="config" /><summary type="html">최근 몇일간 kubernetes를 공부하면서 구글 클라우드에 ssh접속을 하는일이 잦았는데요, 접속 할 때마다 구글 클라우드에 접속해서 인스턴스의 외부 IP를 확인 하여야하고 긴 ssh 접속문을 쓰는게 귀찮았는데 알고보니 이를 간편하게 해주는 설정이 있더군요. 이 글에선 맥에서 GCP에 접속하기 위한 RSA key pair를 생성하는 부분부터 ssh config 설정하는법을 다루겠습니다. key pair 생성하기 #-t 암호화타입 -f key pair 저장할 위치 -C 주석(보통 사용자 로그인ID를 적음) $ssh-keygen -t rsa -f ~/.ssh/&amp;lt;KEY_FILE_NAME&amp;gt; -C &quot;account@gmail.com&quot; 위와같이 입력하면 RSA key pair가 생성됩니다. ssh-keygen -t rsa -f ~/.ssh/test -C &quot;test@gmail.com&quot; Generating public/private rsa key pair. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /Users/sanghyukjeong/.ssh/test. Your public key has been saved in /Users/sanghyukjeong/.ssh/test.pub. The key fingerprint is: SHA256:6TjvkM1IFHeI5ywCVgt8DFJpqiK+K4SZO4eTuBcEHkQ test@gmail.com The key&apos;s randomart image is: +---[RSA 3072]----+ |+E+=. ..... | |.o*.o..oo. | |.=.o. .+ | |... ... o. | |o+ ...S | |B.. . B | |*+ . * + | |O.o + | |oOo .o | +----[SHA256]-----+ 이후 cat명령어로 rsa 공개키를 확인할 수 있는데 구글 클라우드 인스턴스에 이 키를 등록하기위해 복사 해놓습니다. $ cat ~/.ssh/test.pub ssh-rsa AAAB3NzaC1yc2EAAAADAQABAAABgQDIlHiLTIM6oCQtjILfmIaTZv6j37J0kZNNjIgK0dFOxSYnMgXirh8gbRqFQY7kMWXZwAo82akxyTAP65GcjsqR+L1RarkKlYA7/lj7rvAf2VMJXy0X6yCbGo3yHcPGEoWLlsOgeYZDAk3Wld/hGdBWKXX4404iUQygjWbIircQ6BNZBb14nbhJK+pLWXMB7TmaRvtDsumBAko0shkA5g6y1oNGdpGBsUTQHk+rqQhqZElP9hgXp71qGhTO0V11kH41n0beReBoi9YngrpJtu6b4h1Ttm4N7CpCU5rUW38i5s71aInLuPolCDXlA8b6qVtBqg6dQ6/IgNQgQFRpwIkcf4v0EHKygcdm+QM25x3VAx1XC51gqHxhdU71/24EiUw0EW3cIvER6150aZF3PiAe5odstk9vx4L/1Vtu1GySQ2Qz8LcK1J3lawh3i8yaobVPUOIOxGDhme+tRMuyy16PhumtxSI5SeSwoIhYEIZtHKHFHKztNGV6m5aNSLZwzbk= test@gmail.com key 등록하기 compute엔진 -&amp;gt; 메타데이터 -&amp;gt; SSH 키로 이동후에 항목추가를 클릭하여 공개키를 추가합니다. 키등록이 끝났으니 ssh 접속을 해봅시다 $ ssh -i ~/.ssh/test yourID@your.gcloudExternal.ip Welcome to Ubuntu 18.04.5 LTS (GNU/Linux 5.4.0-1043-gcp x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage System information as of Tue Jun 1 03:44:22 UTC 2021 System load: 0.27 Users logged in: 0 Usage of /: 14.2% of 28.90GB IP address for ens4: 10.178.0.2 Memory usage: 44% IP address for docker0: 172.17.0.1 Swap usage: 0% IP address for cni0: 10.244.0.1 Processes: 143 * Super-optimized for small spaces - read how we shrank the memory footprint of MicroK8s to make it the smallest full K8s around. https://ubuntu.com/blog/microk8s-memory-optimisation 잘 접속 되는것을 확인할 수 있습니다. 그러나 접속할때마다 저 커맨드를 다 입력하는것은 참 귀찮은일입니다. ip정도는 한번보면 외우시는분이 아니라면요 ㅎㅎ 이제 ssh config파일 설정에대해 알아봅시다 ssh config 설정하여 ssh 접속 간편하게 하기 Linux/Unix서버 접속 계정들을 여러 가지 관리하는 경우, 별도로 메모나 파일에 접속 계정 / 비밀번호 등을 관리하거나 alias에 접속 명령어를 설정하는 번거로움이 있습니다. 하지만 .ssh 경로 밑 config 파일에 계정 정보들을 저장하여 관리하면 정말 편리하게 접속들을 관리할 수 있습니다. 우선 사용자 홈 디렉토리에서 .ssh 폴더로 접근합니다. .ssh 폴더는 ssh 접속을 한 번이라도 했다면, rsa 파일이나 known_hosts 등이 생성되기 때문에 자동으로 생성되는 디렉토리입니다. 홈디렉토리에 있는 .ssh폴더에 들어가서 config 파일을 생성해줍니다. $ cd ~/.ssh $ vim config Host gcloud HostName 10.178.0.3 User shjeong920522 IdentityFile: ~/.ssh/test Port 22 Host: 접속할 정보의 이름입니다. HostName: 접속할 서버의 외부 IP 주소를 입력하세요 User: 접속할 서버의 user 정보입니다. IdentityFile: 인증 키파일이 필요한 경우, 키파일 경로를 설정합니다. 이전 단계에 rsa 키페어 만든거 기억나시죠? Port: ssh 접속 포트입니다. 생략 가능하며, 생략할 경우에 디폴트로 22번 포트로 실생됩니다. 모든 설정이 끝났으니 google cloud에 접속해보겠습니다. # config 에서 Host에 등록한 접속할 정보만 적어주면 접속이되는 마법.... $ ssh gcloud Welcome to Ubuntu 18.04.5 LTS (GNU/Linux 5.4.0-1043-gcp x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage System information as of Tue Jun 1 04:05:52 UTC 2021 System load: 0.65 Users logged in: 0 Usage of /: 14.2% of 28.90GB IP address for ens4: 12.178.0.2 Memory usage: 44% IP address for docker0: 172.17.0.1 Swap usage: 0% IP address for cni0: 12.244.0.1 Processes: 144 * Super-optimized for small spaces - read how we shrank the memory footprint of MicroK8s to make it the smallest full K8s around. https://ubuntu.com/blog/microk8s-memory-optimisation 11 updates can be applied immediately. To see these additional updates run: apt list --upgradable New release &apos;20.04.2 LTS&apos; available. Run &apos;do-release-upgrade&apos; to upgrade to it. Last login: Tue Jun 1 03:44:23 2021 from 122.32.103.55 shjeong920522@master:~$ 이렇게 한번 설정해 놓으면 외부 ip포트 확인하러 gcloud 콘솔에 접속하지 않아도되고, 정말 간편하게 ssh 접속을 할 수 있습니다.</summary></entry><entry><title type="html">[ #6 ] static pod</title><link href="https://shjeong92.github.io/2021/05/31/Learning-Kubernetes-06.html" rel="alternate" type="text/html" title="[ #6 ] static pod" /><published>2021-05-31T00:00:00+09:00</published><updated>2021-05-31T00:00:00+09:00</updated><id>https://shjeong92.github.io/2021/05/31/Learning-Kubernetes-06</id><content type="html" xml:base="https://shjeong92.github.io/2021/05/31/Learning-Kubernetes-06.html">&lt;h2 id=&quot;static-pods이란&quot;&gt;Static pods이란&lt;/h2&gt;

&lt;p&gt;제일 처음에 kubernetes의 구조에서 공부했을때 마스터노드에 &lt;code&gt;kube-apiserver&lt;/code&gt;가 있고, 각 워커노드에는 &lt;code&gt;kubelet&lt;/code&gt; 이 존재하며 마스터노드의 kube-apiserver의 명령에따라 pod을 지우거나 삭제하거나 했었죠. &lt;br /&gt;
이번 시간에는 마스터 노드의 kube-scheduler의 영향을 받지 않는 Static pod 에 대해서 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;각 워커노드에 존재하는 kubelet 또한 pod이 죽거나 에러가 발생했을떄 아래의 방법으로 다시 살릴 수 있습니다.&lt;/p&gt;

&lt;p&gt;우선 static pod을 생성할 노드를 선택하여 ssh 접속해줍니다. 저는 worker-1에 접속하도록 하겠습니다&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get nodes &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; wide
NAME         STATUS   ROLES                  AGE    VERSION
instance-1   Ready    &amp;lt;none&amp;gt;                 3d3h   v1.21.1
master       Ready    control-plane,master   3d3h   v1.21.1
worker-1     Ready    &amp;lt;none&amp;gt;                 3d3h   v1.21.1
worker-2     Ready    &amp;lt;none&amp;gt;                 3d3h   v1.21.1

&lt;span class=&quot;c&quot;&gt;#worker 에 접속하기&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ssh &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; ~/.ssh/rsa-gcp-worker-1 shjeong920522@10.178.0.5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;특징-1&quot;&gt;특징 1&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;kubelet&lt;/strong&gt; 은 기본적으로 /etc/kubernetes/manifests 파일안의 pod.yaml 을 바라보는데, 이는 kubelet.service 의 config.yaml파일안에 staticPodPath에 정의되어있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;직접 확인해봅시다&lt;/p&gt;

&lt;p&gt;우선 아래 커맨드를 입력하여 config.yaml파일의 위치를 알아냅니다&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 모든서비스 확장 | kubelet 정보중에서 | --config 포함하는줄 가져오기&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ps &lt;span class=&quot;nt&quot;&gt;-ef&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;grep &lt;/span&gt;kubelet | &lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\-&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;-config&quot;&lt;/span&gt;
root     18270     1  1 May28 ?        01:31:14 /usr/bin/kubelet &lt;span class=&quot;nt&quot;&gt;--bootstrap-kubeconfig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/kubernetes/bootstrap-kubelet.conf &lt;span class=&quot;nt&quot;&gt;--kubeconfig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/kubernetes/kubelet.conf &lt;span class=&quot;nt&quot;&gt;--config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/var/lib/kubelet/config.yaml &lt;span class=&quot;nt&quot;&gt;--network-plugin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;cni &lt;span class=&quot;nt&quot;&gt;--pod-infra-container-image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;k8s.gcr.io/pause:3.4.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;해당 파일을 확인해 봅시다&lt;/p&gt;
&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;$ sudo vi config=/var/lib/kubelet/config.yaml&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kubelet.config.k8s.io/v1beta1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;authentication&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;anonymous&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;enabled&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;false&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;webhook&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;cacheTTL&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;0s&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;enabled&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;x509&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;clientCAFile&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/etc/kubernetes/pki/ca.crt&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;authorization&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Webhook&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;webhook&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;cacheAuthorizedTTL&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;0s&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;cacheUnauthorizedTTL&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;0s&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;cgroupDriver&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;systemd&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;clusterDNS&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;10.96.0.10&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;clusterDomain&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;cluster.local&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;cpuManagerReconcilePeriod&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;0s&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;evictionPressureTransitionPeriod&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;0s&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;fileCheckFrequency&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;0s&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;healthzBindAddress&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;127.0.0.1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;healthzPort&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10248&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;httpCheckFrequency&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;0s&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;imageMinimumGCAge&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;0s&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;KubeletConfiguration&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;{}&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;nodeStatusReportFrequency&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;0s&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;nodeStatusUpdateFrequency&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;0s&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;resolvConf&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/run/systemd/resolve/resolv.conf&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;rotateCertificates&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;runtimeRequestTimeout&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;0s&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;shutdownGracePeriod&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;0s&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;shutdownGracePeriodCriticalPods&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;0s&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;staticPodPath&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/etc/kubernetes/manifests        &amp;lt;------------------------------ staticPodPath 가 설정되어 있는것을 확인할 수 있습니다.&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;streamingConnectionIdleTimeout&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;0s&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;syncFrequency&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;0s&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;volumeStatsAggPeriod&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;0s&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;위와 같이 파일을 통으로 확인해보아도 되지만 grep명령어를 사용하면 더욱 편히 찾을 수도 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo grep &lt;/span&gt;static /var/lib/kubelet/config.yaml
staticPodPath: /etc/kubernetes/manifests
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;특징-2&quot;&gt;특징 2&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;만약 해동 폴더내에 kind: Pod인 yaml 파일이있다면 kubelet이 자동으로 이를 생성하며 static pod의 이름에는 자동으로 해당 노드의 이름이 suffix로 붙습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;잘 생성되나 확인해 봅시다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /etc/kubernetes/manifests
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;vi static.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;간단한 pod을 해당 볼더에 생성해줍니다.&lt;/p&gt;
&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#static.yaml&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Pod&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp-pod&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;front-end&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-container&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;마스터&lt;/strong&gt; 노드로 이동하여 확인해봅시다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get pods
NAME                 READY   STATUS    RESTARTS   AGE
myapp-pod-worker-1   1/1     Running   0          42m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;static pod를 생성한 노드의 이름인 worker-1 가 Pod이름의 suffix로 붙어있는것을 확인할 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;특징-3&quot;&gt;특징 3&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;마스터노드에서 kubectl delete 명령어를 사용하더라도 워커노드의 kubelet이 다시 살려냅니다. static pod는 해당 워커노드의 kubelet이 관리하기 떄문입니다.
따라서 해당 pod의 image를 변경하고싶다면 manifest 폴더안의 해당 yaml파일의 이미지를 수정해야하고, 지우려면 해당 yaml파일을 삭제하면 됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그럼 정말로 다시 시작되는지 마스터노드에서 &lt;strong&gt;myapp-pod-worker-1&lt;/strong&gt;을 삭제해 봅시다&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl delete pod myapp-pod-worker-1
pod &lt;span class=&quot;s2&quot;&gt;&quot;myapp-pod-worker-1&quot;&lt;/span&gt; deleted
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;지운다음에 바로 확인해보면&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get pods
NAME                 READY   STATUS    RESTARTS   AGE
myapp-pod-worker-1   0/1     Pending   0          1s

kubectl get pods
NAME                 READY   STATUS    RESTARTS   AGE
myapp-pod-worker-1   1/1     Running   0   
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;pending상태에 있다가 running으로 바뀌는 것을 확인할 수 있습니다.
따라서 static pod을 지우고싶으면 해당 노드로 가서 해당 yaml파일을 삭제하는 방법뿐입니다.&lt;/p&gt;</content><author><name>Sanghyuk Jeong</name><email>shjeong920522@gmail.com</email></author><category term="Docker" /><category term="Kubernetes" /><category term="Replicasets" /><category term="Deployment" /><category term="static" /><category term="pod" /><summary type="html">Static pods이란 제일 처음에 kubernetes의 구조에서 공부했을때 마스터노드에 kube-apiserver가 있고, 각 워커노드에는 kubelet 이 존재하며 마스터노드의 kube-apiserver의 명령에따라 pod을 지우거나 삭제하거나 했었죠. 이번 시간에는 마스터 노드의 kube-scheduler의 영향을 받지 않는 Static pod 에 대해서 알아보겠습니다. 각 워커노드에 존재하는 kubelet 또한 pod이 죽거나 에러가 발생했을떄 아래의 방법으로 다시 살릴 수 있습니다. 우선 static pod을 생성할 노드를 선택하여 ssh 접속해줍니다. 저는 worker-1에 접속하도록 하겠습니다 $ kubectl get nodes -o wide NAME STATUS ROLES AGE VERSION instance-1 Ready &amp;lt;none&amp;gt; 3d3h v1.21.1 master Ready control-plane,master 3d3h v1.21.1 worker-1 Ready &amp;lt;none&amp;gt; 3d3h v1.21.1 worker-2 Ready &amp;lt;none&amp;gt; 3d3h v1.21.1 #worker 에 접속하기 $ ssh -i ~/.ssh/rsa-gcp-worker-1 shjeong920522@10.178.0.5 특징 1 kubelet 은 기본적으로 /etc/kubernetes/manifests 파일안의 pod.yaml 을 바라보는데, 이는 kubelet.service 의 config.yaml파일안에 staticPodPath에 정의되어있습니다. 직접 확인해봅시다 우선 아래 커맨드를 입력하여 config.yaml파일의 위치를 알아냅니다 # 모든서비스 확장 | kubelet 정보중에서 | --config 포함하는줄 가져오기 $ ps -ef | grep kubelet | grep &quot;\--config&quot; root 18270 1 1 May28 ? 01:31:14 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --network-plugin=cni --pod-infra-container-image=k8s.gcr.io/pause:3.4.1 해당 파일을 확인해 봅시다 $ sudo vi config=/var/lib/kubelet/config.yaml apiVersion: kubelet.config.k8s.io/v1beta1 authentication: anonymous: enabled: false webhook: cacheTTL: 0s enabled: true x509: clientCAFile: /etc/kubernetes/pki/ca.crt authorization: mode: Webhook webhook: cacheAuthorizedTTL: 0s cacheUnauthorizedTTL: 0s cgroupDriver: systemd clusterDNS: - 10.96.0.10 clusterDomain: cluster.local cpuManagerReconcilePeriod: 0s evictionPressureTransitionPeriod: 0s fileCheckFrequency: 0s healthzBindAddress: 127.0.0.1 healthzPort: 10248 httpCheckFrequency: 0s imageMinimumGCAge: 0s kind: KubeletConfiguration logging: {} nodeStatusReportFrequency: 0s nodeStatusUpdateFrequency: 0s resolvConf: /run/systemd/resolve/resolv.conf rotateCertificates: true runtimeRequestTimeout: 0s shutdownGracePeriod: 0s shutdownGracePeriodCriticalPods: 0s staticPodPath: /etc/kubernetes/manifests &amp;lt;------------------------------ staticPodPath 가 설정되어 있는것을 확인할 수 있습니다. streamingConnectionIdleTimeout: 0s syncFrequency: 0s volumeStatsAggPeriod: 0s 위와 같이 파일을 통으로 확인해보아도 되지만 grep명령어를 사용하면 더욱 편히 찾을 수도 있습니다. $ sudo grep static /var/lib/kubelet/config.yaml staticPodPath: /etc/kubernetes/manifests 특징 2 만약 해동 폴더내에 kind: Pod인 yaml 파일이있다면 kubelet이 자동으로 이를 생성하며 static pod의 이름에는 자동으로 해당 노드의 이름이 suffix로 붙습니다. 잘 생성되나 확인해 봅시다. $ cd /etc/kubernetes/manifests $ sudo vi static.yaml 간단한 pod을 해당 볼더에 생성해줍니다. #static.yaml apiVersion: v1 kind: Pod metadata: name: myapp-pod labels: app: myapp type: front-end spec: containers: - name: nginx-container image: nginx 마스터 노드로 이동하여 확인해봅시다. $ kubectl get pods NAME READY STATUS RESTARTS AGE myapp-pod-worker-1 1/1 Running 0 42m static pod를 생성한 노드의 이름인 worker-1 가 Pod이름의 suffix로 붙어있는것을 확인할 수 있습니다. 특징 3 마스터노드에서 kubectl delete 명령어를 사용하더라도 워커노드의 kubelet이 다시 살려냅니다. static pod는 해당 워커노드의 kubelet이 관리하기 떄문입니다. 따라서 해당 pod의 image를 변경하고싶다면 manifest 폴더안의 해당 yaml파일의 이미지를 수정해야하고, 지우려면 해당 yaml파일을 삭제하면 됩니다. 그럼 정말로 다시 시작되는지 마스터노드에서 myapp-pod-worker-1을 삭제해 봅시다 $ kubectl delete pod myapp-pod-worker-1 pod &quot;myapp-pod-worker-1&quot; deleted 지운다음에 바로 확인해보면 $ kubectl get pods NAME READY STATUS RESTARTS AGE myapp-pod-worker-1 0/1 Pending 0 1s kubectl get pods NAME READY STATUS RESTARTS AGE myapp-pod-worker-1 1/1 Running 0 pending상태에 있다가 running으로 바뀌는 것을 확인할 수 있습니다. 따라서 static pod을 지우고싶으면 해당 노드로 가서 해당 yaml파일을 삭제하는 방법뿐입니다.</summary></entry><entry><title type="html">[ #5 ] pod 스케쥴링-2</title><link href="https://shjeong92.github.io/2021/05/31/Learning-Kubernetes-05.html" rel="alternate" type="text/html" title="[ #5 ] pod 스케쥴링-2" /><published>2021-05-31T00:00:00+09:00</published><updated>2021-05-31T00:00:00+09:00</updated><id>https://shjeong92.github.io/2021/05/31/Learning-Kubernetes-05</id><content type="html" xml:base="https://shjeong92.github.io/2021/05/31/Learning-Kubernetes-05.html">&lt;h2 id=&quot;nodeselector&quot;&gt;nodeSelector&lt;/h2&gt;
&lt;p&gt;nodeSelector 는 파드를 특정 레이블이 있는 노드로 제한하는 매우 간단한 방법을 제공합니다.&lt;/p&gt;
&lt;h3 id=&quot;1-노드에-레이블-붙이기&quot;&gt;1. 노드에 레이블 붙이기&lt;/h3&gt;

&lt;p&gt;노드에 레이블을 붙여서 추후 pod을 원하는 노드에 할당할때 사용할 수 있습니다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;kubectl label nodes &amp;lt;노드 이름&amp;gt; &amp;lt;레이블 키&amp;gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&amp;lt;레이블 값&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;2-pod설정에-nodeselector-필드-추가하기&quot;&gt;2. pod설정에 nodeSelector 필드 추가하기&lt;/h3&gt;
&lt;p&gt;실행하고자 하는 파드의 설정 파일을 가져오고, 이처럼 nodeSelector 섹션을 추가합니다. 아래의 예를 들어보면&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Pod&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;test&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;spec아래에 nodeSelector을 추가해줍니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Pod&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;test&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;imagePullPolicy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;IfNotPresent&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;nodeSelector&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;#&amp;lt;레이블 키&amp;gt;: &amp;lt;레이블 값&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;disktype&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ssd&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;node-affinity&quot;&gt;node affinity&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;nodeSelector&lt;/strong&gt; 을 사용했을때는 매칭 조건이 레이블에 key=value, key와 value가 일치했을때 pod을 노드에 있었습니다.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;nodeAffinity&lt;/strong&gt; 는 operator로 Equal, In, NotIn, Exists, DoseNotExist 를 사용할 수 있어, 더 여러가지 제약을 정의 할 수 있습니다.&lt;/p&gt;

&lt;p&gt;또한 &lt;strong&gt;nodeAffinity&lt;/strong&gt; 에는 아래와 같이 두가지 타입이 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;requiredDuringSchedulingIgnoredDuringExecution&lt;/li&gt;
  &lt;li&gt;preferredDuringSchedulingIgnoredDuringExecution&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;첫번째 타입은 파드가 노드에 스케줄되려면 규칙을 만족해야만 하는것이고, 없다면 pod는 pending 상태가 됩니다
두번째 타입은 선호하는 선호하는 또다른 키와 벨류, 연산자를 추가할 수 있는데요, 첫번째 조건을 만족하는 노드가 여러개 있을경우에, 두번째 조건의 weight(선호도) 점수에따라
pod이 스케쥴되는 형태입니다.&lt;/p&gt;

&lt;p&gt;미래에는 requiredDuringSchedulingRequiredDuringExecution 라는 새로운 타입이 나올것이라고 합니다, 앞서 소개드린 두 타입은 이미 pod이 스케줄 되었을때 node의 label이 바뀌거나 없어지면서
affinity의 조건과 맞지 않더라도 이미 배정되었음으로 무시합니다. 하지만 미래에 나올 새로운 타입은 이미 배정받은 pod이라도 노드의 label이 삭제,변경되면 조건에 맞지 않는 pod을 중지 시키는 타입 이라고합니다.&lt;/p&gt;

&lt;h3 id=&quot;예제&quot;&gt;예제&lt;/h3&gt;
&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Pod&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;with-node-affinity&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;affinity&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;nodeAffinity&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;requiredDuringSchedulingIgnoredDuringExecution&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;nodeSelectorTerms&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;matchExpressions&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kubernetes.io/e2e-az-name&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;In&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;e2e-az1&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;e2e-az2&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;preferredDuringSchedulingIgnoredDuringExecution&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;preference&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;matchExpressions&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;another-node-label-key&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;In&lt;/span&gt;
            &lt;span class=&quot;na&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;another-node-label-value&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;with-node-affinity&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;k8s.gcr.io/pause:2.0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Node affinity는 여러 affinity를 동시에 적용할 수 있는데요 저는 아래와 같은 경우에 대해 실험해 보았습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;requiredDuringSchedulingIgnoredDuringExecution 만 적용했을 경우&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;조건을 만족하는 노드가 없을경우 pod는 스케쥴되지않고 pending상태가 됩니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;requiredDuringSchedulingIgnoredDuringExecution 과 preferredDuringSchedulingIgnoredDuringExecution 를 동시에 적용할경우&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;첫번째 조건을 을 만족하는 노드가 여러개 있을때 두번째 조건을 만족하는 노드가 있다면 두번째 조건을 만족하는 노드에 pod가 배치됩니다.&lt;/li&gt;
      &lt;li&gt;두번째 조건만을 만족하는 경우에는 pod는 스케쥴링되지 않고 pending 상태가 됩니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;preferredDuringSchedulingIgnoredDuringExecution 만 적용할 경우&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;조건을 만족하는 노드가 있을경우 해당 노드에 스케쥴링되고, 조건을 만족하는 노드가 없다면 랜덤으로 스케쥴 되었습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위의 예제에서는 두 개의 Affinity가 정의되어 있는데요 만약 노드들중 &lt;strong&gt;requiredDuringSchedulingIgnoredDuringExecution&lt;/strong&gt; 을 만족하는 노드가 없다면 해당 pod은 pending 상태가
될것이며, 해당 조건을 만족하는 노드가 여러개일 경우 &lt;strong&gt;preferredDuringSchedulingIgnoredDuringExecution&lt;/strong&gt; 조건이 맞는 노드로 배정 될 것입니다. &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;weight&lt;/code&gt; 는 선호도입니다 만약 여러개의 &lt;strong&gt;preferredDuringSchedulingIgnoredDuringExecution&lt;/strong&gt; 을 적용하였을때에는 weight이 높은 노드에 스케쥴됩니다.&lt;/p&gt;</content><author><name>Sanghyuk Jeong</name><email>shjeong920522@gmail.com</email></author><category term="Docker" /><category term="Kubernetes" /><category term="Replicasets" /><category term="Deployment" /><category term="Google" /><category term="cloud" /><summary type="html">nodeSelector nodeSelector 는 파드를 특정 레이블이 있는 노드로 제한하는 매우 간단한 방법을 제공합니다. 1. 노드에 레이블 붙이기 노드에 레이블을 붙여서 추후 pod을 원하는 노드에 할당할때 사용할 수 있습니다. kubectl label nodes &amp;lt;노드 이름&amp;gt; &amp;lt;레이블 키&amp;gt;=&amp;lt;레이블 값&amp;gt; 2. pod설정에 nodeSelector 필드 추가하기 실행하고자 하는 파드의 설정 파일을 가져오고, 이처럼 nodeSelector 섹션을 추가합니다. 아래의 예를 들어보면 apiVersion: v1 kind: Pod metadata: name: nginx labels: env: test spec: containers: - name: nginx image: nginx spec아래에 nodeSelector을 추가해줍니다. apiVersion: v1 kind: Pod metadata: name: nginx labels: env: test spec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent nodeSelector: #&amp;lt;레이블 키&amp;gt;: &amp;lt;레이블 값&amp;gt; disktype: ssd node affinity nodeSelector 을 사용했을때는 매칭 조건이 레이블에 key=value, key와 value가 일치했을때 pod을 노드에 있었습니다. nodeAffinity 는 operator로 Equal, In, NotIn, Exists, DoseNotExist 를 사용할 수 있어, 더 여러가지 제약을 정의 할 수 있습니다. 또한 nodeAffinity 에는 아래와 같이 두가지 타입이 있습니다. requiredDuringSchedulingIgnoredDuringExecution preferredDuringSchedulingIgnoredDuringExecution 첫번째 타입은 파드가 노드에 스케줄되려면 규칙을 만족해야만 하는것이고, 없다면 pod는 pending 상태가 됩니다 두번째 타입은 선호하는 선호하는 또다른 키와 벨류, 연산자를 추가할 수 있는데요, 첫번째 조건을 만족하는 노드가 여러개 있을경우에, 두번째 조건의 weight(선호도) 점수에따라 pod이 스케쥴되는 형태입니다. 미래에는 requiredDuringSchedulingRequiredDuringExecution 라는 새로운 타입이 나올것이라고 합니다, 앞서 소개드린 두 타입은 이미 pod이 스케줄 되었을때 node의 label이 바뀌거나 없어지면서 affinity의 조건과 맞지 않더라도 이미 배정되었음으로 무시합니다. 하지만 미래에 나올 새로운 타입은 이미 배정받은 pod이라도 노드의 label이 삭제,변경되면 조건에 맞지 않는 pod을 중지 시키는 타입 이라고합니다. 예제 apiVersion: v1 kind: Pod metadata: name: with-node-affinity spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/e2e-az-name operator: In values: - e2e-az1 - e2e-az2 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: another-node-label-key operator: In values: - another-node-label-value containers: - name: with-node-affinity image: k8s.gcr.io/pause:2.0 Node affinity는 여러 affinity를 동시에 적용할 수 있는데요 저는 아래와 같은 경우에 대해 실험해 보았습니다. requiredDuringSchedulingIgnoredDuringExecution 만 적용했을 경우: 조건을 만족하는 노드가 없을경우 pod는 스케쥴되지않고 pending상태가 됩니다. requiredDuringSchedulingIgnoredDuringExecution 과 preferredDuringSchedulingIgnoredDuringExecution 를 동시에 적용할경우: 첫번째 조건을 을 만족하는 노드가 여러개 있을때 두번째 조건을 만족하는 노드가 있다면 두번째 조건을 만족하는 노드에 pod가 배치됩니다. 두번째 조건만을 만족하는 경우에는 pod는 스케쥴링되지 않고 pending 상태가 됩니다. preferredDuringSchedulingIgnoredDuringExecution 만 적용할 경우: 조건을 만족하는 노드가 있을경우 해당 노드에 스케쥴링되고, 조건을 만족하는 노드가 없다면 랜덤으로 스케쥴 되었습니다. 위의 예제에서는 두 개의 Affinity가 정의되어 있는데요 만약 노드들중 requiredDuringSchedulingIgnoredDuringExecution 을 만족하는 노드가 없다면 해당 pod은 pending 상태가 될것이며, 해당 조건을 만족하는 노드가 여러개일 경우 preferredDuringSchedulingIgnoredDuringExecution 조건이 맞는 노드로 배정 될 것입니다. weight 는 선호도입니다 만약 여러개의 preferredDuringSchedulingIgnoredDuringExecution 을 적용하였을때에는 weight이 높은 노드에 스케쥴됩니다.</summary></entry><entry><title type="html">[ #4 ] pod 스케쥴링-1</title><link href="https://shjeong92.github.io/2021/05/30/Learning-Kubernetes-04.html" rel="alternate" type="text/html" title="[ #4 ] pod 스케쥴링-1" /><published>2021-05-30T00:00:00+09:00</published><updated>2021-05-30T00:00:00+09:00</updated><id>https://shjeong92.github.io/2021/05/30/Learning-Kubernetes-04</id><content type="html" xml:base="https://shjeong92.github.io/2021/05/30/Learning-Kubernetes-04.html">&lt;h2 id=&quot;taint--toleration&quot;&gt;Taint &amp;amp; Toleration&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;taint: 노드마다 설정가능&lt;/li&gt;
  &lt;li&gt;toleration: taint를 무시할 수 있음&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;주로 노드를 지정된 역할만 하게할때 사용합니다.
예를들어 gpu잇는 노드에는 다른 pod들은 올라가지않고 gpu쓰는 pod들만 올라가게 하는등의 상황에 사용할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
taint에는 사용할 수 있는 3가지 옵션이 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;NoSchedule : toleration이 없으면 pod이 스케쥴되지 않음, 기존 실행되던 pod에는 적용 안됨&lt;/li&gt;
  &lt;li&gt;PreferNoSchedule : toleration이 없으면 pod을 스케줄링안하려고 하지만 필수는 아님, 클러스터내에 자원이 부족하거나 하면 taint가 걸려있는 노드에서도 pod이 스케줄링될 수 있음&lt;/li&gt;
  &lt;li&gt;NoExecute : toleration이 없으면 pod이 스케줄되지 않으며 기존에 실행되던 pod도 toleration이 없으면 종료시킴.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;taint 형식은 다음과 같습니다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl taint node &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;nodename&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;key&lt;span class=&quot;o&quot;&gt;}={&lt;/span&gt;value&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;:&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;option&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;하나의 노드에 taint 적용하기&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl taint node worker-1 &lt;span class=&quot;nv&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;value:NoSchedule
node/worker-1 tainted
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;describe로 잘 적용 되었는지 확인해 봅시다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl describe node worker-1 | &lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; taint
Taints:             &lt;span class=&quot;nv&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;value:NoSchedule
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;잘 적용이 되었군요.&lt;/p&gt;

&lt;p&gt;taint의 옵션이 &lt;code&gt;NoSchedule&lt;/code&gt; 이므로 pod에 toleration 필드에 같은 key, value가 없다면 생성되지 않겠죠?
확인해봅시다.&lt;/p&gt;

&lt;h3 id=&quot;rocket테스트해보기&quot;&gt;:rocket:테스트해보기&lt;/h3&gt;
&lt;p&gt;Deployment로 pod을 띄어보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;환경&lt;/strong&gt;:&lt;br /&gt;
실습에 사용한 클러스터는 마스터노드1개 워커노드3개로 구성되었으며,
&lt;br /&gt;
이름은 다음과 같고, 워커노드들의 cpu와 ram스팩은 모두 같게 설정하였습니다. &lt;br /&gt;
taint는 worker-1 노드에 설정하였습니다.
master&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;worker-1&lt;/li&gt;
  &lt;li&gt;worker-2&lt;/li&gt;
  &lt;li&gt;instance-1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;우선 pod을 세개 생성하는 test-taint.yaml이라는 deployment를 만들어줍니다&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl create deployment test-taint &lt;span class=&quot;nt&quot;&gt;--image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;nginx &lt;span class=&quot;nt&quot;&gt;--replicas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3 &lt;span class=&quot;nt&quot;&gt;--dry-run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;client &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; yaml &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; test-taint.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;yaml파일을 열어보면 이렇습니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Deployment&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;creationTimestamp&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;null&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;test-taint&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;test-taint&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;replicas&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;selector&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;matchLabels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;test-taint&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;strategy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;{}&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;creationTimestamp&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;null&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;test-taint&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;{}&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;{}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;만들어진 yaml파일을 apply 해봅시다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl apply &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; test-taint.yaml
deployment.apps/test-taint created
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;pod을 확인해보면 taint를 설정한 node에는 pod이 배정되지 않은것을 확인 할 수 있습니다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get pods &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; wide
NAME                          READY   STATUS    RESTARTS   AGE    IP           NODE         NOMINATED NODE   READINESS GATES
test-taint-6bd4977499-2thmv   1/1     Running   0          106s   10.244.3.7   instance-1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
test-taint-6bd4977499-4sccs   1/1     Running   0          106s   10.244.1.6   worker-2     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
test-taint-6bd4977499-h4rt8   1/1     Running   0          106s   10.244.3.8   instance-1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 이 deployment를 삭제하고 toleration을 적용시킨후 다시 deployment를 apply 해보겠습니다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl delete deployment test-taint
deployment.apps &lt;span class=&quot;s2&quot;&gt;&quot;test-taint&quot;&lt;/span&gt; deleted

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;vim test-taint.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;spec.template.spec 밑에 toleration옵션을 추가해줍니다.&lt;/p&gt;
&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;apps/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Deployment&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;creationTimestamp&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;null&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;test-taint&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;test-taint&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;replicas&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;selector&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;matchLabels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;test-taint&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;strategy&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;{}&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;creationTimestamp&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;null&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;test-taint&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;tolerations&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;key&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Equal&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;value&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;effect&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;NoSchedule&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;resources&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;{}&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;{}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;수정된 yaml파일 다시 배포하기:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl apply &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; test-taint.yaml
deployment.apps/test-taint created
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;pod 리스트를 다시 확인해보면 각 1개의노드에 1개의 pod이 생성된걸 확인할 수 있습니다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ kubectl get pods -o wide
NAME                          READY   STATUS    RESTARTS   AGE   IP           NODE         NOMINATED NODE   READINESS GATES
test-taint-77b85b88c6-8hq5l   1/1     Running   0          43s   10.244.3.9   instance-1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
test-taint-77b85b88c6-957bv   1/1     Running   0          43s   10.244.1.7   worker-2     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
test-taint-77b85b88c6-f6xn2   1/1     Running   0          43s   10.244.2.8   worker-1     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Sanghyuk Jeong</name><email>shjeong920522@gmail.com</email></author><category term="Docker" /><category term="Kubernetes" /><category term="Replicasets" /><category term="Deployment" /><category term="Google" /><category term="cloud" /><summary type="html">Taint &amp;amp; Toleration taint: 노드마다 설정가능 toleration: taint를 무시할 수 있음 주로 노드를 지정된 역할만 하게할때 사용합니다. 예를들어 gpu잇는 노드에는 다른 pod들은 올라가지않고 gpu쓰는 pod들만 올라가게 하는등의 상황에 사용할 수 있습니다. taint에는 사용할 수 있는 3가지 옵션이 있습니다. NoSchedule : toleration이 없으면 pod이 스케쥴되지 않음, 기존 실행되던 pod에는 적용 안됨 PreferNoSchedule : toleration이 없으면 pod을 스케줄링안하려고 하지만 필수는 아님, 클러스터내에 자원이 부족하거나 하면 taint가 걸려있는 노드에서도 pod이 스케줄링될 수 있음 NoExecute : toleration이 없으면 pod이 스케줄되지 않으며 기존에 실행되던 pod도 toleration이 없으면 종료시킴. taint 형식은 다음과 같습니다. $ kubectl taint node {nodename} {key}={value}:{option} 하나의 노드에 taint 적용하기 $ kubectl taint node worker-1 key=value:NoSchedule node/worker-1 tainted describe로 잘 적용 되었는지 확인해 봅시다. $ kubectl describe node worker-1 | grep -i taint Taints: key=value:NoSchedule 잘 적용이 되었군요. taint의 옵션이 NoSchedule 이므로 pod에 toleration 필드에 같은 key, value가 없다면 생성되지 않겠죠? 확인해봅시다. :rocket:테스트해보기 Deployment로 pod을 띄어보겠습니다. 환경: 실습에 사용한 클러스터는 마스터노드1개 워커노드3개로 구성되었으며, 이름은 다음과 같고, 워커노드들의 cpu와 ram스팩은 모두 같게 설정하였습니다. taint는 worker-1 노드에 설정하였습니다. master worker-1 worker-2 instance-1 우선 pod을 세개 생성하는 test-taint.yaml이라는 deployment를 만들어줍니다 $ kubectl create deployment test-taint --image=nginx --replicas=3 --dry-run=client -o yaml &amp;gt; test-taint.yaml yaml파일을 열어보면 이렇습니다. kind: Deployment metadata: creationTimestamp: null labels: app: test-taint name: test-taint spec: replicas: 3 selector: matchLabels: app: test-taint strategy: {} template: metadata: creationTimestamp: null labels: app: test-taint spec: containers: - image: nginx name: nginx resources: {} status: {} 만들어진 yaml파일을 apply 해봅시다. $ kubectl apply -f test-taint.yaml deployment.apps/test-taint created pod을 확인해보면 taint를 설정한 node에는 pod이 배정되지 않은것을 확인 할 수 있습니다. $ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES test-taint-6bd4977499-2thmv 1/1 Running 0 106s 10.244.3.7 instance-1 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt; test-taint-6bd4977499-4sccs 1/1 Running 0 106s 10.244.1.6 worker-2 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt; test-taint-6bd4977499-h4rt8 1/1 Running 0 106s 10.244.3.8 instance-1 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt; 이제 이 deployment를 삭제하고 toleration을 적용시킨후 다시 deployment를 apply 해보겠습니다. $ kubectl delete deployment test-taint deployment.apps &quot;test-taint&quot; deleted $ vim test-taint.yaml spec.template.spec 밑에 toleration옵션을 추가해줍니다. apiVersion: apps/v1 kind: Deployment metadata: creationTimestamp: null labels: app: test-taint name: test-taint spec: replicas: 3 selector: matchLabels: app: test-taint strategy: {} template: metadata: creationTimestamp: null labels: app: test-taint spec: tolerations: - key: key operator: Equal value: value effect: NoSchedule containers: - image: nginx name: nginx resources: {} status: {} 수정된 yaml파일 다시 배포하기: $ kubectl apply -f test-taint.yaml deployment.apps/test-taint created pod 리스트를 다시 확인해보면 각 1개의노드에 1개의 pod이 생성된걸 확인할 수 있습니다. $ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES test-taint-77b85b88c6-8hq5l 1/1 Running 0 43s 10.244.3.9 instance-1 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt; test-taint-77b85b88c6-957bv 1/1 Running 0 43s 10.244.1.7 worker-2 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt; test-taint-77b85b88c6-f6xn2 1/1 Running 0 43s 10.244.2.8 worker-1 &amp;lt;none&amp;gt; &amp;lt;none&amp;gt;</summary></entry><entry><title type="html">[ #3 ] Replicasets &amp;amp; Deployment</title><link href="https://shjeong92.github.io/2021/05/28/Learning-Kubernetes-03.html" rel="alternate" type="text/html" title="[ #3 ] Replicasets &amp;amp; Deployment" /><published>2021-05-28T00:00:00+09:00</published><updated>2021-05-28T00:00:00+09:00</updated><id>https://shjeong92.github.io/2021/05/28/Learning-Kubernetes-03</id><content type="html" xml:base="https://shjeong92.github.io/2021/05/28/Learning-Kubernetes-03.html">&lt;hr /&gt;

&lt;h2 id=&quot;replicaset&quot;&gt;Replicaset&lt;/h2&gt;

&lt;p&gt;먼저 Deployment의 개념중에서 가장 중요한것은 ReplicaSet입니다. Replication Controller의 새로운 버전으로 Label Selector를 통해 노드 상의 여러 Pod의 생성/복제/삭제 등의 라이프 싸이클을 관리합니다.&lt;/p&gt;

&lt;h3 id=&quot;작동-방식&quot;&gt;작동 방식&lt;/h3&gt;
&lt;p&gt;레플리카셋을 정의하는 필드는 획득 가능한 파드를 식별하는 방법이 명시된 셀렉터, 유지해야 하는 파드 개수를 명시하는 레플리카의 개수, 그리고 레플리카 수 유지를 위해 생성하는 신규 파드에 대한 데이터를 명시하는 파드 템플릿을 포함한다. 그러면 레플리카셋은 필드에 지정된 설정을 충족하기 위해 필요한 만큼 파드를 만들고 삭제합니다. 레플리카셋이 새로운 파드를 생성해야 할 경우, 명시된 파드 템플릿을 사용합니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#replicaset.yaml&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;apps/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ReplicaSet&lt;/span&gt; 
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp-replicaset&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;front-end&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;#replicate할 pod명시하기&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp-pod&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;front-end&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-container&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;#pod을 몇개 유지할것인지?      &lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;replicas&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;#ReplicaSet은 이미 생성되있는 같은 종류의 pod들까지 신경써가면서 pod을 생성합니다.&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;selector&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; 
    &lt;span class=&quot;na&quot;&gt;matchLabels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;front-end&lt;/span&gt;


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Replicaset은 selector가 있는데 만약 이에 match되는 label을 가진 pod이 있다면 그것도 갯수에 포함시킵니다.&lt;/p&gt;
&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#pod.yaml&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Pod&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp-pod&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;front-end&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-container&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;우선 labels.type 이 동일한 pod 하나를 생성해줍니다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl apply &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; pod-definition.yml 
pod/myapp-pod created
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get pods
NAME        READY   STATUS              RESTARTS   AGE
myapp-pod   0/1     ContainerCreating   0          8s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;레이블이 같으니 replicaset.yaml을 apply하면 두개가 생성 되야합니다 한번 확인해봅시다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl apply &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; replicaset-definition.yml 
replicaset.apps/myapp-replicaset created
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
myapp-pod                1/1     Running   0          23s
myapp-replicaset-f9f87   1/1     Running   0          13s
myapp-replicaset-szrtw   1/1     Running   0          13s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;딱 2개가 생성된것을 확인할 수 있습니다.
&lt;br /&gt;
만약 pod.yaml을 통해 생성된 pod을 지우면 어떻게될까요?&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl delete pod myapp-pod
pod &lt;span class=&quot;s2&quot;&gt;&quot;myapp-pod&quot;&lt;/span&gt; deleted

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
myapp-replicaset-f9f87   1/1     Running   0          2m46s
myapp-replicaset-spvjx   1/1     Running   0          9s
myapp-replicaset-szrtw   1/1     Running   0          2m46s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ReplicaSet에 replicas를 3으로 세팅해놔서 동일한 label의 팟이 사라지자 자동으로 명시한 pod을 생선한 것을 확인할 수 있습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;deployment&quot;&gt;Deployment&lt;/h2&gt;

&lt;p&gt;Deployment는 Replication controller와 Replica Set의 좀더 상위 추상화 개념입니다. kubernetes docs에서는 ReplicaSet 이나 Replication Controller를 바로 사용하는 것보다, 좀 더 추상화된 Deployment를 사용하는것이 권장하고 있습니다.&lt;/p&gt;

&lt;p&gt;yaml파일을 살펴도보면 차이점은 별로 없습니다.&lt;/p&gt;

&lt;p&gt;위의 replicaset.yaml파일에서 한줄만 수정하면 deployment 를 위한 yaml파일을 만들 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;apps/v1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Deployment   &amp;lt;----------- 수정된부분&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp-replicaset&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;front-end&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;#replicate할 pod명시하기&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp-pod&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;myapp&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;front-end&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx-container&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;#pod을 몇개 유지할것인지?      &lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;replicas&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;#ReplicaSet은 이미 생성되있는 같은 종류의 pod들까지 신경써가면서 pod을 생성합니다.&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;selector&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; 
    &lt;span class=&quot;na&quot;&gt;matchLabels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;front-end&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;deployment 또한 replicaset과 같이 이미 동일한 라벨의 pod이 생성되어있으면 또다른 3개의 pod을 만들지 않습니다.&lt;/p&gt;

&lt;p&gt;위의 Replicaset.yaml을 통해 만들어진 동일한 label의 pod이 존재하기때문에 새로운 pod을 만들지 않습니다. 또한
이미 동일한 replicaset이 있기에 다른 replicaset을 만들지 않습니다.&lt;/p&gt;

&lt;p&gt;기존의 Replicaset object를 지우면 어떻게 될까요?&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl delete &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; replicaset-definition.yml 
replicaset.apps &lt;span class=&quot;s2&quot;&gt;&quot;myapp-replicaset&quot;&lt;/span&gt; deleted

&lt;span class=&quot;c&quot;&gt;# 삭제직후 replicaset을 바로 확인해보면 Deployment.yaml에의해 새로운 replicaset이 생성된것을 확인할 수 있고&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get replicaset
NAME                          DESIRED   CURRENT   READY   AGE
myapp-replicaset-7df67f74c5   3         3         3       3s

&lt;span class=&quot;c&quot;&gt;# 이전 replicaset에 의해 생성 된 pod들이 삭제되면서, 새로운 replicaset에의해 pod이 재 생성되는것을 볼 수 있습니다.&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get pods
NAME                                READY   STATUS              RESTARTS   AGE
myapp-replicaset-7df67f74c5-c992z   1/1     Running             0          5s
myapp-replicaset-7df67f74c5-cwk22   0/1     ContainerCreating   0          5s
myapp-replicaset-7df67f74c5-zzx7h   1/1     Running             0          5s
myapp-replicaset-jnqgg              0/1     Terminating         0          73s
myapp-replicaset-qghpt              0/1     Terminating         0          73s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Sanghyuk Jeong</name><email>shjeong920522@gmail.com</email></author><category term="Docker" /><category term="Kubernetes" /><category term="Replicasets" /><category term="Deployment" /><category term="Google" /><category term="cloud" /><summary type="html">Replicaset 먼저 Deployment의 개념중에서 가장 중요한것은 ReplicaSet입니다. Replication Controller의 새로운 버전으로 Label Selector를 통해 노드 상의 여러 Pod의 생성/복제/삭제 등의 라이프 싸이클을 관리합니다. 작동 방식 레플리카셋을 정의하는 필드는 획득 가능한 파드를 식별하는 방법이 명시된 셀렉터, 유지해야 하는 파드 개수를 명시하는 레플리카의 개수, 그리고 레플리카 수 유지를 위해 생성하는 신규 파드에 대한 데이터를 명시하는 파드 템플릿을 포함한다. 그러면 레플리카셋은 필드에 지정된 설정을 충족하기 위해 필요한 만큼 파드를 만들고 삭제합니다. 레플리카셋이 새로운 파드를 생성해야 할 경우, 명시된 파드 템플릿을 사용합니다. #replicaset.yaml apiVersion: apps/v1 kind: ReplicaSet metadata: name: myapp-replicaset labels: app: myapp type: front-end spec: #replicate할 pod명시하기 template: metadata: name: myapp-pod labels: app: myapp type: front-end spec: containers: - name: nginx-container image: nginx #pod을 몇개 유지할것인지? replicas: 3 #ReplicaSet은 이미 생성되있는 같은 종류의 pod들까지 신경써가면서 pod을 생성합니다. selector: matchLabels: type: front-end Replicaset은 selector가 있는데 만약 이에 match되는 label을 가진 pod이 있다면 그것도 갯수에 포함시킵니다. #pod.yaml apiVersion: v1 kind: Pod metadata: name: myapp-pod labels: app: myapp type: front-end spec: containers: - name: nginx-container image: nginx 우선 labels.type 이 동일한 pod 하나를 생성해줍니다. $ kubectl apply -f pod-definition.yml pod/myapp-pod created $ kubectl get pods NAME READY STATUS RESTARTS AGE myapp-pod 0/1 ContainerCreating 0 8s 레이블이 같으니 replicaset.yaml을 apply하면 두개가 생성 되야합니다 한번 확인해봅시다. $ kubectl apply -f replicaset-definition.yml replicaset.apps/myapp-replicaset created $ kubectl get pods NAME READY STATUS RESTARTS AGE myapp-pod 1/1 Running 0 23s myapp-replicaset-f9f87 1/1 Running 0 13s myapp-replicaset-szrtw 1/1 Running 0 13s 딱 2개가 생성된것을 확인할 수 있습니다. 만약 pod.yaml을 통해 생성된 pod을 지우면 어떻게될까요? $ kubectl delete pod myapp-pod pod &quot;myapp-pod&quot; deleted $ kubectl get pods NAME READY STATUS RESTARTS AGE myapp-replicaset-f9f87 1/1 Running 0 2m46s myapp-replicaset-spvjx 1/1 Running 0 9s myapp-replicaset-szrtw 1/1 Running 0 2m46s ReplicaSet에 replicas를 3으로 세팅해놔서 동일한 label의 팟이 사라지자 자동으로 명시한 pod을 생선한 것을 확인할 수 있습니다. Deployment Deployment는 Replication controller와 Replica Set의 좀더 상위 추상화 개념입니다. kubernetes docs에서는 ReplicaSet 이나 Replication Controller를 바로 사용하는 것보다, 좀 더 추상화된 Deployment를 사용하는것이 권장하고 있습니다. yaml파일을 살펴도보면 차이점은 별로 없습니다. 위의 replicaset.yaml파일에서 한줄만 수정하면 deployment 를 위한 yaml파일을 만들 수 있습니다. apiVersion: apps/v1 kind: Deployment &amp;lt;----------- 수정된부분 metadata: name: myapp-replicaset labels: app: myapp type: front-end spec: #replicate할 pod명시하기 template: metadata: name: myapp-pod labels: app: myapp type: front-end spec: containers: - name: nginx-container image: nginx #pod을 몇개 유지할것인지? replicas: 3 #ReplicaSet은 이미 생성되있는 같은 종류의 pod들까지 신경써가면서 pod을 생성합니다. selector: matchLabels: type: front-end deployment 또한 replicaset과 같이 이미 동일한 라벨의 pod이 생성되어있으면 또다른 3개의 pod을 만들지 않습니다. 위의 Replicaset.yaml을 통해 만들어진 동일한 label의 pod이 존재하기때문에 새로운 pod을 만들지 않습니다. 또한 이미 동일한 replicaset이 있기에 다른 replicaset을 만들지 않습니다. 기존의 Replicaset object를 지우면 어떻게 될까요? $ kubectl delete -f replicaset-definition.yml replicaset.apps &quot;myapp-replicaset&quot; deleted # 삭제직후 replicaset을 바로 확인해보면 Deployment.yaml에의해 새로운 replicaset이 생성된것을 확인할 수 있고 $ kubectl get replicaset NAME DESIRED CURRENT READY AGE myapp-replicaset-7df67f74c5 3 3 3 3s # 이전 replicaset에 의해 생성 된 pod들이 삭제되면서, 새로운 replicaset에의해 pod이 재 생성되는것을 볼 수 있습니다. $ kubectl get pods NAME READY STATUS RESTARTS AGE myapp-replicaset-7df67f74c5-c992z 1/1 Running 0 5s myapp-replicaset-7df67f74c5-cwk22 0/1 ContainerCreating 0 5s myapp-replicaset-7df67f74c5-zzx7h 1/1 Running 0 5s myapp-replicaset-jnqgg 0/1 Terminating 0 73s myapp-replicaset-qghpt 0/1 Terminating 0 73s</summary></entry><entry><title type="html">[ #2 ] Kubernetes 설치 및 환경 구성하기</title><link href="https://shjeong92.github.io/2021/05/27/Learning-Kubernetes-02.html" rel="alternate" type="text/html" title="[ #2 ] Kubernetes 설치 및 환경 구성하기" /><published>2021-05-27T00:00:00+09:00</published><updated>2021-05-27T00:00:00+09:00</updated><id>https://shjeong92.github.io/2021/05/27/Learning-Kubernetes-02</id><content type="html" xml:base="https://shjeong92.github.io/2021/05/27/Learning-Kubernetes-02.html">&lt;hr /&gt;

&lt;p&gt;minikube를 이용하면 정말 간단하게 로컬머신에 테스트환경을 구성할 수 있었습니다 또한 &lt;code&gt;kubectl&lt;/code&gt; 커맨드에 친숙해지는데 잘 활용했었지요,
 하지만 이는 싱글 노드 클러스트이고, 다른 노드를 추가할 수 없습니다. 그 말은 즉 진또배기 쿠버네티스를 체험할 수 없는것이며 모는 기능을 제대로 체험할 수 없다는 것이지요.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
따라서 kubeadm을 이용하여 마스터노드와 워커노드들을 구성해보기로 했습니다.
로컬 환경에서 vagrant와 virtualbox를 통해 실험환경을 구축하고싶었지만 m1 맥에 그런것은 없습니다 ㅠㅠ
어쩌다보니 구글 클라우드를 처음시작하면 무료크레딧으로 300$를 제공하는것을 발견하였고 구글클라우드를 이용하여 쿠버네티스 환경을 구축해보기로 결정했습니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
이번 포스트에서는 쿠버네티스 설치부터 기본적인 환경까지 구성할것입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;쿠버네티스는 기본적으로 &lt;code&gt;마스터 노드&lt;/code&gt; 와 &lt;code&gt;워커 노드&lt;/code&gt;로 구성됩니다.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;마스터 노드&lt;/code&gt;는 &lt;code&gt;워커 노드&lt;/code&gt;에 Pod를 할당하고 Pod 안에 컨테이너를 띄우게 하는 역할을 합니다.
또한 쿠버네티스의 상태를 관리하고 여러 Pod 들의 스케줄링도 하는 등 쿠버네티스에서 중추적인 역할을 합니다.
&lt;code&gt;워커 노드&lt;/code&gt;는 &lt;code&gt;마스터 노드&lt;/code&gt;와 통신하면서 Pod를 할당 받고 그 안에 컨테이너를 띄워 유지 및 관리하는 역할을 합니다. 
또한 네트워크나 볼륨에 대한 기능도 컨트롤도 합니다.&lt;/p&gt;

&lt;p&gt;마스터 노드1개와 와 워커 노드 2개를 생성할 것이며, 
운영체제는 Ubuntu 18.04 LTS 를 사용하여 구성하도록 하겠습니다.
&lt;br /&gt;
그리고 마스터 및 모든 워커노드의 스펙은 아래와 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CPU : 2 core&lt;/li&gt;
  &lt;li&gt;RAM : 2 GB&lt;/li&gt;
  &lt;li&gt;Storage : 30 GB&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;kubeadm을-활용한-환경구축&quot;&gt;kubeadm을 활용한 환경구축&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;kubeadm&lt;/code&gt;이란, kubernetes에서 제공하는 기본적인 도구이며, 
kubernetes 클러스터를 빨리 구축하기 위한 다양한 기능을 제공합니다.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubeadm&lt;/code&gt;은 아래와같이 다양한 커맨드명령어를 사용하여 클러스터를 구축할 수 있습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;kubeadm init&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Kubernetes 컨트롤 플레인 노드를 초기화합니다.&lt;/li&gt;
      &lt;li&gt;즉, 마스터 노드를 초기화합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;kubeadm join&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Kubernetes 워커 노드를 초기화하고 클러스터에 연결합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;kubeadm upgrade&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Kubernetes 클러스터를 업그레이드 합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;kubeadm token&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;부트 스트랩 토큰을 사용한 인증에 설명된대로 부트 스트랩 토큰은 클러스터에 참여하는 노드와 제어 평면 노드 사이에 양방향 신뢰를 설정하는 데 사용됩니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;kubeadm reset&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;kubeadm init 혹은 kubeadm join의 변경사항을 최대한 복구합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;kubeadm version&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;kubeadm 버젼을 보여줍니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;kubeadm alpha&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;정식으로 배포된 기능은 아니지만 kubernetes측에서 사용자 피드백을 얻기 위해 인증서 갱신, 인증서 만료 확인, 사용자 생성, kubelet 설정 등 다양한 기능을 제공한다고 합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;시작하기전에-확인할-것&quot;&gt;시작하기전에 확인할 것&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;2GB 또는 그 이상의 메모리(각노드별)&lt;/li&gt;
  &lt;li&gt;2CPUs 또는 그이상의 시피유&lt;/li&gt;
  &lt;li&gt;클러스터의 모든 시스템 간 완벽한 네트워크 연결되었는지 확인&lt;/li&gt;
  &lt;li&gt;모든 노드에 대한 고유한 호스트 이름, 고유한 MAC 주소, 고유한 product_uuid&lt;/li&gt;
  &lt;li&gt;각노드의 컨트롤러인 kubelet이 제대로 동작하기위해선 swap이 disabled 되어야 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#swap 비활성화하기&lt;/span&gt;
swapoff &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;모든-노드의-mac-address-및-product_uuid-확인&quot;&gt;모든 노드의 Mac address 및 product_uuid 확인&lt;/h2&gt;

&lt;p&gt;로컬 머신의경우 하드웨어 기기들은 각각의 유니크한 주소를 가지는 반면에 가상 머신은 같은 id를 가질 수도 있습니다.
만약에 같은 Mac address 및 product_uuid를 가지고 있으면 설치에 실패 할 수 있기에 확인하여야 합니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#MAC address 확인하기&lt;/span&gt;
ifconfig &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#product_uuid 확인하기&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo cat&lt;/span&gt; /sys/class/dmi/id/product_uuid
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;위 쉘 커맨드를 각각의노드에 적용하여 중복되는 맥주소나 제품아이디가 있는지 확인합니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;iptables-설정하기&quot;&gt;iptables 설정하기&lt;/h2&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#br_netfilter모듈 로드되었는지 확인하기&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;lsmod | &lt;span class=&quot;nb&quot;&gt;grep &lt;/span&gt;br_netfilter
&lt;span class=&quot;c&quot;&gt;# 아무정보도 뜨지않는다.&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#명시적으로 br_netfilter 로드하기&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;modprobe br_netfilter
&lt;span class=&quot;c&quot;&gt;#다시 확인하면 br_netfilter이 로드된걸 볼수 있어요.&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;lsmod | &lt;span class=&quot;nb&quot;&gt;grep &lt;/span&gt;br_netfilter
br_netfilter           28672  0
bridge                176128  1 br_netfilter

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;리눅스 노드의 iptables가 브리지된 트래픽을 올바르게 보기 위한 요구 사항으로, sysctl 구성에서 net.bridge.bridge-nf-call-iptables 가 1로 설정되어 있는지 확인해야 합니다. 
다음3개의 스크립트를 실행해주시면,&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt; | sudo tee /etc/modules-load.d/k8s.conf
br_netfilter
&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF

&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt; | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF

&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;sysctl &lt;span class=&quot;nt&quot;&gt;--system&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아래와같이 뜰거에요.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;* Applying /etc/sysctl.d/10-console-messages.conf ...
kernel.printk = 4 4 1 7
* Applying /etc/sysctl.d/10-ipv6-privacy.conf ...
net.ipv6.conf.all.use_tempaddr = 2
net.ipv6.conf.default.use_tempaddr = 2
* Applying /etc/sysctl.d/10-kernel-hardening.conf ...
kernel.kptr_restrict = 1
* Applying /etc/sysctl.d/10-link-restrictions.conf ...
fs.protected_hardlinks = 1
fs.protected_symlinks = 1
* Applying /etc/sysctl.d/10-lxd-inotify.conf ...
fs.inotify.max_user_instances = 1024
* Applying /etc/sysctl.d/10-magic-sysrq.conf ...
kernel.sysrq = 176
* Applying /etc/sysctl.d/10-network-security.conf ...
net.ipv4.conf.default.rp_filter = 1
net.ipv4.conf.all.rp_filter = 1
net.ipv4.tcp_syncookies = 1
* Applying /etc/sysctl.d/10-ptrace.conf ...
kernel.yama.ptrace_scope = 1
* Applying /etc/sysctl.d/10-zeropage.conf ...
vm.mmap_min_addr = 65536
* Applying /usr/lib/sysctl.d/50-default.conf ...
net.ipv4.conf.all.promote_secondaries = 1
net.core.default_qdisc = fq_codel
* Applying /etc/sysctl.d/60-gce-network-security.conf ...
net.ipv4.tcp_syncookies = 1
net.ipv4.conf.all.accept_source_route = 0
net.ipv4.conf.default.accept_source_route = 0
net.ipv4.conf.all.accept_redirects = 0
net.ipv4.conf.default.accept_redirects = 0
net.ipv4.conf.all.secure_redirects = 1
net.ipv4.conf.default.secure_redirects = 1
net.ipv4.ip_forward = 0
net.ipv4.conf.all.send_redirects = 0
net.ipv4.conf.default.send_redirects = 0
net.ipv4.conf.all.rp_filter = 1
net.ipv4.conf.default.rp_filter = 1
net.ipv4.icmp_echo_ignore_broadcasts = 1
net.ipv4.icmp_ignore_bogus_error_responses = 1
net.ipv4.conf.all.log_martians = 1
net.ipv4.conf.default.log_martians = 1
kernel.randomize_va_space = 2
kernel.panic = 10
* Applying /etc/sysctl.d/99-cloudimg-ipv6.conf ...
net.ipv6.conf.all.use_tempaddr = 0
net.ipv6.conf.default.use_tempaddr = 0
* Applying /etc/sysctl.d/99-sysctl.conf ...
* Applying /etc/sysctl.d/k8s.conf ...
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
* Applying /etc/sysctl.conf ...

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;필수-포트-확인하기&quot;&gt;필수 포트 확인하기&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;마스터 노드에서 필요한 필수 노트&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;6443 포트 : Kubernetes API Server / Used By All&lt;/li&gt;
  &lt;li&gt;2379~2380 포트 : etcd server client API / Used By kube-apiserver, etcd&lt;/li&gt;
  &lt;li&gt;10250 포트 : Kubelet API / Used By Self, Control plane&lt;/li&gt;
  &lt;li&gt;10251 포트 : kube-scheduler / Used By Self&lt;/li&gt;
  &lt;li&gt;10252 포트 : kube-controller-manager / Used By Self&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;워커 노드에서 필요한 필수 포트&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;10250 포트 : Kubelet API / Used By Self, Control plane&lt;/li&gt;
  &lt;li&gt;30000~32767 포트 : NodePort Services / Used By All&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;컨테이너-런타임-설치하기&quot;&gt;컨테이너 런타임 설치하기&lt;/h2&gt;
&lt;p&gt;저는 docker를 설치할 것입니다..&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 구버전의 도커 설치되어있다면 삭제하기.&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get remove docker docker-engine docker.io containerd runc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;도커 공홈에가면 도커 설치하는 방법이 여러가지있는데 저는 그중에서 가장 간단한 방법으로 설치하겠습니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#도커를 설치해주는 스크립트 get-docker.sh 로저장하기&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl &lt;span class=&quot;nt&quot;&gt;-fsSL&lt;/span&gt; https://get.docker.com &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; get-docker.sh
&lt;span class=&quot;c&quot;&gt;#스크립트 실행하기&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;sh get-docker.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아래와같이 뜨면 성공입니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Executing docker install script, commit: 7cae5f8b0decc17d6571f9f52eb840fbc13b2737&lt;/span&gt;
+ sh &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; apt-get update &lt;span class=&quot;nt&quot;&gt;-qq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;/dev/null
+ sh &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;DEBIAN_FRONTEND&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;noninteractive apt-get &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-qq&lt;/span&gt; apt-transport-https ca-certificates curl &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;/dev/null
+ sh &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; curl &lt;span class=&quot;nt&quot;&gt;-fsSL&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;https://download.docker.com/linux/ubuntu/gpg&quot;&lt;/span&gt; | apt-key add &lt;span class=&quot;nt&quot;&gt;-qq&lt;/span&gt; - &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;/dev/null
Warning: apt-key output should not be parsed &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;stdout is not a terminal&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
+ sh &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; /etc/apt/sources.list.d/docker.list
+ sh &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; apt-get update &lt;span class=&quot;nt&quot;&gt;-qq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;/dev/null
+ &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
+ sh &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; apt-get &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-qq&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--no-install-recommends&lt;/span&gt; docker-ce &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;/dev/null
+ &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; 1 &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
+ sh &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;DEBIAN_FRONTEND&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;noninteractive apt-get &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-qq&lt;/span&gt; docker-ce-rootless-extras &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;/dev/null
+ sh &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; docker version
Client: Docker Engine - Community
 Version:           20.10.6
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        370c289
 Built:             Fri Apr  9 22:46:01 2021
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      &lt;span class=&quot;nb&quot;&gt;true

&lt;/span&gt;Server: Docker Engine - Community
 Engine:
  Version:          20.10.6
  API version:      1.41 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;minimum version 1.12&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  Go version:       go1.13.15
  Git commit:       8728dd2
  Built:            Fri Apr  9 22:44:13 2021
  OS/Arch:          linux/amd64
  Experimental:     &lt;span class=&quot;nb&quot;&gt;false
 &lt;/span&gt;containerd:
  Version:          1.4.4
  GitCommit:        05f951a3781f4f2c1911b05e61c160e9c30eaa8e
 runc:
  Version:          1.0.0-rc93
  GitCommit:        12644e614e25b05da6fd08a38ffa0cfe1903fdec
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0

&lt;span class=&quot;o&quot;&gt;================================================================================&lt;/span&gt;

To run Docker as a non-privileged user, consider setting up the
Docker daemon &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;rootless mode &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;your user:

    dockerd-rootless-setuptool.sh &lt;span class=&quot;nb&quot;&gt;install

&lt;/span&gt;Visit https://docs.docker.com/go/rootless/ to learn about rootless mode.


To run the Docker daemon as a fully privileged service, but granting non-root
&lt;span class=&quot;nb&quot;&gt;users &lt;/span&gt;access, refer to https://docs.docker.com/go/daemon-access/

WARNING: Access to the remote API on a privileged Docker daemon is equivalent
         to root access on the host. Refer to the &lt;span class=&quot;s1&quot;&gt;&apos;Docker daemon attack surface&apos;&lt;/span&gt;
         documentation &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;details: https://docs.docker.com/go/attack-surface/

&lt;span class=&quot;o&quot;&gt;================================================================================&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;혹시 모르니 도커 커맨드를 써서 설치가 잘되었는지 확인해봅니다&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Docker 설치가 완료 되었으면, Docker 데몬이 사용하는 드라이버를 cgroupfs 대신 systemd를 사용하도록 설정합니다
왜냐하면 kubernetes에서 권장하는 Docker 데몬의 드라이버는 systemd 이기 때문이고, systemd를 사용하면 kubernetes가 클러스터 노드에서 사용 가능한 자원을 쉽게 알 수 있도록 해주기 때문입니다.
또한, 시스템에 두개의 cgroup관리자가 있으면 리소스가 부족할 때 불안정해지는 사례가 있다고 하니 무조건적으로 설정해줍시다.
아래 명령어를 통해 Docker 데몬의 드라이버를 교체합니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo mkdir&lt;/span&gt; /etc/docker

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt; | sudo tee /etc/docker/daemon.json
{
  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],
  &quot;log-driver&quot;: &quot;json-file&quot;,
  &quot;log-opts&quot;: {
    &quot;max-size&quot;: &quot;100m&quot;
  },
  &quot;storage-driver&quot;: &quot;overlay2&quot;
}
&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF

&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;#도커 재시작과 부팅시 실행되게 설정&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;docker
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl daemon-reload
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;kubeadm-kubelet-및-kubectl-설치하기&quot;&gt;kubeadm, kubelet 및 kubectl 설치하기&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;kubeadm은 kubelet 또는 kubectl 을 설치하거나 관리하지 않으므로, kubeadm이 설치하려는 쿠버네티스 컨트롤 플레인의 버전과 일치하는지 확인해야 합니다&lt;/strong&gt;
따라서 kubeadm 및 쿠버네티스를 업그레이드 할 때에는 버전에 신경쓰셔야 합니다.&lt;/p&gt;

&lt;p&gt;아래에서는 kubeadm, kubelet, 및 kubectl 설치후에 업데이트를 홀드 시킴으로써 실수로 &lt;code&gt;sudo apt-get update&lt;/code&gt;
실행한 커맨드가 해당 패키지에 영향이 가지 않도록 할것입니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 패키지 색인을 최신으로 업데이트하고, kubeadm, kubelet, 및 kubectl 를 설치하는데 필요한 패키지 설치하기.&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get update
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; apt-transport-https ca-certificates curl

&lt;span class=&quot;c&quot;&gt;# 구글 클라우드의 공개 사이닝 키를 다운로드 하기.&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;curl &lt;span class=&quot;nt&quot;&gt;-fsSLo&lt;/span&gt; /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg

&lt;span class=&quot;c&quot;&gt;# 쿠버네티스 apt 리포지터리를 추가하기.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# *apt리포는 apt 도구로 읽을 수있는 deb 패키지 및 메타 데이터 파일이 포함 된 네트워크 서버 또는 로컬 디렉토리입니다*&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main&quot;&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;sudo tee&lt;/span&gt; /etc/apt/sources.list.d/kubernetes.list

&lt;span class=&quot;c&quot;&gt;# apt 패키지 색인을 업데이트 후 kubeadm, kubelet 및 kubectl다운로드 한다음, 버전 고정시키기.&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get update
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-get &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; kubelet kubeadm kubectl
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt-mark hold kubelet kubeadm kubectl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;star처음부터-이-줄-윗부분까지는-마스터노드와-워커노드-모두에-적용되어야-할-내용입니다star&quot;&gt;:star:처음부터 이 줄 윗부분까지는 마스터노드와 워커노드 모두에 적용되어야 할 내용입니다:star:&lt;/h1&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;마스터-노드-세팅&quot;&gt;마스터 노드 세팅&lt;/h2&gt;

&lt;p&gt;마스터 노드를 실행시키려면 &lt;code&gt;kubeadm init&lt;/code&gt; 커맨드를 사용해야합니다.
해당명령어에는 여러가지 옵션이 들어가는데, 여기서 필요한 옵션값은 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;–pod-network-cidr : Pod 네트워크를 설정할 때 사용&lt;/li&gt;
  &lt;li&gt;–apiserver-advertise-address : 특정 마스터 노드의 API Server 주소를 설정할 때 사용&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;pod-네트워크-설정&quot;&gt;Pod 네트워크 설정&lt;/h2&gt;
&lt;p&gt;우선 세팅할 클러스터에서 Pod가 서로 통신할 수 있도록 Pod 네트워크 애드온을 설치 해야 합니다.
kubeadm을 통해 만들어진 클러스터는 CNI(Container Network Interface) 기반의 애드온이 필요합니다.&lt;/p&gt;

&lt;p&gt;기본적으로 k8s에서 제공해주는 kubenet이라는 네트워크 플러그인이 있지만, 
매우 기본적이고 간단한 기능만 제공하는 네트워크 플러그인이기 때문에 이 자체로는 크로스 노드 네트워킹이나 네트워크 정책과 같은 기능들은 구현되어 있지 않습니다.
따라서 kubeadm은 kubernetes가 기본적으로 지원해주는 네트워크 플러그인인 kubenet을 지원하지 않고, CNI 기반 네트워크만 지원합니다.
여기서는 Flannel이라는 Pod 네트워크 애드온을 설치하여 사용할 것입니다.
&lt;br /&gt;
Flannel을 사용하려면 kubeadm init 명령어에 –pod-network-cidr=10.244.0.0/16 이라는 인자를 추가해서 실행해야 하며,
 10.244.0.0/16 이라는 네트워크는 Flannel에서 기본적으로 권장하는 네트워크 대역입니다.
&lt;br /&gt;
Pod 네트워크가 호스트 네트워크와 겹치면 문제가 발생할 수 있기 때문에 일부로 호스트 네트워크로 잘 사용하지 않을 것 같은 네트워크 대역을 권장하는 것입니다.&lt;/p&gt;

&lt;h2 id=&quot;api-server-주소-설정&quot;&gt;API Server 주소 설정&lt;/h2&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#마스터노드입니다.&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ifconfig 

cni0: &lt;span class=&quot;nv&quot;&gt;flags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt;  mtu 1410
        inet 10.244.0.1  netmask 255.255.255.0  broadcast 10.244.0.255
        inet6 fe80::44f7:e3ff:fe0e:7d15  prefixlen 64  scopeid 0x20&amp;lt;&lt;span class=&quot;nb&quot;&gt;link&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
        ether 46:f7:e3:0e:7d:15  txqueuelen 1000  &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Ethernet&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        RX packets 48997  bytes 4021971 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;4.0 MB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 54114  bytes 4910238 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;4.9 MB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

docker0: &lt;span class=&quot;nv&quot;&gt;flags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4099&amp;lt;UP,BROADCAST,MULTICAST&amp;gt;  mtu 1500
        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255
        ether 02:42:29:4d:09:4f  txqueuelen 0  &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Ethernet&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        RX packets 0  bytes 0 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0.0 B&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 0  bytes 0 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0.0 B&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

ens4: &lt;span class=&quot;nv&quot;&gt;flags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt;  mtu 1460
        inet 10.178.0.2  netmask 255.255.255.255  broadcast 0.0.0.0
        inet6 fe80::4001:aff:feb2:2  prefixlen 64  scopeid 0x20&amp;lt;&lt;span class=&quot;nb&quot;&gt;link&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
        ether 42:01:0a:b2:00:02  txqueuelen 1000  &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Ethernet&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        RX packets 456862  bytes 219264003 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;219.2 MB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 291537  bytes 122783503 &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;122.7 MB&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위 &lt;code&gt;ifconfig&lt;/code&gt; 커맨드의 출력에서 해당 마스터 노드의 IPv4 주소는 ens4 이더넷의 10.178.0.2 인것을 확인할 수 있고, 
&lt;br /&gt;
&lt;code&gt;--apiserver-advertise-address&lt;/code&gt; 옵션을 통해 해당 주소를 kubeadm 에게 전달할 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;rocket마스터-노드-생성-및-실행&quot;&gt;:rocket:마스터 노드 생성 및 실행&lt;/h2&gt;

&lt;p&gt;최종적으로 실행할 &lt;code&gt; kubeadm init &lt;/code&gt;는 아래와 같습니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;kubeadm init &lt;span class=&quot;nt&quot;&gt;--pod-network-cidr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;10.244.0.0/16 &lt;span class=&quot;nt&quot;&gt;--apiserver-advertise-address&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;10.178.0.2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;해당 명령어를 실행했을때 뜨는 결과 창인데요 여기서 짚고가야할 두가지가 있습니다&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;kubeadm init &lt;span class=&quot;nt&quot;&gt;--pod-network-cidr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;10.244.0.0/16 &lt;span class=&quot;nt&quot;&gt;--apiserver-advertise-address&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;10.178.0.2
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;init] Using Kubernetes version: v1.21.1
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;preflight] Running pre-flight checks
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;preflight] Pulling images required &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;setting up a Kubernetes cluster
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;preflight] This might take a minute or two, depending on the speed of your internet connection
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;preflight] You can also perform this action &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;beforehand using &lt;span class=&quot;s1&quot;&gt;&apos;kubeadm config images pull&apos;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;certs] Using certificateDir folder &lt;span class=&quot;s2&quot;&gt;&quot;/etc/kubernetes/pki&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;certs] Generating &lt;span class=&quot;s2&quot;&gt;&quot;ca&quot;&lt;/span&gt; certificate and key
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;certs] Generating &lt;span class=&quot;s2&quot;&gt;&quot;apiserver&quot;&lt;/span&gt; certificate and key
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;certs] apiserver serving cert is signed &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;DNS names &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local master] and IPs &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;10.96.0.1 10.178.0.2]
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;certs] Generating &lt;span class=&quot;s2&quot;&gt;&quot;apiserver-kubelet-client&quot;&lt;/span&gt; certificate and key
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;certs] Generating &lt;span class=&quot;s2&quot;&gt;&quot;front-proxy-ca&quot;&lt;/span&gt; certificate and key
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;certs] Generating &lt;span class=&quot;s2&quot;&gt;&quot;front-proxy-client&quot;&lt;/span&gt; certificate and key
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;certs] Generating &lt;span class=&quot;s2&quot;&gt;&quot;etcd/ca&quot;&lt;/span&gt; certificate and key
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;certs] Generating &lt;span class=&quot;s2&quot;&gt;&quot;etcd/server&quot;&lt;/span&gt; certificate and key
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;certs] etcd/server serving cert is signed &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;DNS names &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;localhost master] and IPs &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;10.178.0.2 127.0.0.1 ::1]
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;certs] Generating &lt;span class=&quot;s2&quot;&gt;&quot;etcd/peer&quot;&lt;/span&gt; certificate and key
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;certs] etcd/peer serving cert is signed &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;DNS names &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;localhost master] and IPs &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;10.178.0.2 127.0.0.1 ::1]
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;certs] Generating &lt;span class=&quot;s2&quot;&gt;&quot;etcd/healthcheck-client&quot;&lt;/span&gt; certificate and key
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;certs] Generating &lt;span class=&quot;s2&quot;&gt;&quot;apiserver-etcd-client&quot;&lt;/span&gt; certificate and key
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;certs] Generating &lt;span class=&quot;s2&quot;&gt;&quot;sa&quot;&lt;/span&gt; key and public key
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;kubeconfig] Using kubeconfig folder &lt;span class=&quot;s2&quot;&gt;&quot;/etc/kubernetes&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;kubeconfig] Writing &lt;span class=&quot;s2&quot;&gt;&quot;admin.conf&quot;&lt;/span&gt; kubeconfig file
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;kubeconfig] Writing &lt;span class=&quot;s2&quot;&gt;&quot;kubelet.conf&quot;&lt;/span&gt; kubeconfig file
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;kubeconfig] Writing &lt;span class=&quot;s2&quot;&gt;&quot;controller-manager.conf&quot;&lt;/span&gt; kubeconfig file
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;kubeconfig] Writing &lt;span class=&quot;s2&quot;&gt;&quot;scheduler.conf&quot;&lt;/span&gt; kubeconfig file
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;kubelet-start] Writing kubelet environment file with flags to file &lt;span class=&quot;s2&quot;&gt;&quot;/var/lib/kubelet/kubeadm-flags.env&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;kubelet-start] Writing kubelet configuration to file &lt;span class=&quot;s2&quot;&gt;&quot;/var/lib/kubelet/config.yaml&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;kubelet-start] Starting the kubelet
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;control-plane] Using manifest folder &lt;span class=&quot;s2&quot;&gt;&quot;/etc/kubernetes/manifests&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;control-plane] Creating static Pod manifest &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;kube-apiserver&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;control-plane] Creating static Pod manifest &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;kube-controller-manager&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;control-plane] Creating static Pod manifest &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;kube-scheduler&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;etcd] Creating static Pod manifest &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;local &lt;/span&gt;etcd &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/etc/kubernetes/manifests&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;wait-control-plane] Waiting &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;the kubelet to boot up the control plane as static Pods from directory &lt;span class=&quot;s2&quot;&gt;&quot;/etc/kubernetes/manifests&quot;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; This can take up to 4m0s
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;apiclient] All control plane components are healthy after 12.003615 seconds
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;upload-config] Storing the configuration used &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;ConfigMap &lt;span class=&quot;s2&quot;&gt;&quot;kubeadm-config&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;the &lt;span class=&quot;s2&quot;&gt;&quot;kube-system&quot;&lt;/span&gt; Namespace
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;kubelet] Creating a ConfigMap &lt;span class=&quot;s2&quot;&gt;&quot;kubelet-config-1.21&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;namespace kube-system with the configuration &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;the kubelets &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;the cluster
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;upload-certs] Skipping phase. Please see &lt;span class=&quot;nt&quot;&gt;--upload-certs&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;mark-control-plane] Marking the node master as control-plane by adding the labels: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;node-role.kubernetes.io/master&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;deprecated&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;mark-control-plane] Marking the node master as control-plane by adding the taints &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;node-role.kubernetes.io/master:NoSchedule]
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;bootstrap-token] Using token: ol9g7l.d1f7klw0uh9kmsm5
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;order &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;nodes to get long term certificate credentials
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;bootstrap-token] configured RBAC rules to allow certificate rotation &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;all node client certificates &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;the cluster
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;bootstrap-token] Creating the &lt;span class=&quot;s2&quot;&gt;&quot;cluster-info&quot;&lt;/span&gt; ConfigMap &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;the &lt;span class=&quot;s2&quot;&gt;&quot;kube-public&quot;&lt;/span&gt; namespace
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;kubelet-finalize] Updating &lt;span class=&quot;s2&quot;&gt;&quot;/etc/kubernetes/kubelet.conf&quot;&lt;/span&gt; to point to a rotatable kubelet client certificate and key
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;addons] Applied essential addon: CoreDNS
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  &lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;/.kube
  &lt;span class=&quot;nb&quot;&gt;sudo cp&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; /etc/kubernetes/admin.conf &lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;/.kube/config
  &lt;span class=&quot;nb&quot;&gt;sudo chown&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-u&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;:&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-g&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;/.kube/config

Alternatively, &lt;span class=&quot;k&quot;&gt;if &lt;/span&gt;you are the root user, you can run:

  &lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KUBECONFIG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run &lt;span class=&quot;s2&quot;&gt;&quot;kubectl apply -f [podnetwork].yaml&quot;&lt;/span&gt; with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can &lt;span class=&quot;nb&quot;&gt;join &lt;/span&gt;any number of worker nodes by running the following on each as root:

kubeadm &lt;span class=&quot;nb&quot;&gt;join &lt;/span&gt;10.178.0.2:6443 &lt;span class=&quot;nt&quot;&gt;--token&lt;/span&gt; ol9g7l.d1f7klw0uh9kmsm5 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;--discovery-token-ca-cert-hash&lt;/span&gt; sha256:723e45876b6726f23ff39566d6ae9046423edae440fd76bd328b40ab9b0a8b7d 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 첫째로는 마스터노드에서 실행해야할 커맨드에요&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;/.kube
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo cp&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; /etc/kubernetes/admin.conf &lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;/.kube/config
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo chown&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-u&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;:&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-g&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;/.kube/config
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;해당 명령어는 Root 계정이 아닌 다른 사용자 계정에서 kubectl 커맨드 명령어를 사용하여 클러스터를 제어하기 위해 사용하는 명령어입니다.
기본적으로 kubernetes에서는 /etc/kubernetes/admin.conf 파일을 가지고 kubernetes 관리자 Role의 인증 및 인가 처리를 하며, 
위 명령어는 사용자 계정의 $HOME/.kube/config 디렉터리에 admin.conf 파일을 복사함으로써 사용자 계정이 kubectl을 사용하면서 관리자 Role의 인증 및 인가 처리를 받을 수 있도록 하는 것입니다.
여기서 말한 사용자 계정이란, 마스터 노드의 Shell에 접속한 계정입니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#두번째로는 각각의 워커노드에 실행시켜줄 커맨드에요 메모장에 복사붙여놓기 해놓으시길 추천드립니다!&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubeadm &lt;span class=&quot;nb&quot;&gt;join &lt;/span&gt;10.178.0.2:6443 &lt;span class=&quot;nt&quot;&gt;--token&lt;/span&gt; ol9g7l.d1f7klw0uh9kmsm5 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;--discovery-token-ca-cert-hash&lt;/span&gt; sha256:723e45876b6726f23ff39566d6ae9046423edae440fd76bd328b40ab9b0a8b7d 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;잃어버리면 토큰 다시받아야하고 귀찮아집니다
물론 24시간지나면 토큰 다시 받아야하긴 하지만요 ㅎㅎ&lt;/p&gt;

&lt;h2 id=&quot;flanner-사용을-위해-pod-네트워크-배포하기&quot;&gt;Flanner 사용을 위해 Pod 네트워크 배포하기&lt;/h2&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl apply &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;이 명령어를 실행하면 아래와 같은 메세지를 확인할 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;podsecuritypolicy.policy/psp.flannel.unprivileged created
clusterrole.rbac.authorization.k8s.io/flannel created
clusterrolebinding.rbac.authorization.k8s.io/flannel created
serviceaccount/flannel created
configmap/kube-flannel-cfg created
daemonset.apps/kube-flannel-ds created
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 마스터 노드가 잘 세팅되었는지 아래 명령어를 통해 확인해볼 수 있습니다.&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;노드 확인하기
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get nodes
NAME         STATUS   ROLES                  AGE   VERSION
master       Ready    control-plane,master   49m   v1.21.1

마스터 노드 내의 모든 pod 확인하기
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get pods &lt;span class=&quot;nt&quot;&gt;--all-namespaces&lt;/span&gt;
NAMESPACE     NAME                             READY   STATUS    RESTARTS   AGE
kube-system   coredns-558bd4d5db-8mclv         1/1     Running   0          49m
kube-system   coredns-558bd4d5db-qbs2t         1/1     Running   0          49m
kube-system   etcd-master                      1/1     Running   0          50m
kube-system   kube-apiserver-master            1/1     Running   0          50m
kube-system   kube-controller-manager-master   1/1     Running   0          50m
kube-system   kube-flannel-ds-dmbnj            1/1     Running   0          45m
kube-system   kube-flannel-ds-gmhfd            1/1     Running   0          44m
kube-system   kube-flannel-ds-h27rp            1/1     Running   0          46m
kube-system   kube-flannel-ds-smnhd            1/1     Running   0          45m
kube-system   kube-proxy-2hxsg                 1/1     Running   0          49m
kube-system   kube-proxy-dhgfh                 1/1     Running   0          44m
kube-system   kube-proxy-q9kwk                 1/1     Running   0          45m
kube-system   kube-proxy-x7m4d                 1/1     Running   0          45m
kube-system   kube-scheduler-master            1/1     Running   0          50m

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;워커-노드-세팅&quot;&gt;워커 노드 세팅&lt;/h2&gt;

&lt;p&gt;마스터 노드 생성후 출력된 메세지 맨아래에서 저장 해놓으라고 했던부분을 쓸 시간이 왔습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;연결하고싶은 모든 워커노드에 아래 커맨드를 입력해주세요&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubeadm &lt;span class=&quot;nb&quot;&gt;join &lt;/span&gt;10.178.0.2:6443 &lt;span class=&quot;nt&quot;&gt;--token&lt;/span&gt; ol9g7l.d1f7klw0uh9kmsm5 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;--discovery-token-ca-cert-hash&lt;/span&gt; sha256:723e45876b6726f23ff39566d6ae9046423edae440fd76bd328b40ab9b0a8b7d 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;마스터노드에서-확인하기&quot;&gt;마스터노드에서 확인하기&lt;/h2&gt;

&lt;p&gt;원래 두개 등록되어있었는데 포스트 작성하면서 하나 더만들어졌네요
두번째 만들때는 그래도 수월하게 진행한것 같습니다.&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;kubectl get nodes
NAME         STATUS   ROLES                  AGE   VERSION
instance-1   Ready    &amp;lt;none&amp;gt;                 44m   v1.21.1
master       Ready    control-plane,master   49m   v1.21.1
worker-1     Ready    &amp;lt;none&amp;gt;                 44m   v1.21.1
worker-2     Ready    &amp;lt;none&amp;gt;                 44m   v1.21.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;긴 글 보시느라 고생많으셨습니다.&lt;/p&gt;</content><author><name>Sanghyuk Jeong</name><email>shjeong920522@gmail.com</email></author><category term="Docker" /><category term="Kubernetes" /><category term="CKA" /><category term="도커" /><category term="컨테이너" /><category term="container" /><category term="etcd" /><category term="Google" /><category term="cloud" /><summary type="html">minikube를 이용하면 정말 간단하게 로컬머신에 테스트환경을 구성할 수 있었습니다 또한 kubectl 커맨드에 친숙해지는데 잘 활용했었지요, 하지만 이는 싱글 노드 클러스트이고, 다른 노드를 추가할 수 없습니다. 그 말은 즉 진또배기 쿠버네티스를 체험할 수 없는것이며 모는 기능을 제대로 체험할 수 없다는 것이지요. 따라서 kubeadm을 이용하여 마스터노드와 워커노드들을 구성해보기로 했습니다. 로컬 환경에서 vagrant와 virtualbox를 통해 실험환경을 구축하고싶었지만 m1 맥에 그런것은 없습니다 ㅠㅠ 어쩌다보니 구글 클라우드를 처음시작하면 무료크레딧으로 300$를 제공하는것을 발견하였고 구글클라우드를 이용하여 쿠버네티스 환경을 구축해보기로 결정했습니다. 이번 포스트에서는 쿠버네티스 설치부터 기본적인 환경까지 구성할것입니다. 쿠버네티스는 기본적으로 마스터 노드 와 워커 노드로 구성됩니다. 마스터 노드는 워커 노드에 Pod를 할당하고 Pod 안에 컨테이너를 띄우게 하는 역할을 합니다. 또한 쿠버네티스의 상태를 관리하고 여러 Pod 들의 스케줄링도 하는 등 쿠버네티스에서 중추적인 역할을 합니다. 워커 노드는 마스터 노드와 통신하면서 Pod를 할당 받고 그 안에 컨테이너를 띄워 유지 및 관리하는 역할을 합니다. 또한 네트워크나 볼륨에 대한 기능도 컨트롤도 합니다. 마스터 노드1개와 와 워커 노드 2개를 생성할 것이며, 운영체제는 Ubuntu 18.04 LTS 를 사용하여 구성하도록 하겠습니다. 그리고 마스터 및 모든 워커노드의 스펙은 아래와 같습니다. CPU : 2 core RAM : 2 GB Storage : 30 GB kubeadm을 활용한 환경구축 kubeadm이란, kubernetes에서 제공하는 기본적인 도구이며, kubernetes 클러스터를 빨리 구축하기 위한 다양한 기능을 제공합니다. kubeadm은 아래와같이 다양한 커맨드명령어를 사용하여 클러스터를 구축할 수 있습니다. kubeadm init Kubernetes 컨트롤 플레인 노드를 초기화합니다. 즉, 마스터 노드를 초기화합니다. kubeadm join Kubernetes 워커 노드를 초기화하고 클러스터에 연결합니다. kubeadm upgrade Kubernetes 클러스터를 업그레이드 합니다. kubeadm token 부트 스트랩 토큰을 사용한 인증에 설명된대로 부트 스트랩 토큰은 클러스터에 참여하는 노드와 제어 평면 노드 사이에 양방향 신뢰를 설정하는 데 사용됩니다. kubeadm reset kubeadm init 혹은 kubeadm join의 변경사항을 최대한 복구합니다. kubeadm version kubeadm 버젼을 보여줍니다. kubeadm alpha 정식으로 배포된 기능은 아니지만 kubernetes측에서 사용자 피드백을 얻기 위해 인증서 갱신, 인증서 만료 확인, 사용자 생성, kubelet 설정 등 다양한 기능을 제공한다고 합니다. 시작하기전에 확인할 것 2GB 또는 그 이상의 메모리(각노드별) 2CPUs 또는 그이상의 시피유 클러스터의 모든 시스템 간 완벽한 네트워크 연결되었는지 확인 모든 노드에 대한 고유한 호스트 이름, 고유한 MAC 주소, 고유한 product_uuid 각노드의 컨트롤러인 kubelet이 제대로 동작하기위해선 swap이 disabled 되어야 합니다. #swap 비활성화하기 swapoff -a 모든 노드의 Mac address 및 product_uuid 확인 로컬 머신의경우 하드웨어 기기들은 각각의 유니크한 주소를 가지는 반면에 가상 머신은 같은 id를 가질 수도 있습니다. 만약에 같은 Mac address 및 product_uuid를 가지고 있으면 설치에 실패 할 수 있기에 확인하여야 합니다. #MAC address 확인하기 ifconfig -a #product_uuid 확인하기 sudo cat /sys/class/dmi/id/product_uuid 위 쉘 커맨드를 각각의노드에 적용하여 중복되는 맥주소나 제품아이디가 있는지 확인합니다. iptables 설정하기 #br_netfilter모듈 로드되었는지 확인하기 $ lsmod | grep br_netfilter # 아무정보도 뜨지않는다. $ #명시적으로 br_netfilter 로드하기 $ sudo modprobe br_netfilter #다시 확인하면 br_netfilter이 로드된걸 볼수 있어요. $ lsmod | grep br_netfilter br_netfilter 28672 0 bridge 176128 1 br_netfilter 리눅스 노드의 iptables가 브리지된 트래픽을 올바르게 보기 위한 요구 사항으로, sysctl 구성에서 net.bridge.bridge-nf-call-iptables 가 1로 설정되어 있는지 확인해야 합니다. 다음3개의 스크립트를 실행해주시면, $ cat &amp;lt;&amp;lt;EOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF $ cat &amp;lt;&amp;lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF $ sudo sysctl --system 아래와같이 뜰거에요. * Applying /etc/sysctl.d/10-console-messages.conf ... kernel.printk = 4 4 1 7 * Applying /etc/sysctl.d/10-ipv6-privacy.conf ... net.ipv6.conf.all.use_tempaddr = 2 net.ipv6.conf.default.use_tempaddr = 2 * Applying /etc/sysctl.d/10-kernel-hardening.conf ... kernel.kptr_restrict = 1 * Applying /etc/sysctl.d/10-link-restrictions.conf ... fs.protected_hardlinks = 1 fs.protected_symlinks = 1 * Applying /etc/sysctl.d/10-lxd-inotify.conf ... fs.inotify.max_user_instances = 1024 * Applying /etc/sysctl.d/10-magic-sysrq.conf ... kernel.sysrq = 176 * Applying /etc/sysctl.d/10-network-security.conf ... net.ipv4.conf.default.rp_filter = 1 net.ipv4.conf.all.rp_filter = 1 net.ipv4.tcp_syncookies = 1 * Applying /etc/sysctl.d/10-ptrace.conf ... kernel.yama.ptrace_scope = 1 * Applying /etc/sysctl.d/10-zeropage.conf ... vm.mmap_min_addr = 65536 * Applying /usr/lib/sysctl.d/50-default.conf ... net.ipv4.conf.all.promote_secondaries = 1 net.core.default_qdisc = fq_codel * Applying /etc/sysctl.d/60-gce-network-security.conf ... net.ipv4.tcp_syncookies = 1 net.ipv4.conf.all.accept_source_route = 0 net.ipv4.conf.default.accept_source_route = 0 net.ipv4.conf.all.accept_redirects = 0 net.ipv4.conf.default.accept_redirects = 0 net.ipv4.conf.all.secure_redirects = 1 net.ipv4.conf.default.secure_redirects = 1 net.ipv4.ip_forward = 0 net.ipv4.conf.all.send_redirects = 0 net.ipv4.conf.default.send_redirects = 0 net.ipv4.conf.all.rp_filter = 1 net.ipv4.conf.default.rp_filter = 1 net.ipv4.icmp_echo_ignore_broadcasts = 1 net.ipv4.icmp_ignore_bogus_error_responses = 1 net.ipv4.conf.all.log_martians = 1 net.ipv4.conf.default.log_martians = 1 kernel.randomize_va_space = 2 kernel.panic = 10 * Applying /etc/sysctl.d/99-cloudimg-ipv6.conf ... net.ipv6.conf.all.use_tempaddr = 0 net.ipv6.conf.default.use_tempaddr = 0 * Applying /etc/sysctl.d/99-sysctl.conf ... * Applying /etc/sysctl.d/k8s.conf ... net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 * Applying /etc/sysctl.conf ... 필수 포트 확인하기 마스터 노드에서 필요한 필수 노트 6443 포트 : Kubernetes API Server / Used By All 2379~2380 포트 : etcd server client API / Used By kube-apiserver, etcd 10250 포트 : Kubelet API / Used By Self, Control plane 10251 포트 : kube-scheduler / Used By Self 10252 포트 : kube-controller-manager / Used By Self 워커 노드에서 필요한 필수 포트 10250 포트 : Kubelet API / Used By Self, Control plane 30000~32767 포트 : NodePort Services / Used By All 컨테이너 런타임 설치하기 저는 docker를 설치할 것입니다.. # 구버전의 도커 설치되어있다면 삭제하기. $ sudo apt-get remove docker docker-engine docker.io containerd runc 도커 공홈에가면 도커 설치하는 방법이 여러가지있는데 저는 그중에서 가장 간단한 방법으로 설치하겠습니다. #도커를 설치해주는 스크립트 get-docker.sh 로저장하기 $ curl -fsSL https://get.docker.com -o get-docker.sh #스크립트 실행하기 $ sudo sh get-docker.sh 아래와같이 뜨면 성공입니다. # Executing docker install script, commit: 7cae5f8b0decc17d6571f9f52eb840fbc13b2737 + sh -c apt-get update -qq &amp;gt;/dev/null + sh -c DEBIAN_FRONTEND=noninteractive apt-get install -y -qq apt-transport-https ca-certificates curl &amp;gt;/dev/null + sh -c curl -fsSL &quot;https://download.docker.com/linux/ubuntu/gpg&quot; | apt-key add -qq - &amp;gt;/dev/null Warning: apt-key output should not be parsed (stdout is not a terminal) + sh -c echo &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable&quot; &amp;gt; /etc/apt/sources.list.d/docker.list + sh -c apt-get update -qq &amp;gt;/dev/null + [ -n ] + sh -c apt-get install -y -qq --no-install-recommends docker-ce &amp;gt;/dev/null + [ -n 1 ] + sh -c DEBIAN_FRONTEND=noninteractive apt-get install -y -qq docker-ce-rootless-extras &amp;gt;/dev/null + sh -c docker version Client: Docker Engine - Community Version: 20.10.6 API version: 1.41 Go version: go1.13.15 Git commit: 370c289 Built: Fri Apr 9 22:46:01 2021 OS/Arch: linux/amd64 Context: default Experimental: true Server: Docker Engine - Community Engine: Version: 20.10.6 API version: 1.41 (minimum version 1.12) Go version: go1.13.15 Git commit: 8728dd2 Built: Fri Apr 9 22:44:13 2021 OS/Arch: linux/amd64 Experimental: false containerd: Version: 1.4.4 GitCommit: 05f951a3781f4f2c1911b05e61c160e9c30eaa8e runc: Version: 1.0.0-rc93 GitCommit: 12644e614e25b05da6fd08a38ffa0cfe1903fdec docker-init: Version: 0.19.0 GitCommit: de40ad0 ================================================================================ To run Docker as a non-privileged user, consider setting up the Docker daemon in rootless mode for your user: dockerd-rootless-setuptool.sh install Visit https://docs.docker.com/go/rootless/ to learn about rootless mode. To run the Docker daemon as a fully privileged service, but granting non-root users access, refer to https://docs.docker.com/go/daemon-access/ WARNING: Access to the remote API on a privileged Docker daemon is equivalent to root access on the host. Refer to the &apos;Docker daemon attack surface&apos; documentation for details: https://docs.docker.com/go/attack-surface/ ================================================================================ 혹시 모르니 도커 커맨드를 써서 설치가 잘되었는지 확인해봅니다 $ sudo docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES Docker 설치가 완료 되었으면, Docker 데몬이 사용하는 드라이버를 cgroupfs 대신 systemd를 사용하도록 설정합니다 왜냐하면 kubernetes에서 권장하는 Docker 데몬의 드라이버는 systemd 이기 때문이고, systemd를 사용하면 kubernetes가 클러스터 노드에서 사용 가능한 자원을 쉽게 알 수 있도록 해주기 때문입니다. 또한, 시스템에 두개의 cgroup관리자가 있으면 리소스가 부족할 때 불안정해지는 사례가 있다고 하니 무조건적으로 설정해줍시다. 아래 명령어를 통해 Docker 데몬의 드라이버를 교체합니다. $ sudo mkdir /etc/docker $ cat &amp;lt;&amp;lt;EOF | sudo tee /etc/docker/daemon.json { &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: { &quot;max-size&quot;: &quot;100m&quot; }, &quot;storage-driver&quot;: &quot;overlay2&quot; } EOF #도커 재시작과 부팅시 실행되게 설정 $ sudo systemctl enable docker $ sudo systemctl daemon-reload $ sudo systemctl restart docker kubeadm, kubelet 및 kubectl 설치하기 kubeadm은 kubelet 또는 kubectl 을 설치하거나 관리하지 않으므로, kubeadm이 설치하려는 쿠버네티스 컨트롤 플레인의 버전과 일치하는지 확인해야 합니다 따라서 kubeadm 및 쿠버네티스를 업그레이드 할 때에는 버전에 신경쓰셔야 합니다. 아래에서는 kubeadm, kubelet, 및 kubectl 설치후에 업데이트를 홀드 시킴으로써 실수로 sudo apt-get update 실행한 커맨드가 해당 패키지에 영향이 가지 않도록 할것입니다. # 패키지 색인을 최신으로 업데이트하고, kubeadm, kubelet, 및 kubectl 를 설치하는데 필요한 패키지 설치하기. $ sudo apt-get update $ sudo apt-get install -y apt-transport-https ca-certificates curl # 구글 클라우드의 공개 사이닝 키를 다운로드 하기. $ sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg # 쿠버네티스 apt 리포지터리를 추가하기. # *apt리포는 apt 도구로 읽을 수있는 deb 패키지 및 메타 데이터 파일이 포함 된 네트워크 서버 또는 로컬 디렉토리입니다* $ echo &quot;deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main&quot; | sudo tee /etc/apt/sources.list.d/kubernetes.list # apt 패키지 색인을 업데이트 후 kubeadm, kubelet 및 kubectl다운로드 한다음, 버전 고정시키기. $ sudo apt-get update $ sudo apt-get install -y kubelet kubeadm kubectl $ sudo apt-mark hold kubelet kubeadm kubectl :star:처음부터 이 줄 윗부분까지는 마스터노드와 워커노드 모두에 적용되어야 할 내용입니다:star: 마스터 노드 세팅 마스터 노드를 실행시키려면 kubeadm init 커맨드를 사용해야합니다. 해당명령어에는 여러가지 옵션이 들어가는데, 여기서 필요한 옵션값은 다음과 같습니다. –pod-network-cidr : Pod 네트워크를 설정할 때 사용 –apiserver-advertise-address : 특정 마스터 노드의 API Server 주소를 설정할 때 사용 Pod 네트워크 설정 우선 세팅할 클러스터에서 Pod가 서로 통신할 수 있도록 Pod 네트워크 애드온을 설치 해야 합니다. kubeadm을 통해 만들어진 클러스터는 CNI(Container Network Interface) 기반의 애드온이 필요합니다. 기본적으로 k8s에서 제공해주는 kubenet이라는 네트워크 플러그인이 있지만, 매우 기본적이고 간단한 기능만 제공하는 네트워크 플러그인이기 때문에 이 자체로는 크로스 노드 네트워킹이나 네트워크 정책과 같은 기능들은 구현되어 있지 않습니다. 따라서 kubeadm은 kubernetes가 기본적으로 지원해주는 네트워크 플러그인인 kubenet을 지원하지 않고, CNI 기반 네트워크만 지원합니다. 여기서는 Flannel이라는 Pod 네트워크 애드온을 설치하여 사용할 것입니다. Flannel을 사용하려면 kubeadm init 명령어에 –pod-network-cidr=10.244.0.0/16 이라는 인자를 추가해서 실행해야 하며, 10.244.0.0/16 이라는 네트워크는 Flannel에서 기본적으로 권장하는 네트워크 대역입니다. Pod 네트워크가 호스트 네트워크와 겹치면 문제가 발생할 수 있기 때문에 일부로 호스트 네트워크로 잘 사용하지 않을 것 같은 네트워크 대역을 권장하는 것입니다. API Server 주소 설정 #마스터노드입니다. $ ifconfig cni0: flags=4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt; mtu 1410 inet 10.244.0.1 netmask 255.255.255.0 broadcast 10.244.0.255 inet6 fe80::44f7:e3ff:fe0e:7d15 prefixlen 64 scopeid 0x20&amp;lt;link&amp;gt; ether 46:f7:e3:0e:7d:15 txqueuelen 1000 (Ethernet) RX packets 48997 bytes 4021971 (4.0 MB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 54114 bytes 4910238 (4.9 MB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 docker0: flags=4099&amp;lt;UP,BROADCAST,MULTICAST&amp;gt; mtu 1500 inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255 ether 02:42:29:4d:09:4f txqueuelen 0 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ens4: flags=4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt; mtu 1460 inet 10.178.0.2 netmask 255.255.255.255 broadcast 0.0.0.0 inet6 fe80::4001:aff:feb2:2 prefixlen 64 scopeid 0x20&amp;lt;link&amp;gt; ether 42:01:0a:b2:00:02 txqueuelen 1000 (Ethernet) RX packets 456862 bytes 219264003 (219.2 MB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 291537 bytes 122783503 (122.7 MB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 위 ifconfig 커맨드의 출력에서 해당 마스터 노드의 IPv4 주소는 ens4 이더넷의 10.178.0.2 인것을 확인할 수 있고, --apiserver-advertise-address 옵션을 통해 해당 주소를 kubeadm 에게 전달할 수 있습니다. :rocket:마스터 노드 생성 및 실행 최종적으로 실행할 kubeadm init 는 아래와 같습니다. $ sudo kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=10.178.0.2 해당 명령어를 실행했을때 뜨는 결과 창인데요 여기서 짚고가야할 두가지가 있습니다 $ sudo kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=10.178.0.2 [init] Using Kubernetes version: v1.21.1 [preflight] Running pre-flight checks [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos; [certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot; [certs] Generating &quot;ca&quot; certificate and key [certs] Generating &quot;apiserver&quot; certificate and key [certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local master] and IPs [10.96.0.1 10.178.0.2] [certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key [certs] Generating &quot;front-proxy-ca&quot; certificate and key [certs] Generating &quot;front-proxy-client&quot; certificate and key [certs] Generating &quot;etcd/ca&quot; certificate and key [certs] Generating &quot;etcd/server&quot; certificate and key [certs] etcd/server serving cert is signed for DNS names [localhost master] and IPs [10.178.0.2 127.0.0.1 ::1] [certs] Generating &quot;etcd/peer&quot; certificate and key [certs] etcd/peer serving cert is signed for DNS names [localhost master] and IPs [10.178.0.2 127.0.0.1 ::1] [certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key [certs] Generating &quot;apiserver-etcd-client&quot; certificate and key [certs] Generating &quot;sa&quot; key and public key [kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot; [kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file [kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file [kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file [kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file [kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot; [kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot; [kubelet-start] Starting the kubelet [control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot; [control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot; [control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot; [control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot; [etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot; [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s [apiclient] All control plane components are healthy after 12.003615 seconds [upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace [kubelet] Creating a ConfigMap &quot;kubelet-config-1.21&quot; in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --upload-certs [mark-control-plane] Marking the node master as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers] [mark-control-plane] Marking the node master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: ol9g7l.d1f7klw0uh9kmsm5 [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstrap-token] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace [kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 10.178.0.2:6443 --token ol9g7l.d1f7klw0uh9kmsm5 \ --discovery-token-ca-cert-hash sha256:723e45876b6726f23ff39566d6ae9046423edae440fd76bd328b40ab9b0a8b7d # 첫째로는 마스터노드에서 실행해야할 커맨드에요 $ mkdir -p $HOME/.kube $ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config 해당 명령어는 Root 계정이 아닌 다른 사용자 계정에서 kubectl 커맨드 명령어를 사용하여 클러스터를 제어하기 위해 사용하는 명령어입니다. 기본적으로 kubernetes에서는 /etc/kubernetes/admin.conf 파일을 가지고 kubernetes 관리자 Role의 인증 및 인가 처리를 하며, 위 명령어는 사용자 계정의 $HOME/.kube/config 디렉터리에 admin.conf 파일을 복사함으로써 사용자 계정이 kubectl을 사용하면서 관리자 Role의 인증 및 인가 처리를 받을 수 있도록 하는 것입니다. 여기서 말한 사용자 계정이란, 마스터 노드의 Shell에 접속한 계정입니다. #두번째로는 각각의 워커노드에 실행시켜줄 커맨드에요 메모장에 복사붙여놓기 해놓으시길 추천드립니다! $ kubeadm join 10.178.0.2:6443 --token ol9g7l.d1f7klw0uh9kmsm5 \ --discovery-token-ca-cert-hash sha256:723e45876b6726f23ff39566d6ae9046423edae440fd76bd328b40ab9b0a8b7d 잃어버리면 토큰 다시받아야하고 귀찮아집니다 물론 24시간지나면 토큰 다시 받아야하긴 하지만요 ㅎㅎ Flanner 사용을 위해 Pod 네트워크 배포하기 $ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 이 명령어를 실행하면 아래와 같은 메세지를 확인할 수 있습니다. podsecuritypolicy.policy/psp.flannel.unprivileged created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created serviceaccount/flannel created configmap/kube-flannel-cfg created daemonset.apps/kube-flannel-ds created 이제 마스터 노드가 잘 세팅되었는지 아래 명령어를 통해 확인해볼 수 있습니다. 노드 확인하기 $ kubectl get nodes NAME STATUS ROLES AGE VERSION master Ready control-plane,master 49m v1.21.1 마스터 노드 내의 모든 pod 확인하기 $ kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-558bd4d5db-8mclv 1/1 Running 0 49m kube-system coredns-558bd4d5db-qbs2t 1/1 Running 0 49m kube-system etcd-master 1/1 Running 0 50m kube-system kube-apiserver-master 1/1 Running 0 50m kube-system kube-controller-manager-master 1/1 Running 0 50m kube-system kube-flannel-ds-dmbnj 1/1 Running 0 45m kube-system kube-flannel-ds-gmhfd 1/1 Running 0 44m kube-system kube-flannel-ds-h27rp 1/1 Running 0 46m kube-system kube-flannel-ds-smnhd 1/1 Running 0 45m kube-system kube-proxy-2hxsg 1/1 Running 0 49m kube-system kube-proxy-dhgfh 1/1 Running 0 44m kube-system kube-proxy-q9kwk 1/1 Running 0 45m kube-system kube-proxy-x7m4d 1/1 Running 0 45m kube-system kube-scheduler-master 1/1 Running 0 50m 워커 노드 세팅 마스터 노드 생성후 출력된 메세지 맨아래에서 저장 해놓으라고 했던부분을 쓸 시간이 왔습니다. 연결하고싶은 모든 워커노드에 아래 커맨드를 입력해주세요 $ kubeadm join 10.178.0.2:6443 --token ol9g7l.d1f7klw0uh9kmsm5 \ --discovery-token-ca-cert-hash sha256:723e45876b6726f23ff39566d6ae9046423edae440fd76bd328b40ab9b0a8b7d 마스터노드에서 확인하기 원래 두개 등록되어있었는데 포스트 작성하면서 하나 더만들어졌네요 두번째 만들때는 그래도 수월하게 진행한것 같습니다. $ kubectl get nodes NAME STATUS ROLES AGE VERSION instance-1 Ready &amp;lt;none&amp;gt; 44m v1.21.1 master Ready control-plane,master 49m v1.21.1 worker-1 Ready &amp;lt;none&amp;gt; 44m v1.21.1 worker-2 Ready &amp;lt;none&amp;gt; 44m v1.21.1 긴 글 보시느라 고생많으셨습니다.</summary></entry><entry><title type="html">[ #1 ] Kubernetes의 구조</title><link href="https://shjeong92.github.io/2021/05/26/Learning-Kubernetes-01.html" rel="alternate" type="text/html" title="[ #1 ] Kubernetes의 구조" /><published>2021-05-26T00:00:00+09:00</published><updated>2021-05-26T00:00:00+09:00</updated><id>https://shjeong92.github.io/2021/05/26/Learning-Kubernetes-01</id><content type="html" xml:base="https://shjeong92.github.io/2021/05/26/Learning-Kubernetes-01.html">&lt;h2 id=&quot;etcd란-무엇인가&quot;&gt;ETCD란 무엇인가?&lt;/h2&gt;

&lt;h3 id=&quot;distributed-reliable-key-value-store&quot;&gt;Distributed Reliable Key Value Store&lt;/h3&gt;
&lt;p&gt;분산 시스템의 중요한 데이터를위한 신뢰할 수있는 분산 key/value 저장소이며 다음과 같은 특징이 있습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;단순함: 잘 정의 된 사용자용 API&lt;/li&gt;
  &lt;li&gt;보안: 선택적 클라이언트 인증을 사용하는 자동 TLS&lt;/li&gt;
  &lt;li&gt;속도: 10000 쓰기 / sec&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mac에-etcd-설치하여-사용해보기&quot;&gt;mac에 etcd 설치하여 사용해보기&lt;/h2&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# brew를 이용하여 간편히 설치&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;brew &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;etcd
&lt;span class=&quot;c&quot;&gt;# etcd를 백그라운드 환경으로 실행시키기&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;brew services start etcd

&lt;span class=&quot;c&quot;&gt;# Key value 생성&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;etcdctl put key &lt;span class=&quot;s2&quot;&gt;&quot;I am a value&quot;&lt;/span&gt;
OK

&lt;span class=&quot;c&quot;&gt;# Key를 통한 value 호출&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;etcdctl get key
key
I am a value

&lt;span class=&quot;c&quot;&gt;# Key 삭제하기&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;etcdctl del key
1

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;rocket-마스터&quot;&gt;:rocket: 마스터&lt;/h1&gt;

&lt;h2 id=&quot;kubernetes-안의-etcd-클러스터&quot;&gt;Kubernetes 안의 etcd 클러스터&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Nodes&lt;/li&gt;
  &lt;li&gt;Pods&lt;/li&gt;
  &lt;li&gt;Configs&lt;/li&gt;
  &lt;li&gt;Secrets&lt;/li&gt;
  &lt;li&gt;Accounts&lt;/li&gt;
  &lt;li&gt;Roles&lt;/li&gt;
  &lt;li&gt;Bindings&lt;/li&gt;
  &lt;li&gt;Others&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;모든 클러스터 데이터를 담는 쿠버네티스 뒷단의 저장소로 사용되는 일관성·고가용성 키-값 저장소입니다.&lt;/p&gt;

&lt;h2 id=&quot;kube-apiserver&quot;&gt;kube-apiserver&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;kubernetes의 API server이며 worker node를 관리하는 Kubelet과 통신합니다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;kubectl 을 통하여 kube-apiserver과 통신하는것 이외에도 post request를 통해서도 가능합니다.&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Authenticate User
        &lt;ul&gt;
          &lt;li&gt;사용자가 인장된 사용자인지 확인&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Validate Request
        &lt;ul&gt;
          &lt;li&gt;요청이 올바른 요청인지 확인&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Retrieve data
        &lt;ul&gt;
          &lt;li&gt;요청에 대한 결과를 응답한다. (ex. Pod 생성 요청 완료)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Updatae ETCD
        &lt;ul&gt;
          &lt;li&gt;생성 요청된 POD 정보를 ETCD에 업데이트 합니다ㅣ.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Scheduler
        &lt;ul&gt;
          &lt;li&gt;Scheduler에게 POD이 배치될 Worker Node를 요청합니다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Kubelet
        &lt;ul&gt;
          &lt;li&gt;Schduler에게 받은 Worker Node의 Kubelet에게 POD 생성을 요청합니다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;kube-scheduler&quot;&gt;kube-scheduler&lt;/h2&gt;

&lt;p&gt;스케줄러는 생성되었지만 배정되지 못하여 실행되지 않은 컨테이너를 감지하고 실행할 노드를 선택하는 역할을 합니다. 스케줄링 결정을 위해서 고려되는 요소는 리소스에 대한 개별 및 총체적 요구 사항, 노드의 상태, 제약 조건등을 포함.&lt;/p&gt;

&lt;h2 id=&quot;kube-controller-manager&quot;&gt;Kube Controller Manager&lt;/h2&gt;

&lt;p&gt;컨트롤러를 구동하는 컴포넌트로, 앞에서 설명한 control-loop를 돌면서 current state가 desired state로 되도록 바꾸어주는 역할을 담당한다. 컨트롤러의 종류에도 여러가지가 존재하는데 논리적으로 각 컨트롤러는 개별 프로세스이지만 복잡성을 낮추기 위해 모두 단일 바이너리로 컴파일되고 단일 프로세스 내에서 실행된다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;노드 컨트롤러: 노드 컨트롤러: 노드가 다운되었을 때에 대응.&lt;/li&gt;
  &lt;li&gt;레플리케이션 컨트롤러: 레플리케이션 오브젝트에서 알맞은 수의 Pod를 유지.&lt;/li&gt;
  &lt;li&gt;엔드포인트 컨트롤러: 서비스와 Pod를 연결.&lt;/li&gt;
  &lt;li&gt;서비스 어카운트 &amp;amp; 토큰 컨트롤러: 새로운 네임스페이스에 대한 기본 계정과 API 접근 토큰을 생성.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cloud-controller-manager&quot;&gt;Cloud-controller-manager&lt;/h2&gt;
&lt;p&gt;클라우드별 컨트롤 로직을 포함하는 쿠버네티스 컨트롤 플레인 컴포넌트. 클라우드 컨트롤러 매니저를 통해 클러스터를 클라우드에 연결하여 클라우드 플랫폼의 리소스를 추가 및 사용할 수 있습니다. kube-controller-manager와 마찬가지로 cloud-controller-manager도 논리적으로 독립적인 여러 control-loop를 단일 프로세스로 실행하는 단일 바이너리로 결합합니다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;
다음 컨트롤러들은 클라우드 플랫폼의 의존성을 가질 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;노드 컨트롤러: 노드가 응답을 멈춘 후 클라우드 상에서 삭제되었는지 판별하기 위해 클라우드 제공 사업자에게 확인하는 것&lt;/li&gt;
  &lt;li&gt;라우트 컨트롤러: 기본 클라우드 인프라에 경로를 구성하는 것&lt;/li&gt;
  &lt;li&gt;서비스 컨트롤러: 클라우드 제공 사업자 로드밸런서를 생성, 업데이트 그리고 삭제하는 것&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;rocket-워커-노드&quot;&gt;:rocket: 워커 노드&lt;/h1&gt;
&lt;p&gt;워커 노드는 마스터로부터 전달받은 명령에 따라 컨테이너를 실행합니다.&lt;/p&gt;

&lt;h2 id=&quot;kubelet노드-관리자&quot;&gt;kubelet(노드 관리자)&lt;/h2&gt;
&lt;p&gt;클러스터의 각 노드에서 실행되는 핵심 컴포넌트로 다양한 메커니즘을 통해 제공된 명세(Spec)의 집합을 받아서 컨테이너를 실행시킵니다. 여기서 끝나는 것이 아니라 정상적으로 동작하는지 지속적으로 모니터링하고 주기적으로 마스터 노드의 api 서버와 통신하여 정보를 주고받습니다.&lt;/p&gt;

&lt;h2 id=&quot;kube-proxy&quot;&gt;kube-proxy&lt;/h2&gt;
&lt;p&gt;클러스터의 각 노드에서 실행되는 네트워크 프록시로, 쿠버네티스의 서비스 오브젝트를 구현합니다. 즉 노드의 네트워크 규칙을 관리하여 서비스마다 개별 IP를 가질 수 있게 만들어주고 클러스터 내부나 외부의 트래픽을 Pod로 전달할 수있도록 해줍니다.&lt;/p&gt;

&lt;h2 id=&quot;container-runtime&quot;&gt;container runtime&lt;/h2&gt;
&lt;p&gt;실제 컨테이너 실행을 담당하는 소프트웨어이다. 예를 들어 도커, CRI-O, containerd 등이 있습니다.&lt;/p&gt;</content><author><name>Sanghyuk Jeong</name><email>shjeong920522@gmail.com</email></author><category term="Docker" /><category term="Kubernetes" /><category term="CKA" /><category term="도커" /><category term="컨테이너" /><category term="container" /><category term="etcd" /><summary type="html">ETCD란 무엇인가? Distributed Reliable Key Value Store 분산 시스템의 중요한 데이터를위한 신뢰할 수있는 분산 key/value 저장소이며 다음과 같은 특징이 있습니다. 단순함: 잘 정의 된 사용자용 API 보안: 선택적 클라이언트 인증을 사용하는 자동 TLS 속도: 10000 쓰기 / sec mac에 etcd 설치하여 사용해보기 # brew를 이용하여 간편히 설치 $ brew install etcd # etcd를 백그라운드 환경으로 실행시키기 $ brew services start etcd # Key value 생성 $ etcdctl put key &quot;I am a value&quot; OK # Key를 통한 value 호출 $ etcdctl get key key I am a value # Key 삭제하기 $ etcdctl del key 1 :rocket: 마스터 Kubernetes 안의 etcd 클러스터 Nodes Pods Configs Secrets Accounts Roles Bindings Others 모든 클러스터 데이터를 담는 쿠버네티스 뒷단의 저장소로 사용되는 일관성·고가용성 키-값 저장소입니다. kube-apiserver kubernetes의 API server이며 worker node를 관리하는 Kubelet과 통신합니다. kubectl 을 통하여 kube-apiserver과 통신하는것 이외에도 post request를 통해서도 가능합니다. Authenticate User 사용자가 인장된 사용자인지 확인 Validate Request 요청이 올바른 요청인지 확인 Retrieve data 요청에 대한 결과를 응답한다. (ex. Pod 생성 요청 완료) Updatae ETCD 생성 요청된 POD 정보를 ETCD에 업데이트 합니다ㅣ. Scheduler Scheduler에게 POD이 배치될 Worker Node를 요청합니다. Kubelet Schduler에게 받은 Worker Node의 Kubelet에게 POD 생성을 요청합니다. kube-scheduler 스케줄러는 생성되었지만 배정되지 못하여 실행되지 않은 컨테이너를 감지하고 실행할 노드를 선택하는 역할을 합니다. 스케줄링 결정을 위해서 고려되는 요소는 리소스에 대한 개별 및 총체적 요구 사항, 노드의 상태, 제약 조건등을 포함. Kube Controller Manager 컨트롤러를 구동하는 컴포넌트로, 앞에서 설명한 control-loop를 돌면서 current state가 desired state로 되도록 바꾸어주는 역할을 담당한다. 컨트롤러의 종류에도 여러가지가 존재하는데 논리적으로 각 컨트롤러는 개별 프로세스이지만 복잡성을 낮추기 위해 모두 단일 바이너리로 컴파일되고 단일 프로세스 내에서 실행된다. 노드 컨트롤러: 노드 컨트롤러: 노드가 다운되었을 때에 대응. 레플리케이션 컨트롤러: 레플리케이션 오브젝트에서 알맞은 수의 Pod를 유지. 엔드포인트 컨트롤러: 서비스와 Pod를 연결. 서비스 어카운트 &amp;amp; 토큰 컨트롤러: 새로운 네임스페이스에 대한 기본 계정과 API 접근 토큰을 생성. Cloud-controller-manager 클라우드별 컨트롤 로직을 포함하는 쿠버네티스 컨트롤 플레인 컴포넌트. 클라우드 컨트롤러 매니저를 통해 클러스터를 클라우드에 연결하여 클라우드 플랫폼의 리소스를 추가 및 사용할 수 있습니다. kube-controller-manager와 마찬가지로 cloud-controller-manager도 논리적으로 독립적인 여러 control-loop를 단일 프로세스로 실행하는 단일 바이너리로 결합합니다. 다음 컨트롤러들은 클라우드 플랫폼의 의존성을 가질 수 있다. 노드 컨트롤러: 노드가 응답을 멈춘 후 클라우드 상에서 삭제되었는지 판별하기 위해 클라우드 제공 사업자에게 확인하는 것 라우트 컨트롤러: 기본 클라우드 인프라에 경로를 구성하는 것 서비스 컨트롤러: 클라우드 제공 사업자 로드밸런서를 생성, 업데이트 그리고 삭제하는 것 :rocket: 워커 노드 워커 노드는 마스터로부터 전달받은 명령에 따라 컨테이너를 실행합니다. kubelet(노드 관리자) 클러스터의 각 노드에서 실행되는 핵심 컴포넌트로 다양한 메커니즘을 통해 제공된 명세(Spec)의 집합을 받아서 컨테이너를 실행시킵니다. 여기서 끝나는 것이 아니라 정상적으로 동작하는지 지속적으로 모니터링하고 주기적으로 마스터 노드의 api 서버와 통신하여 정보를 주고받습니다. kube-proxy 클러스터의 각 노드에서 실행되는 네트워크 프록시로, 쿠버네티스의 서비스 오브젝트를 구현합니다. 즉 노드의 네트워크 규칙을 관리하여 서비스마다 개별 IP를 가질 수 있게 만들어주고 클러스터 내부나 외부의 트래픽을 Pod로 전달할 수있도록 해줍니다. container runtime 실제 컨테이너 실행을 담당하는 소프트웨어이다. 예를 들어 도커, CRI-O, containerd 등이 있습니다.</summary></entry></feed>