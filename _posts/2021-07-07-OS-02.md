---
layout: article
title: "[ #2 ] 운영체제 - 가상메모리"
tags: OS 운영체제 가상메모리
---

### 가상 메모리란?

가상 메모리는 메모리를 관리하는 방법의 하나로, 각 프로그램에 실제 메모리 주소가 아닌 가상의 메모리 주소를 주는 방식을 말합니다.
이러한 방식은 멀티태스킹 운영체제에서 흔히 사용되며, RAM보다 큰 영역으로 제공하는 방법으로 사용된다고 합니다.

--- 

### 가상 메모리의 등장 배경

- **"RAM은 결코 충분하지 않다."**
이 말은 옛날부터 운영체제 설계자들이 고민해 왔던 말이라고 하는데요,
예를들어, 가상 메모리의 개념을 사용하지 않는 시스템에서 어플리케이션 수행 시 1기가 바이트의 용량을 차지하는 프로그램이 있다고 가정해 보면, 시스템의 메모리는 최소 1기가 바이트 이상이 되어야 할 것입니다. 만일, 1바이트라도 모자라다면 메모리 부족 오류가 나야하죠. 요즘 게임프로그램은 용량이 어마어마하죠? 수십기가는 그냥 넘는데도 16GB램에서 별 탈없이 돌아갑니다. 어떻게 가능했던걸까요?


가상 메모리는 프로그램이 차지하는 주소공간의 개념에 대해 조금 다르게 접근한다고 합니다.
가상 메모리를 사용하는 운영체제는 "프로그램을 실행하는데 얼마나 많은 메모리가 필요한가?"에 집중하지 않고, **프로그램을 실행하는데 필요한 최소한의 메모리는 얼마인가?**에 대해 고민하기 시작했다고 합니다.

메모리 접근은 순차적이고 지역화되어 있다는 특성때문에 어플리케이션을 실행하는데 완전한 1기가 바이트가 필요한 것처럼 보이지만, 사실 이 어플리케이션을 실행하는데 필요한 메모리 용량은 1기가바이트 보다 훨씬 적게 된다고 합니다.

---

위에서 말한 1기가바이트의 프로그램이 실행하는데 필요한 최소한의 처리 순서를 아래와 같이 가정해 봅시다.
1. 메모리에서 명령 읽어오기
2. 명령어가 필요로하는 데이터도 메모리에서 읽어오기
3. 명령이 완료된 후, 결과가 메모리에 기록됨

예를들어, 이 각각의 명령 처리에 10메가 바이트씩의 메모리가 할당 되어야 한다면, 고작 30메가바이트 만으로 프로그램을 실행 시킬 수 있다는 말이죠.

그렇다면 실행한 다음은 어떻게 되는걸까요?

프로그램의 나머지 기능을 수행할 코드나 데이터부분의 처리를 위한 메모리 할당은 어떻게 해야 할까요?
그 나머지는 어디에 위치해야 할까요?

- 바로, **보조 기억장치(하드,SSD)**입니다.

현재 필요하거나 향후 필요할 어플리케이션의 일부분을 필요한만큼 계속 RAM에 올려 놓도록 가상 메모리 하부 시스템을 구축하여 동작할 수만 있다면, 하드디스크를 RAM의 보조기억장치로 쓰는데 문제가 없는 것입니다.
이러한 방식은 빠르고 작은 기억장치를 크고 느린 기억장치와 병합하여 하나의 크고 빠른 기억장치처럼 작동하게 한다는 면에서 캐시(Cache)와 RAM의 관계와도 유사하다고 할 수 있습니다.

--- 

### 가상 주소 공간

가상 주소 공간이란 어플리케이션이 사용 가능한 최대 주소 공간을 말합니다.

 
CPU 아키텍쳐에 따라 주소지정을 위해 필요한 비트수가 달라지기 때문에 가상 주소 공간은 아키텍쳐에 따라 달라지게 된다. CPU 아키텍쳐는 레지스터(Resiter)의 크기와 관련이 있습니다.

예를들어, 32비트 CPU는 2^32 = 4294967296로 0 ~ 4294967295 까지의 주소 공간을 나타낼 수 
있습니다

여기에 메모리의 가장 작은 단위는 Byte이기 때문에 4GByte가 되는 것입니다.
때문에 각 어플리케이션들은 4GB의 주소공간을 가질 수 있고, 32비트 시스템의 운영체제에서 RAM이 4GB까지 밖에 인식 못 하는 이유도 여기에 있었던 것이지요.

그렇다면 64bit cpu는 얼마나 많은 물리적 주소공간을 가질 수 있을까요?

2^64 즉 184467440709551616(16엑사바이트) 엄청나게 큰 숫자입니다. 하지만 실제로는 하위 48bit만 사용한다고 합니다. 이는 256TB에 향하는 주소 범위인데요 16엑사바이트 만큼의 큰 양의 메모리 어드레싱이 필요하지 않기 때문이라고 합니다.

--- 

### 가상메모리 동작 방법

이제 가상메모리가 어떻게 동작하는지 알아봅시다.

대표적인 가상 메모리 기법으로 페이징(paging), 세그멘테이션(segmentation)이 있는데, 현대 운영체제에서는 두가지 방식이 혼용되어 사용된다고 합니다.

- 페이징 - 고정분할 - 페이지 테이블
- 세그멘테이션 - 가변 분할 - 세그멘테이션 테이블




![vm01](https://user-images.githubusercontent.com/75003424/124723850-6af3cf00-df46-11eb-92b3-42e6c2c5903e.png)

### 페이징(Paging)

페이징이란 고정 크기로 분할된 페이지(page)를 통해 가상 메모리를 관리하는 기법입니다


- 페이지(page) : 가상 메모리를 고정 크기로 나눈 블록
- 프레임(frame) : 실제 메모리를 페이지와 같은 크기로 나눈 블록 (= 페이지 프레임)

프레임과 페이지는 메모리를 일정한 크기의 공간으로 나누어 관리하는 단위이며, 프레임과 페이지의 크기는 같습니다.

##### 페이지와 프레임간의 관계
- Vitual Memory의 page가 하나의 frame을 할당 받으면, 물리 메모리에 위치하게 된다.
- 프레임을 할당 받지 못한 페이지들은 외부 저장장치에 저장되며, 이때도 프레임과 같은 크기 단위로 관리된다.

##### 페이지 테이블(Page Table)

프로세스의 페이지 정보를 저장하고 있는 테이블
=> page에 매핑되는 frame을 찾을 때 참조함

페이지 테이블 정보
- 키(또는 인덱스): 페이지 번호
- 값
  - 페이지와 매핑된 frame 번호
  - 기타 플래그 정보(페이지 존재 유무, R/W 권한, 접근권한)

---

### MMU(Memory Management Unit)란?
MMU는 CPU가 메모리에 접근하는 것을 관리하는 컴퓨터 하드웨어 부품인데요,
가상 메모리 주소를 실제 메모리 주소로 변환하며, 메모리 보호, 캐시 관리, 버스 중재 등의 역할을 담당합니다.

MMU는 페이지를 기본 단위로 가상 주소를 실제 물리 주소로 매핑 시키는 역할을 합니다.
변화 과정에서, TLB와 Page Table이 사용됩니다.


TLB : 캐시 역할. 자주 사용되는 페이지 저장
Page Table : 물리 주소와 연관시킬 수 있는 페이지가 저장되어 있는 자료구조

![vm06](https://user-images.githubusercontent.com/75003424/124724971-71367b00-df47-11eb-9787-91d23fd3ea2e.png)

---

### 페이징 기법에서의 주소 바인딩 과정
![vm02](https://user-images.githubusercontent.com/75003424/124723860-6cbd9280-df46-11eb-8997-67e21400e663.png)

- P: 페이지번호
- d: 변위
- f: 프레임 번호

1. CPU에서 사용하는 logical address는 페이지 번호(P)와 변위(d)로 구성
2. Page Table에서 페이지 번호에 해당하는 프레임 시작 주소를 찾음
3. 프레임 시작 주소(f) + 변위(d)를 통해 물리 주소를 계산하여 실제 물리 주소에 접근

이러한 변환은 MMU(Memory Management Unit)에 의해 이루워 집니다.
이러한 변환 과정은 MMU에서 이루어 지며, 페이지 정보가 캐싱 되어 있을 경우 TLB를 통해 빠르게 접근하도록 합니다.


![vm03](https://user-images.githubusercontent.com/75003424/124723863-6d562900-df46-11eb-9980-4a3f1900a25e.png)



<br>

그렇다면 **어떻게 캐싱 되어 있는지** 알 수 있을까요??
페이지 테이블은 **PTE**라고 하는 레코드를 갖는데, 이 **PTE**를 통해 캐싱 되어 있는지 알 수 있습니다.

<br>


![vm04](https://user-images.githubusercontent.com/75003424/124723865-6deebf80-df46-11eb-8529-ad658ea5a360.png)
 

페이지 테이블의 레코드로 프레임 번호와 여러 플레그로 이루어져 구성되어 있습니다.

 

##### 포함 정보

- Frame Number : 프레임 번호
- Present/Absent : 메인 메모리에 페이지가 존재하는지 확인하는 비트 필드 => 이를 통해 page fault 판별이 가능
- Protection : 읽기만 가능한 경우 0, 읽기 쓰기 모두 가능한 경우 1
- Reference : 참조 비트 (최근 참조 됐는지 판단하여 페이지 교체 알고리즘을 적용 시킬 수 있음)
- Caching : 해당 페이지를 캐싱할지 선택
- Dirty (or modified bit) : 오염 또는 수정 여부를 판단하는 비트로, 페이지 내용이 변경됐음을 알려 페이지 교체시 하드 디스크에 다시 기록하게 한다.


### 요구 페이징(Demand Paging)과 페이지 부재(Page Fault)

- 요구 페이징(Demand Pagin) : 요청할 때 해당 페이지를 메모리로 가져오는 것 
- 페이지 부재(Page Fault) : 요청한 페이지가 메모리에 존재하지 않는 경우를 말한다. (캐시 미스와 비슷?)

설명

요구 페이징(Demand Paging)은 가져 오기 정책(fetch policy)중 요구 적재(demand fetch)에 해당하는 방법으로, 한정된 메모리 공간을 효율적으로 관리하기 위해 사용되는 방법입니다. ( <-> Anticipatory Paging : pre-fetch 방식 )


페이지 부재(Page Fault)는 요구 페이징을 사용할 때 발생할 수 있는 상황으로, 페이지 부재가 발생하면 필요로하는 페이지를 스왑 영역에서 메모리로 옮깁니다.

### 페이지 교체(Page replacement)

페이지가 메모리에서 올라오고 쫒겨나고를 반복하기 때문에, 어떤 페이지가 쫒겨나야 하는지 결정 해줘야 합니다.

이를 결정해주는 알고리즘을 페이지 교체 알고리즘이라고 합니다.
ex) FIFO, LRU, LFU, NUR 등의 알고리즘이 있습니다.

 
### 스레싱(Thrasing)

잦은 페이지 부재로 인해 페이지를 교체 하는 시간이 많아져 CPU처리율이 저하되는 현상.
메모리 부족, 부적절한 페이지 교체 등이 원인이 될 수 있음.
cach hit rate와 관련있음.
 


<!-- 
![vm05](https://user-images.githubusercontent.com/75003424/124723869-6e875600-df46-11eb-8498-dcde8d43ff1a.png) -->